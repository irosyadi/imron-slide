<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/quarto-contrib/live-runtime/live-runtime.js" type="module"></script>
<link href="../site_libs/quarto-contrib/live-runtime/live-runtime.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.26">

  <meta name="author" content="Imron Rosyadi">
  <title>Machine Learning</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-b0356e9119c1bdfd0db189d130feb51c.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script type="module" src="../site_libs/quarto-ojs/quarto-ojs-runtime.js"></script>
  <link href="../site_libs/quarto-ojs/quarto-ojs.css" rel="stylesheet">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Machine Learning</h1>
  <p class="subtitle">CNN Model Zoo</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Imron Rosyadi 
</div>
</div>
</div>

</section>
<section>
<section id="convolutional-neural-networks-cnns-in-ece" class="title-slide slide level1 center">
<h1>Convolutional Neural Networks (CNNs) in ECE</h1>
<div class="columns">
<div class="column" style="width:50%;">
<p>Welcome to the fascinating world of Convolutional Neural Networks!</p>
<p>Today, we’ll dive into advanced CNN architectures commonly used in ECE for tasks like:</p>
<ul>
<li><strong>Image/Video Processing:</strong> Object detection, facial recognition</li>
<li><strong>Signal Processing:</strong> Anomaly detection, medical imaging</li>
<li><strong>Robotics &amp; Autonomous Systems:</strong> Perception, navigation</li>
</ul>
</div><div class="column" style="width:50%;">
<p><img data-src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Comparison_image_neural_networks.svg/1280px-Comparison_image_neural_networks.svg.png"></p>
</div></div>
<aside class="notes">
<p><strong>Speaker Notes:</strong></p>
<ul>
<li>Start by engaging students with the practical relevance of CNNs in ECE fields they might be interested in.</li>
<li>Briefly explain what CNNs are at a high level (feature extractors from grid-like data).</li>
<li>Mention that the focus today is on widely used, pre-trained architectures from TensorFlow.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="what-makes-cnn-architectures-advanced" class="slide level2">
<h2>What makes CNN architectures “Advanced”?</h2>
<p>Advanced CNNs are designed to overcome limitations of simpler networks:</p>
<ul>
<li><strong>Deeper Networks:</strong> Learn more complex features.
<ul>
<li><em>Challenge:</em> Vanishing/exploding gradients, computational cost.</li>
</ul></li>
<li><strong>Efficiency:</strong> Achieve high accuracy with fewer parameters/computations.
<ul>
<li><em>Crucial for:</em> Embedded systems, mobile devices (common in ECE).</li>
</ul></li>
<li><strong>Better Generalization:</strong> Perform well on unseen data.
<ul>
<li><em>Important for:</em> Robust real-world ECE applications.</li>
</ul></li>
</ul>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p>These architectures often introduce innovative layers or connections to manage depth and efficiency.</p>
</div>
</div>
</div>
<aside class="notes">
<p><strong>Speaker Notes:</strong></p>
<ul>
<li>Explain that “advanced” isn’t just about more layers, but smarter ways to design those layers and connections.</li>
<li>Connect the challenges (vanishing gradients, computational cost) back to practical ECE constraints, like power consumption or real-time processing.</li>
<li>Emphasize efficiency and generalization as key performance indicators for deploying ML models in ECE systems.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="key-concepts-revisited-convolutions-and-pooling" class="slide level2">
<h2>Key Concepts Revisited: Convolutions and Pooling</h2>
<p>Before diving into complex models, let’s quickly recap:</p>
<h3 id="convolutional-layer">Convolutional Layer</h3>
<p>Extracts features by sliding a filter (kernel) over the input.</p>
<p><span class="math display">\[ (I * K)(i, j) = \sum_m \sum_n I(i-m, j-n) K(m, n) \]</span></p>
<ul>
<li><strong>Parameters:</strong> Filter size, number of filters, stride, padding.</li>
<li><strong>Output:</strong> Feature maps revealing specific patterns.</li>
</ul>
<h3 id="pooling-layer">Pooling Layer</h3>
<p>Reduces spatial dimensions, making the representation smaller and more manageable.</p>
<ul>
<li><p><strong>Max Pooling:</strong> Selects the maximum value from a region.</p></li>
<li><p><strong>Average Pooling:</strong> Computes the average value from a region.</p></li>
<li><p><strong>Benefits:</strong> Reduces parameters, controls overfitting, makes the network invariant to small shifts.</p></li>
</ul>
<aside class="notes">
<p><strong>Speaker Notes:</strong></p>
<ul>
<li>Quickly go over the core operations. Assume students have some basic understanding.</li>
<li>Highlight how these basic building blocks are combined in intricate ways in advanced architectures.</li>
<li>Mention the role of activation functions (ReLU, etc.) even if not explicitly on the slide.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="interactive-convolution-visualization" class="slide level2">
<h2>Interactive Convolution Visualization</h2>
<p>Let’s visualize how a filter slides over an input!</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code hidden" id="cb1" data-startfrom="116" data-source-offset="-0"><pre class="sourceCode numberSource js number-lines code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 115;"><span id="cb1-116"><a></a>viewof input_matrix <span class="op">=</span> Inputs<span class="op">.</span><span class="fu">textarea</span>({</span>
<span id="cb1-117"><a></a>  <span class="dt">label</span><span class="op">:</span> <span class="st">"Input Matrix (3x3 or 4x4, space-separated)"</span><span class="op">,</span></span>
<span id="cb1-118"><a></a>  <span class="dt">value</span><span class="op">:</span> <span class="st">"1 0 1</span><span class="sc">\n</span><span class="st">0 1 0</span><span class="sc">\n</span><span class="st">1 0 1"</span><span class="op">,</span></span>
<span id="cb1-119"><a></a>  <span class="dt">rows</span><span class="op">:</span> <span class="dv">4</span></span>
<span id="cb1-120"><a></a>})<span class="op">;</span></span>
<span id="cb1-121"><a></a></span>
<span id="cb1-122"><a></a>viewof kernel_matrix <span class="op">=</span> Inputs<span class="op">.</span><span class="fu">textarea</span>({</span>
<span id="cb1-123"><a></a>  <span class="dt">label</span><span class="op">:</span> <span class="st">"Kernel Matrix (2x2 or 3x3, space-separated)"</span><span class="op">,</span></span>
<span id="cb1-124"><a></a>  <span class="dt">value</span><span class="op">:</span> <span class="st">"1 0</span><span class="sc">\n</span><span class="st">0 1"</span><span class="op">,</span></span>
<span id="cb1-125"><a></a>  <span class="dt">rows</span><span class="op">:</span> <span class="dv">3</span></span>
<span id="cb1-126"><a></a>})<span class="op">;</span></span>
<span id="cb1-127"><a></a></span>
<span id="cb1-128"><a></a>viewof stride_val <span class="op">=</span> Inputs<span class="op">.</span><span class="fu">range</span>([<span class="dv">1</span><span class="op">,</span> <span class="dv">2</span>]<span class="op">,</span> {<span class="dt">value</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span> <span class="dt">step</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">"Stride"</span>})<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-1" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-2" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-3" data-nodetype="declaration">

</div>
</div>
</div>
</div>
<div>
<div id="pyodide-1" class="exercise-cell">

</div>
<script type="pyodide-1-contents">
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
</script>
</div>
<aside class="notes">
<p><strong>Speaker Notes:</strong></p>
<ul>
<li>Encourage students to experiment with different input images (simple matrices), kernels, and strides.</li>
<li>Point out how the kernel “filters” different features and how stride affects the output size.</li>
<li>Mention that padding (not implemented here for simplicity) would keep the output size similar to the input.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="model-zoo-advanced-cnn-architectures" class="slide level2">
<h2>Model Zoo: Advanced CNN Architectures</h2>
<p>Now, let’s explore some of the most influential advanced CNN architectures available in TensorFlow.</p>
<p>Each model introduces unique strategies to build deeper, more efficient, and more accurate networks.</p>
<ul>
<li><strong>VGG</strong> (Visual Geometry Group)</li>
<li><strong>ResNet</strong> (Residual Network)</li>
<li><strong>Inception</strong> (GoogLeNet)</li>
<li><strong>Xception</strong> (Extreme Inception)</li>
<li><strong>MobileNet</strong> (Mobile-first design)</li>
<li><strong>EfficientNet</strong> (Compound Scaling)</li>
</ul>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p>These models are often pre-trained on large datasets like ImageNet, providing a powerful starting point for various ECE applications via <strong>transfer learning</strong>.</p>
</div>
</div>
</div>
<aside class="notes">
<p><strong>Speaker Notes:</strong></p>
<ul>
<li>Introduce the “model zoo” concept – a collection of battle-tested architectures.</li>
<li>Emphasize transfer learning as a huge benefit for ECE students, allowing them to leverage state-of-the-art models without training from scratch. Connect this to practical engineering efficiency.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="vgg16-vgg19" class="slide level2">
<h2>VGG16 / VGG19</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p>Developed by the Visual Geometry Group at Oxford, known for its <strong>simplicity and uniformity</strong>.</p>
<ul>
<li><strong>Architecture:</strong> Stacks 3x3 convolutional layers with 2x2 max-pooling layers.
<ul>
<li>VGG16 has 16 layers, VGG19 has 19 layers (counted as weight layers).</li>
</ul></li>
<li><strong>Key Idea:</strong> Proved that very deep networks with small filters (3x3) could achieve state-of-the-art performance.</li>
<li><strong>Parameters:</strong> Very high (VGG16 ~138M, VGG19 ~143M).
<ul>
<li><em>Downside:</em> Computationally expensive and memory-intensive.</li>
</ul></li>
</ul>
</div><div class="column" style="width:40%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="https://datahacker.rs/wp-content/uploads/2018/11/vgg-ispravljeno--718x1024.png"></p>
<figcaption>VGG-16 and VGG-19</figcaption>
</figure>
</div>
</div></div>
<aside class="notes">
<p><strong>Speaker Notes:</strong></p>
<ul>
<li>Explain the “simplicity” of VGG – just 3x3 convs and max pooling, but <em>many</em> of them.</li>
<li>Highlight the impact of VGG in demonstrating the power of depth.</li>
<li>Discuss the major drawback: a huge number of parameters, making it less suitable for resource-constrained ECE systems directly. However, it’s still a great feature extractor.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="resnet-residual-network" class="slide level2">
<h2>ResNet (Residual Network)</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p>Introduced by Microsoft Research, solving the vanishing gradient problem in very deep networks.</p>
<ul>
<li><strong>Architecture:</strong> Features <strong>“skip connections”</strong> or <strong>“residual blocks”</strong>.
<ul>
<li>Allows gradients to flow directly through the network.</li>
<li>Enables training networks with hundreds or even thousands of layers (e.g., ResNet-50, ResNet-101, ResNet-152).</li>
</ul></li>
<li><strong>Key Idea:</strong> Instead of learning direct mappings, layers learn <strong>residual mappings</strong>.
<ul>
<li><span class="math inline">\(H(x) = F(x) + x\)</span>, where <span class="math inline">\(F(x)\)</span> is the residual function.</li>
</ul></li>
<li><strong>Parameters:</strong> ResNet-50 ~25M parameters. Much more efficient than VGG.</li>
</ul>
</div><div class="column" style="width:40%;">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><img data-src="cnn_zoo_files\figure-revealjs\mermaid-figure-1.png" style="width:3.78in;height:4.5in"></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p><strong>Speaker Notes:</strong></p>
<ul>
<li>Emphasize the <em>problem</em> ResNet solved: the degradation problem (accuracy saturating and then degrading with increasing depth).</li>
<li>Explain skip connections intuitively: “If a layer doesn’t need to learn anything, it can just pass the input through.”</li>
<li>ResNet’s efficiency and depth make it a go-to for complex image recognition tasks in ECE.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="resnet-residual-network-1" class="slide level2">
<h2>ResNet (Residual Network)</h2>

<img data-src="https://upload.wikimedia.org/wikipedia/commons/thumb/b/b3/ResNet_block.svg/2560px-ResNet_block.svg.png" class="r-stretch"></section>
<section id="resnet-residual-network-2" class="slide level2">
<h2>ResNet (Residual Network)</h2>

<img data-src="https://upload.wikimedia.org/wikipedia/commons/thumb/6/6f/Resnet-18_architecture.svg/400px-Resnet-18_architecture.svg.png" class="r-stretch"></section>
<section id="inception-googlenet" class="slide level2">
<h2>Inception (GoogLeNet)</h2>
<div class="columns">
<div class="column" style="width:50%;">
<p>Developed by Google, emphasizing efficiency and “computational budget.”</p>
<ul>
<li><strong>Architecture:</strong> Uses <strong>Inception Modules</strong> (or blocks) that perform multiple parallel convolutions with different kernel sizes (1x1, 3x3, 5x5) and pooling.
<ul>
<li>1x1 convolutions (bottleneck layers) are used to reduce dimensionality before larger convolutions, saving computation.</li>
</ul></li>
<li><strong>Key Idea:</strong> Allow the network to learn multiple feature representations at once, then concatenate them. Optimizes “width” and “depth” simultaneously.</li>
<li><strong>Parameters:</strong> Very low for its accuracy (GoogLeNet ~5M parameters).
<ul>
<li><em>Highly efficient</em> for deployment in real-time ECE systems.</li>
</ul></li>
</ul>
</div><div class="column" style="width:50%;">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><img data-src="cnn_zoo_files\figure-revealjs\mermaid-figure-5.png" style="width:7.93in;height:5.54in"></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p><strong>Speaker Notes:</strong></p>
<ul>
<li>Focus on the “parallel processing” and “multi-scale feature extraction” aspects of the Inception module.</li>
<li>Explain the 1x1 convolution trick (bottleneck layers) for reducing computational cost. This is a very ECE-relevant concept (resource optimization).</li>
<li>Highlight its low parameter count for high accuracy.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="inception-googlenet-1" class="slide level2">
<h2>Inception (GoogLeNet)</h2>

<img data-src="https://upload.wikimedia.org/wikipedia/commons/thumb/c/c3/Inception_dimension-reduced_module.svg/2560px-Inception_dimension-reduced_module.svg.png" class="r-stretch"></section>
<section id="inception-googlenet-2" class="slide level2">
<h2>Inception (GoogLeNet)</h2>

<img data-src="https://upload.wikimedia.org/wikipedia/commons/thumb/4/44/GoogLeNet_architecture.svg/400px-GoogLeNet_architecture.svg.png" class="r-stretch"></section>
<section id="xception-extreme-inception" class="slide level2">
<h2>Xception (Extreme Inception)</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p>Proposed by Google, building on the Inception idea by replacing standard convolutions with <strong>depthwise separable convolutions</strong>.</p>
<ul>
<li><strong>Architecture:</strong> Inception modules are replaced with depthwise separable convolutions.
<ul>
<li><strong>Depthwise Conv:</strong> Applies a single filter to each input channel independently. For example, if an image has three color channels (red, green, and blue), a separate filter is applied to each color channel.</li>
<li><strong>Pointwise Conv:</strong> A 1x1 convolution projects the output of the depthwise operation into a new channel space. This is a 1×1 filter that combines the output of the depthwise convolution into a single feature map.</li>
</ul></li>
<li><strong>Key Idea:</strong> Separating spatial and channel-wise correlations.
<ul>
<li>More efficient parameter usage and computation than traditional convolutions.</li>
</ul></li>
<li><strong>Parameters:</strong> Xception ~22.9M parameters.
<ul>
<li>Achieves comparable or better accuracy than Inception with fewer parameters and FLOPs.</li>
</ul></li>
</ul>
</div><div class="column" style="width:40%;">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><img data-src="cnn_zoo_files\figure-revealjs\mermaid-figure-4.png" style="width:2.87in;height:3.98in"></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p><strong>Speaker Notes:</strong></p>
<ul>
<li>This is a crucial concept for modern efficient CNNs. Explain depthwise separable convolutions thoroughly.</li>
<li>Analogy: imagine filtering each color channel (R, G, B) separately first (depthwise), then mixing the filtered channels (pointwise).</li>
<li>Connect this efficiency to mobile and embedded device applications in ECE.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="xception-extreme-inception-1" class="slide level2">
<h2>Xception (Extreme Inception)</h2>

<img data-src="https://media.geeksforgeeks.org/wp-content/uploads/20250701093908444668/xception-1.webp" class="r-stretch quarto-figure-center"><p class="caption">Xception</p></section>
<section id="mobilenet-v1-v2-v3" class="slide level2">
<h2>MobileNet (V1, V2, V3)</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p>Designed by Google specifically for <strong>mobile and embedded vision applications</strong>.</p>
<ul>
<li><strong>Architecture:</strong> Primarily uses <strong>depthwise separable convolutions</strong>, similar to Xception.
<ul>
<li><strong>MobileNetV2</strong> introduces “Inverted Residuals” and linear bottlenecks to improve efficiency and avoid information loss.</li>
<li><strong>MobileNetV3</strong> further optimizes through NAS (Neural Architecture Search) and new activation functions.</li>
</ul></li>
<li><strong>Key Idea:</strong> Achieve high accuracy with extremely low latency and small model size.</li>
<li><strong>Parameters:</strong> MobileNetV1 ~4.2M, MobileNetV2 ~3.5M.
<ul>
<li><em>Crucial for:</em> Real-time processing on edge devices, a core ECE application area.</li>
</ul></li>
</ul>
</div><div class="column" style="width:40%;">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><img data-src="cnn_zoo_files\figure-revealjs\mermaid-figure-3.png" style="width:2.53in;height:7.18in"></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p><strong>Speaker Notes:</strong></p>
<ul>
<li>Emphasize the <em>purpose</em> of MobileNet: “mobile-first” design. This is directly relevant to many ECE projects.</li>
<li>Reiterate the role of depthwise separable convolutions and briefly mention inverted residuals for V2/V3 optimizations.</li>
<li>Discuss the trade-off between accuracy and model size/speed, and why this trade-off is often acceptable or necessary in ECE.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="mobilenet-v1-v2-v3-1" class="slide level2">
<h2>MobileNet (V1, V2, V3)</h2>

<img data-src="https://www.tandfonline.com/cms/asset/91c27834-032f-4444-bf2e-7eab0d96b8eb/uemp_a_2329336_f0004_c.jpg" class="r-stretch quarto-figure-center"><p class="caption">MobileNet</p></section>
<section id="efficientnet-b0-to-b7" class="slide level2">
<h2>EfficientNet (B0 to B7)</h2>
<div class="columns">
<div class="column" style="width:60%;">
<p>Developed by Google, achieving state-of-the-art accuracy with significantly fewer parameters and FLOPs than previous models.</p>
<ul>
<li><strong>Architecture:</strong> Uses a compound scaling method to uniformly scale <strong>width, depth, and resolution</strong> of the network.
<ul>
<li>Scales up from a baseline model (EfficientNet-B0) to larger versions (B1-B7).</li>
</ul></li>
<li><strong>Key Idea:</strong> It found a “recipe” for scaling CNNs more efficiently than arbitrary scaling, leading to better accuracy and efficiency trade-offs.</li>
<li><strong>Parameters:</strong> EfficientNet-B0 has ~5.3M parameters, B7 ~66M.
<ul>
<li>Outperforms ResNets and Inception variants with orders of magnitude fewer parameters and FLOPs.</li>
</ul></li>
</ul>
</div><div class="column" style="width:40%;">
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><img data-src="cnn_zoo_files\figure-revealjs\mermaid-figure-2.png" style="width:2.56in;height:5.23in"></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p><strong>Speaker Notes:</strong></p>
<ul>
<li>“Compound scaling” is the unique aspect here. Explain that instead of just making it deeper or wider, EfficientNet finds the optimal way to scale all three dimensions simultaneously.</li>
<li>Highlight its position as the current “state-of-the-art” in terms of efficiency-accuracy trade-off. This is the model to beat in computer vision.</li>
<li>Emphasize its relevance for competitive ECE projects that require both high performance and computational awareness.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="efficientnet-b0-to-b7-1" class="slide level2">
<h2>EfficientNet (B0 to B7)</h2>

<img data-src="https://www.researchgate.net/publication/358585113/figure/fig4/AS:1123594918739968@1644897312526/A-A-concise-representation-of-the-EfficientNet-B0-model-B-The-building-blocks-of_W640.jpg" class="r-stretch quarto-figure-center"><p class="caption">EfficientNet</p></section>
<section id="conclusion-choosing-the-right-cnn-for-ece" class="slide level2">
<h2>Conclusion: Choosing the Right CNN for ECE</h2>
<p>Selecting a CNN architecture largely depends on your specific ECE application requirements:</p>
<ul>
<li><strong>VGG:</strong> Good for understanding basic depth, but often too heavy for deployment.</li>
<li><strong>ResNet:</strong> Excellent for very deep networks, good accuracy. A strong general-purpose choice.</li>
<li><strong>Inception / Xception:</strong> Great for balancing accuracy and efficiency, especially with <strong>depthwise separable convolutions</strong>.</li>
<li><strong>MobileNet:</strong> Your go-to for <strong>edge devices</strong> and real-time mobile applications.</li>
<li><strong>EfficientNet:</strong> Achieves <strong>state-of-the-art</strong> results with remarkable efficiency, often the best choice when pushing performance limits.</li>
</ul>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Important</strong></p>
</div>
<div class="callout-content">
<p>Always consider the trade-off between <strong>accuracy, inference speed, model size, and computational power</strong> available on your target hardware.</p>
</div>
</div>
</div>
<aside class="notes">
<p><strong>Speaker Notes:</strong></p>
<ul>
<li>Summarize the key takeaways for each model regarding its strengths and weaknesses in an ECE context.</li>
<li>Reiterate the importance of the “trade-off” concept, as this is fundamental to engineering design.</li>
<li>Encourage students to experiment with TensorFlow’s <code>tf.keras.applications</code> module to easily load and use these models.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="further-exploration-discussion" class="slide level2">
<h2>Further Exploration &amp; Discussion</h2>
<ul>
<li>How might these different architectures perform on custom datasets specific to ECE applications (e.g., medical images, SAR data, sensor readings)?</li>
<li>What are the challenges of deploying these models on FPGAs or custom ASICs in ECE systems?</li>
<li>Beyond classification, how are these models adapted for tasks like object detection, segmentation, or robotics in your field?</li>
</ul>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p><strong>TensorFlow Keras Applications Documentation:</strong> <a href="https://www.tensorflow.org/api_docs/python/tf/keras/applications">tf.keras.applications</a> This is your starting point for loading pre-trained models.</p>
</div>
</div>
</div>
<aside class="notes">
<p><strong>Speaker Notes:</strong></p>
<ul>
<li>Open the floor for questions and discussion.</li>
<li>Encourage students to think critically about applying these models beyond simple image classification.</li>
<li>Mention the <code>tf.keras.applications</code> module as a practical tool for them to start experimenting.</li>
<li>Reinforce that these models are tools, and engineers need to understand their characteristics to choose the right tool for the job.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>


<script type="pyodide-data">
eyJvcHRpb25zIjp7ImVudiI6eyJQTE9UTFlfUkVOREVSRVIiOiJwbG90bHlfbWltZXR5cGUifSwiaW5kZXhVUkwiOiJodHRwczovL2Nkbi5qc2RlbGl2ci5uZXQvcHlvZGlkZS92MC4yNy4wL2Z1bGwvIn0sInBhY2thZ2VzIjp7InBrZ3MiOlsicHlvZGlkZV9odHRwIiwibWljcm9waXAiLCJpcHl0aG9uIiwibnVtcHkiLCJwbG90bHkiLCJuYmZvcm1hdCJdfX0=
</script>
<script type="ojs-module-contents">
{"contents":[{"cellName":"pyodide-1","inline":false,"methodName":"interpret","source":"_pyodide_value_1 = {\n  const { highlightPython, b64Decode} = window._exercise_ojs_runtime;\n\n  const scriptContent = document.querySelector(`script[type=\\\"pyodide-1-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  // Default evaluation configuration\n  const options = Object.assign({\n    id: \"pyodide-1-contents\",\n    echo: true,\n    output: true\n  }, block.attr);\n\n  // Evaluate the provided Python code\n  const result = pyodideOjs.process({code: block.code, options}, {input_matrix, kernel_matrix, stride_val});\n\n  // Early yield while we wait for the first evaluation and render\n  if (options.output && !(\"1\" in pyodideOjs.renderedOjs)) {\n    const container = document.createElement(\"div\");\n    const spinner = document.createElement(\"div\");\n\n    if (options.echo) {\n      // Show output as highlighted source\n      const preElem = document.createElement(\"pre\");\n      container.className = \"sourceCode\";\n      preElem.className = \"sourceCode python\";\n      preElem.appendChild(highlightPython(block.code));\n      spinner.className = \"spinner-grow spinner-grow-sm m-2 position-absolute top-0 end-0\";\n      preElem.appendChild(spinner);\n      container.appendChild(preElem);\n    } else {\n      spinner.className = \"spinner-border spinner-border-sm\";\n      container.appendChild(spinner);\n    }\n\n    yield container;\n  }\n\n  pyodideOjs.renderedOjs[\"1\"] = true;\n  yield await result;\n}\n"},{"cellName":"pyodide-prelude","inline":false,"methodName":"interpretQuiet","source":"pyodideOjs = {\n  const {\n    PyodideEvaluator,\n    PyodideEnvironmentManager,\n    setupPython,\n    startPyodideWorker,\n    b64Decode,\n    collapsePath,\n  } = window._exercise_ojs_runtime;\n\n  const statusContainer = document.getElementById(\"exercise-loading-status\");\n  const indicatorContainer = document.getElementById(\"exercise-loading-indicator\");\n  indicatorContainer.classList.remove(\"d-none\");\n\n  let statusText = document.createElement(\"div\")\n  statusText.classList = \"exercise-loading-details\";\n  statusText = statusContainer.appendChild(statusText);\n  statusText.textContent = `Initialise`;\n\n  // Hoist indicator out from final slide when running under reveal\n  const revealStatus = document.querySelector(\".reveal .exercise-loading-indicator\");\n  if (revealStatus) {\n    revealStatus.remove();\n    document.querySelector(\".reveal > .slides\").appendChild(revealStatus);\n  }\n\n  // Make any reveal slides with live cells scrollable\n  document.querySelectorAll(\".reveal .exercise-cell\").forEach((el) => {\n    el.closest('section.slide').classList.add(\"scrollable\");\n  })\n\n  // Pyodide supplemental data and options\n  const dataContent = document.querySelector(`script[type=\\\"pyodide-data\\\"]`).textContent;\n  const data = JSON.parse(b64Decode(dataContent));\n\n  // Grab list of resources to be downloaded\n  const filesContent = document.querySelector(`script[type=\\\"vfs-file\\\"]`).textContent;\n  const files = JSON.parse(b64Decode(filesContent));\n\n  let pyodidePromise = (async () => {\n    statusText.textContent = `Downloading Pyodide`;\n    const pyodide = await startPyodideWorker(data.options);\n\n    statusText.textContent = `Downloading package: micropip`;\n    await pyodide.loadPackage(\"micropip\");\n    const micropip = await pyodide.pyimport(\"micropip\");\n    await data.packages.pkgs.map((pkg) => () => {\n      statusText.textContent = `Downloading package: ${pkg}`;\n      return micropip.install(pkg);\n    }).reduce((cur, next) => cur.then(next), Promise.resolve());\n    await micropip.destroy();\n\n    // Download and install resources\n    await files.map((file) => async () => {\n      const name = file.substring(file.lastIndexOf('/') + 1);\n      statusText.textContent = `Downloading resource: ${name}`;\n      const response = await fetch(file);\n      if (!response.ok) {\n        throw new Error(`Can't download \\`${file}\\`. Error ${response.status}: \"${response.statusText}\".`);\n      }\n      const data = await response.arrayBuffer();\n\n      // Store URLs in the cwd without any subdirectory structure\n      if (file.includes(\"://\")) {\n        file = name;\n      }\n\n      // Collapse higher directory structure\n      file = collapsePath(file);\n\n      // Create directory tree, ignoring \"directory exists\" VFS errors\n      const parts = file.split('/').slice(0, -1);\n      let path = '';\n      while (parts.length > 0) {\n        path += parts.shift() + '/';\n        try {\n          await pyodide.FS.mkdir(path);\n        } catch (e) {\n          if (e.name !== \"ErrnoError\") throw e;\n          if (e.errno !== 20) {\n            const errorTextPtr = await pyodide._module._strerror(e.errno);\n            const errorText = await pyodide._module.UTF8ToString(errorTextPtr);\n            throw new Error(`Filesystem Error ${e.errno} \"${errorText}\".`);\n          }\n        }\n      }\n\n      // Write this file to the VFS\n      try {\n        return await pyodide.FS.writeFile(file, new Uint8Array(data));\n      } catch (e) {\n        if (e.name !== \"ErrnoError\") throw e;\n        const errorTextPtr = await pyodide._module._strerror(e.errno);\n        const errorText = await pyodide._module.UTF8ToString(errorTextPtr);\n        throw new Error(`Filesystem Error ${e.errno} \"${errorText}\".`);\n      }\n    }).reduce((cur, next) => cur.then(next), Promise.resolve());\n\n    statusText.textContent = `Pyodide environment setup`;\n    await setupPython(pyodide);\n\n    statusText.remove();\n    if (statusContainer.children.length == 0) {\n      statusContainer.parentNode.remove();\n    }\n    return pyodide;\n  })().catch((err) => {\n    statusText.style.color = \"var(--exercise-editor-hl-er, #AD0000)\";\n    statusText.textContent = err.message;\n    //indicatorContainer.querySelector(\".spinner-grow\").classList.add(\"d-none\");\n    throw err;\n  });\n\n  // Keep track of initial OJS block render\n  const renderedOjs = {};\n\n  const process = async (context, inputs) => {\n    const pyodide = await pyodidePromise;\n    const evaluator = new PyodideEvaluator(pyodide, context);\n    await evaluator.process(inputs);\n    return evaluator.container;\n  }\n\n  return {\n    pyodidePromise,\n    renderedOjs,\n    process,\n  };\n}\n"}]}
</script>
<div id="exercise-loading-indicator" class="exercise-loading-indicator d-none d-flex align-items-center gap-2">
<div id="exercise-loading-status" class="d-flex gap-2">

</div>
<div class="spinner-grow spinner-grow-sm">

</div>
</div>
<script type="vfs-file">
W10=
</script>
</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="../qrjs_pics/unsoed_logo.png" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://imron-slide.vercel.app">irosyadi-2025</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script type="ojs-module-contents">
    eyJjb250ZW50cyI6W3sibWV0aG9kTmFtZSI6ImludGVycHJldCIsImNlbGxOYW1lIjoib2pzLWNlbGwtMSIsImlubGluZSI6ZmFsc2UsInNvdXJjZSI6InZpZXdvZiBpbnB1dF9tYXRyaXggPSBJbnB1dHMudGV4dGFyZWEoe1xuICBsYWJlbDogXCJJbnB1dCBNYXRyaXggKDN4MyBvciA0eDQsIHNwYWNlLXNlcGFyYXRlZClcIixcbiAgdmFsdWU6IFwiMSAwIDFcXG4wIDEgMFxcbjEgMCAxXCIsXG4gIHJvd3M6IDRcbn0pO1xuXG52aWV3b2Yga2VybmVsX21hdHJpeCA9IElucHV0cy50ZXh0YXJlYSh7XG4gIGxhYmVsOiBcIktlcm5lbCBNYXRyaXggKDJ4MiBvciAzeDMsIHNwYWNlLXNlcGFyYXRlZClcIixcbiAgdmFsdWU6IFwiMSAwXFxuMCAxXCIsXG4gIHJvd3M6IDNcbn0pO1xuXG52aWV3b2Ygc3RyaWRlX3ZhbCA9IElucHV0cy5yYW5nZShbMSwgMl0sIHt2YWx1ZTogMSwgc3RlcDogMSwgbGFiZWw6IFwiU3RyaWRlXCJ9KTtcbiJ9LHsibWV0aG9kTmFtZSI6ImludGVycHJldFF1aWV0Iiwic291cmNlIjoic2hpbnlJbnB1dCgnaW5wdXRfbWF0cml4JykifSx7Im1ldGhvZE5hbWUiOiJpbnRlcnByZXRRdWlldCIsInNvdXJjZSI6InNoaW55SW5wdXQoJ2tlcm5lbF9tYXRyaXgnKSJ9LHsibWV0aG9kTmFtZSI6ImludGVycHJldFF1aWV0Iiwic291cmNlIjoic2hpbnlJbnB1dCgnc3RyaWRlX3ZhbCcpIn1dfQ==
    </script>
    <script type="module">
    if (window.location.protocol === "file:") { alert("The OJS runtime does not work with file:// URLs. Please use a web server to view this document."); }
    window._ojs.paths.runtimeToDoc = "../../others";
    window._ojs.paths.runtimeToRoot = "../..";
    window._ojs.paths.docToRoot = "..";
    window._ojs.selfContained = false;
    window._ojs.runtime.interpretFromScriptTags();
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>