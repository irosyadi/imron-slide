[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Machine Learning",
    "section": "",
    "text": "This is Machine Learning Lecture Notes"
  },
  {
    "objectID": "index.html#amli",
    "href": "index.html#amli",
    "title": "Machine Learning",
    "section": "AMLI",
    "text": "AMLI\n\nMachine Learning 8.1: Regression\nMachine Learning 8.2: Regression\nMachine Learning 8.3: Classification\nMachine Learning 8.4: Classification"
  },
  {
    "objectID": "index.html#cs231n",
    "href": "index.html#cs231n",
    "title": "Machine Learning",
    "section": "CS231n",
    "text": "CS231n\n\nCS231n: Classification\nCS231n: Neural Network 1\nCS231n: Neural Network 2\nCS231n: Neural Network 3"
  },
  {
    "objectID": "cs231n/neural-network-2.html#sources",
    "href": "cs231n/neural-network-2.html#sources",
    "title": "Machine Learning",
    "section": "Sources",
    "text": "Sources\nStanford University CS231n: Deep Learning for Computer Vision\nCS231n Deep Learning for Computer Vision"
  },
  {
    "objectID": "cs231n/neural-network-2.html#table-of-contents",
    "href": "cs231n/neural-network-2.html#table-of-contents",
    "title": "Machine Learning",
    "section": "Table of Contents",
    "text": "Table of Contents\n\nQuick Intro: Linear vs NN\nModeling One Neuron\n\nBiological Motivation\nSingle Neuron as Linear Classifier\nActivation Functions\n\nNeural Network Architectures\n\nLayer-wise Organization\nFeed-Forward Computation\nRepresentational Power\nSetting Layers & Sizes\n\nSummary P1"
  },
  {
    "objectID": "cs231n/neural-network-2.html#table-of-contents-continued",
    "href": "cs231n/neural-network-2.html#table-of-contents-continued",
    "title": "Machine Learning",
    "section": "Table of Contents (Continued)",
    "text": "Table of Contents (Continued)\n\nSetting up the Data and Model\n\nData Preprocessing\nWeight Initialization\nBatch Normalization\nRegularization\n\nLoss Functions\nSummary P2\nAdditional References"
  },
  {
    "objectID": "cs231n/neural-network-2.html#setting-up-the-data-and-the-model",
    "href": "cs231n/neural-network-2.html#setting-up-the-data-and-the-model",
    "title": "Machine Learning",
    "section": "5. Setting up the Data and the Model",
    "text": "5. Setting up the Data and the Model\nHaving introduced the basic neuron model and neural network architectures, we now delve into practical considerations for setting up a robust machine learning system.\nThese include:\n\nData Preprocessing: Preparing input data for optimal network performance.\nWeight Initialization: Setting initial values for network parameters.\nBatch Normalization: Stabilizing and accelerating training.\nRegularization: Techniques to prevent overfitting.\n\n\n\n\n\n\n\nNote\n\n\nA Neural Network performs a sequence of linear mappings with interwoven non-linearities. These design choices significantly impact training stability and final model performance.\n\n\n\n\nIn the first part of this lecture, we established the fundamental building blocks of neural networks: the neuron, activation functions, and how neurons arrange into layers to form an architecture. Now, we shift our focus to the practical steps needed before we even begin the iterative training process.\nThe choices we make in data preprocessing, how we initialize weights, whether we use techniques like batch normalization, and applying regularization are not just minor details—they are critical engineering decisions that directly influence how quickly and effectively our network learns, and how well it generalizes to new, unseen data. Each of these steps plays a vital role in taking a theoretical model from concept to a high-performing solution."
  },
  {
    "objectID": "cs231n/neural-network-2.html#data-preprocessing-centering-and-scaling",
    "href": "cs231n/neural-network-2.html#data-preprocessing-centering-and-scaling",
    "title": "Machine Learning",
    "section": "5.1 Data Preprocessing: Centering and Scaling",
    "text": "5.1 Data Preprocessing: Centering and Scaling\nThree common forms of data preprocessing for a data matrix X of size [N x D] (N data, D dimensions).\n1. Mean Subtraction\n\nMost common form; centers data around the origin.\nX -= np.mean(X, axis = 0) (subtract mean of each feature).\nFor images, can subtract global mean or per-channel mean.\n\n2. Normalization\n\nScales data dimensions to approximately same range.\nStandardization: Divide by standard deviation after mean-centering: X /= np.std(X, axis = 0).\nMin-Max Scaling: Normalize to range [-1, 1].\nUseful when features have different scales but similar importance.\n\n\n\n\nLeft: Original data. Middle: Zero-centered. Right: Scaled by standard deviation.\n\n\n\n\n\n\n\n\nImportant\n\n\nPitfall: Preprocessing statistics must be computed only on training data and then applied to validation/test sets to avoid data leakage.\n\n\n\n\nData preprocessing is a crucial first step. Imagine you have a dataset where one feature, like ‘age’, ranges from 0-100, and another feature, ‘income’, ranges from 0-1,000,000. If we feed these directly into a neural network, the income feature might disproportionately influence the weights and gradients simply because its numerical values are much larger.\nMean subtraction removes the average value from each feature, effectively centering the data around zero. This is geometrically equivalent to shifting the cloud of data points so its center aligns with the origin. Normalization then scales these features. Standardization, by dividing by the standard deviation, results in features with unit variance. This ensures that all features contribute roughly equally to the learning process, regardless of their original scale.\nThe image helps visualize these steps. The “Common pitfall” is extremely important: to prevent “data leakage” (where information from your test set inadvertently influences the training process), any statistics (like means or standard deviations) used for preprocessing must be calculated only from the training data. These calculated statistics are then used uniformly across the training, validation, and test datasets."
  },
  {
    "objectID": "cs231n/neural-network-2.html#interactive-data-preprocessing",
    "href": "cs231n/neural-network-2.html#interactive-data-preprocessing",
    "title": "Machine Learning",
    "section": "Interactive Data Preprocessing",
    "text": "Interactive Data Preprocessing\nObserve the effect of mean subtraction and normalization on a small dataset. Modify the data array and rerun the code.\n\n\n\n\n\n\n\nThis interactive block allows you to directly manipulate a small data array and see the immediate effects of mean subtraction and standardization.\nFirst, observe the Original Data. Note the different scales of the features (e.g., column 1 vs. column 2). After Mean Subtracted Data, you’ll see that the values are now centered around zero for each feature. The np.mean(data_centered, axis=0) call will show values very close to zero, validating the centering. Finally, the Standardized Data will have features with values typically ranging around -1 to 1, with means near zero and standard deviations near one. This ensures all features are on a comparable scale, preventing one feature from dominating the learning process purely due to its magnitude. Feel free to change the data array to include different values or even columns of constant values to see how the standardization handles them (e.g., if a feature has zero variance, it will be untouched or handled by the std_data[std_data == 0] = 1 line)."
  },
  {
    "objectID": "cs231n/neural-network-2.html#data-preprocessing-pca-and-whitening",
    "href": "cs231n/neural-network-2.html#data-preprocessing-pca-and-whitening",
    "title": "Machine Learning",
    "section": "5.1 Data Preprocessing: PCA and Whitening",
    "text": "5.1 Data Preprocessing: PCA and Whitening\nAdvanced preprocessing techniques for decorrelation and isotropic representation.\n\nZero-center the data.\nCompute the covariance matrix: cov = np.dot(X.T, X) / X.shape[0].\n\nReveals feature correlations.\n\nPerform Singular Value Decomposition (SVD) on cov: U,S,V = np.linalg.svd(cov).\n\nU: Eigenvectors (new orthogonal basis).\nS: Singular values (related to variance along new axes).\n\nDecorrelate (PCA): Project data onto eigenbasis: Xrot = np.dot(X, U).\n\nXrot_reduced = np.dot(X, U[:,:k]): PCA dimensionality reduction, keeping k most variant dimensions.\n\nWhitening: Scale decorrelated data by eigenvalues: Xwhite = Xrot / np.sqrt(S + 1e-5).\n\nTransforms data to have zero mean and identity covariance matrix (isotropic Gaussian blob).\n\n\n\n\n\n\n\n\nWarning\n\n\nWhitening can exaggerate noise by scaling up low-variance dimensions. A small constant 1e-5 prevents division by zero."
  },
  {
    "objectID": "cs231n/neural-network-2.html#visualizing-pcawhitening-transformations",
    "href": "cs231n/neural-network-2.html#visualizing-pcawhitening-transformations",
    "title": "Machine Learning",
    "section": "Visualizing PCA/Whitening Transformations",
    "text": "Visualizing PCA/Whitening Transformations\n\n\n\n&lt;b&gt;Left&lt;/b&gt;: Original toy 2D data.\n&lt;b&gt;Middle&lt;/b&gt;: After PCA, data is zero-centered and rotated to its eigenbasis (decorrelated).\n&lt;b&gt;Right&lt;/b&gt;: After Whitening, data dimensions are scaled to unit variance, making it an isotropic Gaussian blob.\n\n\n\n\n\n\n\n\nTip\n\n\nIn practice: PCA/Whitening are less common for Convolutional Networks. However, zero-centering is always crucially important, and normalization (dividing by pixel range or standard deviation) is common for images.\n\n\n\n\nPCA and Whitening are more advanced preprocessing steps often used in classical machine learning or for specific types of data. The image shows a beautiful geometric intuition behind these transformations.\nAfter zero-centering, PCA works by rotating the data. The new axes are the “principal components” that capture the most variance in the data. This effectively decorrelates the features. We can also use PCA for dimensionality reduction by keeping only the k principal components that explain most of the variance.\nWhitening takes this a step further by scaling each of these decorrelated dimensions so that they all have unit variance. Geometrically, this transforms the data cloud into a spherical (isotropic) Gaussian distribution.\nWhile powerful, these methods are computationally more intensive and generally not directly applied to raw images in modern Convolutional Neural Networks. For CNNs, zero-centering and simple scaling (e.g., dividing pixel values by 255 or subtracting channel means and dividing by channel standard deviations) are typically sufficient and more robust. The caution about Whitening exaggerating noise is also important, as it scales up even the smallest variances."
  },
  {
    "objectID": "cs231n/neural-network-2.html#pca-visualization-with-cifar-10-features",
    "href": "cs231n/neural-network-2.html#pca-visualization-with-cifar-10-features",
    "title": "Machine Learning",
    "section": "PCA Visualization with CIFAR-10 Features",
    "text": "PCA Visualization with CIFAR-10 Features\nThese visualizations demonstrate PCA’s effect on image features, reducing dimensionality while preserving information.\n\n\n\n&lt;b&gt;Left:&lt;/b&gt; Sample CIFAR-10 images.\n&lt;b&gt;2nd Left:&lt;/b&gt; Top 144 eigenvectors (basis images); capture lower frequencies.\n&lt;b&gt;2nd Right:&lt;/b&gt; Images reconstructed from 144 PCA-reduced features (slightly blurrier, but preserved).\n&lt;b&gt;Right:&lt;/b&gt; Whitened images; higher frequencies exaggerated.\n\n\n\nThis slide offers a qualitative understanding of PCA in the context of image data, specifically CIFAR-10. If we treat each image as a high-dimensional vector, we can apply PCA. The “eigenvectors” in this context can be visualized as synthetic images themselves. The top eigenvectors (second from left) represent dominant patterns or lower frequencies in the dataset.\nWhen we reduce an image to its top 144 PCA components and then reconstruct it (second from right), you can see that despite using significantly fewer numbers (144 vs 3072), much of the visual information—the general shape and color—is retained, although some fine details (higher frequencies) are lost, resulting in blurriness.\nThe rightmost image, showing the “whitened” representation, further illustrates the impact of scaling by eigenvalues. Here, the low-frequency components, which naturally have high variance in images, are compressed, while the higher-frequency, often noisy components are amplified. This leads to a distinct, “edge-enhanced” appearance, which can be useful in some contexts but often problematic for noise sensitivity. This helps illustrate why simple normalization is preferred for CNNs in practice."
  },
  {
    "objectID": "cs231n/neural-network-2.html#weight-initialization",
    "href": "cs231n/neural-network-2.html#weight-initialization",
    "title": "Machine Learning",
    "section": "5.2 Weight Initialization",
    "text": "5.2 Weight Initialization\nCrucial for network stability and convergence. Poor initialization can lead to vanishing/exploding gradients or slow learning.\nPitfall: All Zero Initialization\n\nW = np.zeros((D, H))\nProblem: Every neuron computes the same output, gradients, and updates.\nLeads to a symmetric network where all neurons learn the same features.\nResult: No symmetry breaking, network effectively becomes a single neuron per layer.\n\nSmall Random Numbers (Symmetry Breaking)\n\nW = 0.01 * np.random.randn(D, H)\nInitialize weights to small, random values (e.g., from a Gaussian distribution).\nNeurons start unique, compute distinct updates, and break symmetry.\n\n\n\n\n\n\n\nWarning\n\n\nVery small weights can lead to very small gradients during backpropagation, diminishing the “gradient signal” in deep networks.\n\n\n\n\nWeight initialization is far more important than it might seem at first glance. It sets the starting point for the optimization process, and a bad start can either prevent the network from learning anything or significantly slow down its convergence.\nThe “all zero initialization” is a classic example of what not to do. If all weights are zero, then every neuron in a given layer will produce the same output, and during backpropagation, they will all receive the identical gradients. This means they will all update their weights identically, and effectively become indistinguishable, failing to learn diverse features.\nThe simplest solution is to initialize with “small random numbers.” This breaks the symmetry, ensuring that each neuron starts in a unique state and thus learns different features. However, even this has a caveat: if values are too small, the gradients flowing back through the network can become very tiny, leading to the vanishing gradient problem, especially in deeper networks. This highlights a balancing act we need to achieve: not too uniform, not too small, and preferably calibrated."
  },
  {
    "objectID": "cs231n/neural-network-2.html#weight-initialization-calibrating-variances",
    "href": "cs231n/neural-network-2.html#weight-initialization-calibrating-variances",
    "title": "Machine Learning",
    "section": "5.2 Weight Initialization: Calibrating Variances",
    "text": "5.2 Weight Initialization: Calibrating Variances\nProblem: Variance of a neuron’s output grows with the number of inputs (n).\nProposed Solution: Scale initial weights by 1/sqrt(n) to normalize output variance.\nHeuristic: w = np.random.randn(n) / np.sqrt(n)\n\nEnsures all neurons initially have approximately the same output distribution.\nEmpirically improves convergence rate.\n\nDerivation Sketch:\nFor a neuron’s raw activation s = _i^n w_i x_i with zero-mean inputs/weights: \\[\n\\text{Var}(s) = \\left( n \\text{Var}(w) \\right) \\text{Var}(x)\n\\]\nTo make \\(\\text{Var}(s) \\approx \\text{Var}(x)\\), we need \\(n \\text{Var}(w) = 1\\), so \\(\\text{Var}(w) = 1/n\\).\nIf \\(w_i \\sim N(0, \\sigma^2)\\), then \\(\\sigma^2 = 1/n\\), so \\(\\sigma = 1/\\sqrt{n}\\).\n\n\n\n\n\n\nTip\n\n\nCurrent Recommendation (He et al. 2015): For ReLU neurons, use \\(\\text{Var}(w) = 2/n\\). Thus, w = np.random.randn(n) * np.sqrt(2.0/n).\n\n\n\n\nA significant challenge with random initialization is that the variance of a neuron’s output can increase with the number of its inputs (n). If outputs get too large, they can cause activation functions (like sigmoid or tanh) to saturate, leading to vanishing gradients. If they’re too small, gradients also vanish.\nThe solution is to “calibrate” the variance. The core idea is to scale the initial weights such that the variance of the neuron’s output remains stable across layers, ideally similar to the variance of its inputs. The derivation shows how 1/sqrt(n) comes about.\nFor ReLU activation functions, which are very common, a slightly different scaling factor was derived by He et al. (2015), pushing the variance to 2/n, leading to the np.sqrt(2.0/n) scaling factor. This initialization is widely used and highly recommended for networks employing ReLU. This helps maintain healthy gradients throughout training."
  },
  {
    "objectID": "cs231n/neural-network-2.html#interactive-weight-initialization-variance",
    "href": "cs231n/neural-network-2.html#interactive-weight-initialization-variance",
    "title": "Machine Learning",
    "section": "Interactive Weight Initialization Variance",
    "text": "Interactive Weight Initialization Variance\nObserve how weight scaling affects the variance of a neuron’s output.\nAdjust the number_of_inputs and scaling_factor to see their impact.\n\nviewof number_of_inputs = Inputs.range([1, 100], {value: 50, step: 1, label: \"Number of Inputs (n)\"});\nviewof scaling_factor_val = Inputs.range([0.01, 2.0], {value: 1.0, step: 0.01, label: \"Weight Scaling Factor\"});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis interactive example allows you to explore the relationship between the number of inputs to a neuron (n) and the scaling of its initial weights on the variance of its output s.\n\nnumber_of_inputs (n): Represents the “fan-in” to the neuron.\nscaling_factor_val: This explicitly controls the sigma used to initialize the weights.\n\nObserve how Variance of neuron output (s) changes. If scaling_factor_val is 1.0 (default for np.random.randn), try increasing n. You’ll see var_s increase proportionally to n. This illustrates the problem: a deeper network with many inputs per neuron would quickly lead to very large outputs.\nNow, try to manually set scaling_factor_val to 1/sqrt(n) or sqrt(2/n) (where n is your current number_of_inputs) and observe if var_s approaches 1.0 or 2.0 respectively (reflecting Var(x) if Var(x)=1). For instance, if n=50, try 1/sqrt(50) (approx 0.14) or sqrt(2/50) (approx 0.2). You should see the variance stabilize.\nThis demonstrates why proper scaling is critical for maintaining healthy signal magnitudes throughout the network, preventing activations from exploding or vanishing and facilitating stable training."
  },
  {
    "objectID": "cs231n/neural-network-2.html#weight-initialization-other-considerations",
    "href": "cs231n/neural-network-2.html#weight-initialization-other-considerations",
    "title": "Machine Learning",
    "section": "5.2 Weight Initialization: Other Considerations",
    "text": "5.2 Weight Initialization: Other Considerations\n\nSparse Initialization:\n\nSet all weight matrices to zero, but randomly connect a fixed, small number of neurons (e.g., 10) with small Gaussian weights.\nAddresses uncalibrated variance but less common than He/Xavier.\n\nInitializing Biases:\n\nUsually initialized to zero. Symmetry breaking is handled by weights.\nFor ReLU, sometimes a small constant (e.g., 0.01) is used to ensure units fire initially, but this is not consistently beneficial.\n\n\n\n\n\n\n\n\nTip\n\n\nIn practice: Current recommendation for ReLU is w = np.random.randn(n) * np.sqrt(2.0/n). Biases are typically initialized to zero."
  },
  {
    "objectID": "cs231n/neural-network-2.html#batch-normalization-batchnorm",
    "href": "cs231n/neural-network-2.html#batch-normalization-batchnorm",
    "title": "Machine Learning",
    "section": "5.3 Batch Normalization (BatchNorm)",
    "text": "5.3 Batch Normalization (BatchNorm)\nA technique to stabilize and accelerate deep network training.\nCore Idea:\nExplicitly forces activations throughout the network to take on a unit Gaussian distribution at the beginning of training for each mini-batch.\nMechanism:\nFor each feature map in a layer, normalize its activations:\n\nCalculate mean \\(\\mu_B\\) and variance \\(\\sigma_B^2\\) for the current mini-batch B.\nNormalize: \\(\\hat{x}_i = (x_i - \\mu_B) / \\sqrt{\\sigma_B^2 + \\epsilon}\\)\nScale and Shift: \\(y_i = \\gamma \\hat{x}_i + \\beta\\)\n\n\\(\\gamma, \\beta\\) are learnable parameters (scale and shift).\nAllows network to restore original distribution if optimal.\n\n\n\n\n\n\n\n\nImportant\n\n\nInsert the BatchNorm layer immediately after fully connected/convolutional layers and before non-linearities."
  },
  {
    "objectID": "cs231n/neural-network-2.html#visualizing-batch-normalizations-placement",
    "href": "cs231n/neural-network-2.html#visualizing-batch-normalizations-placement",
    "title": "Machine Learning",
    "section": "Visualizing Batch Normalization’s Placement",
    "text": "Visualizing Batch Normalization’s Placement\n\n\n\n\n\ngraph TD\n    Input --&gt; FC_Layer(Fully Connected Layer)\n    FC_Layer --&gt; BatchNorm_Layer(Batch Normalization Layer)\n    BatchNorm_Layer --&gt; Activation_Function(\"Activation Function (e.g., ReLU)\")\n    Activation_Function --&gt; Next_Layer(...)\n\n    style Input fill:#e0f7fa,stroke:#333,stroke-width:2px;\n    style FC_Layer fill:#fff8e1,stroke:#333,stroke-width:2px;\n    style BatchNorm_Layer fill:#e8f5e9,stroke:#333,stroke-width:2px;\n    style Activation_Function fill:#ffebee,stroke:#333,stroke-width:2px;\n    style Next_Layer fill:#e0f7fa,stroke:#333,stroke-width:2px;\n\n\n\n\n\n\nBenefits of BatchNorm:\n\nGreatly improves training speed.\nMakes networks significantly more robust to bad initialization.\nActs as a form of regularization, reducing reliance on other techniques like Dropout.\nAllows for higher learning rates.\n\n\nBatch Normalization, introduced by Ioffe and Szegedy in 2015, is a major breakthrough in deep learning training. It addresses the “internal covariate shift” problem, where the distribution of activations changes throughout training as parameters in previous layers update. This constant shifting makes it difficult for deeper layers to learn effective representations.\nThe core idea is simple: for each mini-batch during training, normalize the activations of each feature to have zero mean and unit variance. This is done on a per-feature basis. However, simply normalizing might restrict the network’s representational power. To counteract this, BatchNorm introduces two learnable parameters, gamma (scale) and beta (shift), which allow the network to optimally re-scale and re-shift the normalized values. If it’s optimal for a layer to have a different mean or variance, the network can learn to restore that.\nThe Mermaid diagram clearly shows BatchNorm’s preferred placement: always after the linear transformation (FC or Conv layer) and before the non-linear activation function. This ensures that the inputs to the non-linearity are always in a stable, well-behaved range. The benefits are profound, leading to faster training, better robustness, and often improved generalization."
  },
  {
    "objectID": "cs231n/neural-network-2.html#regularization-preventing-overfitting",
    "href": "cs231n/neural-network-2.html#regularization-preventing-overfitting",
    "title": "Machine Learning",
    "section": "5.4 Regularization: Preventing Overfitting",
    "text": "5.4 Regularization: Preventing Overfitting\nTechniques to control network capacity and improve generalization to unseen data.\nL2 Regularization (Weight Decay)\n\nMost common form.\nAdds \\(\\frac{1}{2}\\lambda w^2\\) to the objective for each weight \\(w\\).\nIntuition: Penalizes large weights, preferring diffuse weight vectors.\nEncourages the network to use all inputs a little, rather than some inputs a lot.\nDuring gradient descent, causes weights to decay linearly towards zero: W += -lambda * W.\n\nL1 Regularization\n\nAdds \\(\\lambda \\mid w \\mid\\) to the objective for each weight w.\nProperty: Leads to sparse weight vectors (many weights become exactly zero).\nUseful for feature selection; neurons rely on a sparse subset of inputs.\nCan be combined with L2: Elastic Net Regularization.\n\n\n\n\n\n\n\nNote\n\n\nL2 regularization generally gives superior performance unless explicit feature selection (sparsity) is desired."
  },
  {
    "objectID": "cs231n/neural-network-2.html#regularization-max-norm-dropout",
    "href": "cs231n/neural-network-2.html#regularization-max-norm-dropout",
    "title": "Machine Learning",
    "section": "5.4 Regularization: Max Norm & Dropout",
    "text": "5.4 Regularization: Max Norm & Dropout\nMax Norm Constraints\n\nEnforces an absolute upper bound on the magnitude of each neuron’s weight vector.\nWeight vector \\(\\vec{w}\\) is clamped to satisfy \\(\\Vert \\vec{w} \\Vert_2 &lt; c\\) after each update (e.g., \\(c=3\\) or \\(4\\)).\nBenefit: Prevents “exploding” network activations, even with high learning rates.\n\nDropout\n\nExtremely effective and simple regularization technique.\nDuring training, each neuron is kept active with probability \\(p\\) (hyperparameter, e.g., 0.5) or set to zero otherwise.\n\n\n\n\nDropout can be seen as training an ensemble of neural networks.\n\n\n\n\n\n\n\n\nImportant\n\n\nDropout, L2, L1, and Max Norm address different aspects of overfitting and can often be combined effectively."
  },
  {
    "objectID": "cs231n/neural-network-2.html#dropout-implementation",
    "href": "cs231n/neural-network-2.html#dropout-implementation",
    "title": "Machine Learning",
    "section": "Dropout: Implementation",
    "text": "Dropout: Implementation\nVanilla Dropout (Not Recommended)\nScales activations at test time.\np = 0.5 # probability of keeping a unit active\n\ndef train_step(X):\n  H1 = np.maximum(0, np.dot(W1, X) + b1)\n  U1 = np.random.rand(*H1.shape) &lt; p # binary mask\n  H1 *= U1 # drop!\n  # ... second layer ...\n\ndef predict(X):\n  H1 = np.maximum(0, np.dot(W1, X) + b1) * p # NOTE: scale by p\n  # ... second layer ..."
  },
  {
    "objectID": "cs231n/neural-network-2.html#dropout-implementation-1",
    "href": "cs231n/neural-network-2.html#dropout-implementation-1",
    "title": "Machine Learning",
    "section": "Dropout: Implementation",
    "text": "Dropout: Implementation\nInverted Dropout (Recommended)\nScales activations at train time, leaving test time untouched.\np = 0.5 # probability of keeping a unit active\n\ndef train_step(X):\n  H1 = np.maximum(0, np.dot(W1, X) + b1)\n  U1 = (np.random.rand(*H1.shape) &lt; p) / p # NOTE: scale by 1/p\n  H1 *= U1 # drop!\n  # ... second layer ...\n\ndef predict(X):\n  H1 = np.maximum(0, np.dot(W1, X) + b1) # NO scaling needed\n  # ... second layer ...\n\n\n\n\n\n\nTip\n\n\nIn practice: Use a single, global L2 regularization strength (cross-validated) with inverted dropout (p=0.5 is a good default).\n\n\n\n\nDropout is an ingenious and remarkably simple regularization technique. During training, it randomly “turns off” (sets to zero) a fraction of neurons in a layer. This forces the network to learn more robust features because no single neuron can rely too heavily on the presence of another. It prevents complex co-adaptations and effectively trains an “ensemble” of many smaller networks.\nThe crucial detail is how it’s handled during prediction. To maintain the same expected output magnitude as during training, we usually have to scale the activations. “Vanilla Dropout” scales at test time, which can complicate deployment. “Inverted Dropout,” the recommended approach, performs this scaling during training (by dividing by p), so that at test time, no modifications are needed. This makes the prediction code cleaner and more efficient.\nThe figure illustrates dropout as sampling a sub-network from the full network. The “In practice” tip is a strong guide for initial experiments: combine L2 regularization with inverted dropout."
  },
  {
    "objectID": "cs231n/neural-network-2.html#interactive-dropout-simulation",
    "href": "cs231n/neural-network-2.html#interactive-dropout-simulation",
    "title": "Machine Learning",
    "section": "Interactive Dropout Simulation",
    "text": "Interactive Dropout Simulation\nSimulate inverted dropout on a small matrix. Adjust dropout_probability_p to see how many elements are dropped and scaled.\n\nviewof dropout_probability_p = Inputs.range([0.1, 1.0], {value: 0.5, step: 0.1, label: \"Dropout Probability (p)\"});\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis Pyodide block provides a hands-on demonstration of Inverted Dropout. You can see how:\n\nA random random_mask is generated based on the dropout_probability_p. Elements are True (kept) with probability p, and False (dropped) with probability 1-p.\nThe mask U is created by dividing the random_mask by p. This 1/p scaling is the core of inverted dropout, ensuring that the expected sum of activations remains the same after dropout.\nThe H_original activations are then multiplied by U to get H_dropped_scaled. Notice how some values become zero (dropped), and the values that are kept are scaled up by 1/p.\n\nExperiment by changing the dropout_probability_p:\n\nA p=1.0 means no dropout; all elements are kept and scaled by 1/1.0 = 1, so H_dropped_scaled should be identical to H_original.\nA smaller p (e.g., 0.1) will result in more elements being dropped and the kept elements being scaled up by a larger factor (e.g., 1/0.1 = 10).\n\nThis interactive visualization helps solidify the understanding of how inverted dropout operates and why the scaling factor 1/p is essential."
  },
  {
    "objectID": "cs231n/neural-network-2.html#loss-functions",
    "href": "cs231n/neural-network-2.html#loss-functions",
    "title": "Machine Learning",
    "section": "6. Loss Functions",
    "text": "6. Loss Functions\nThe “data loss” component of your objective function. Measures compatibility between prediction (f) and ground truth label (y). Total loss: \\(L = \\frac{1}{N} \\sum_i L_i + \\text{Regularization Loss}\\).\n6.1 Classification\nOne correct label \\(y_i\\) from a fixed set.\n\nSVM Loss (Weston Watkins): \\[L_i = \\sum_{j\\neq y_i} \\max(0, f_j - f_{y_i} + 1)\\]\n\nAlso common: squared hinge loss \\(\\max(0, f_j - f_{y_i} + 1)^2\\).\n\nSoftmax Loss (Cross-Entropy): \\[L_i = -\\log\\left(\\frac{e^{f_{y_i}}}{ \\sum_j e^{f_j} }\\right)\\]\n\nInterprets scores \\(f_j\\) as unnormalized log-probabilities.\n\n\n\n\n\n\n\n\nNote\n\n\nLarge Number of Classes Problem: For huge label sets (e.g., ImageNet 22k, NLP vocabularies), computing full Softmax is expensive. Solutions like Hierarchical Softmax approximate by structuring labels in a tree.\n\n\n\n\nLoss functions are fundamental in supervised learning; they quantify how “wrong” our model’s predictions are. The goal of training is to minimize this loss, along with the regularization loss discussed earlier.\nFor classification, where each example has one correct label, two major loss functions stand out. The SVM loss aims to ensure that the score of the correct class is at least a certain margin (typically 1) higher than the scores of all incorrect classes. If this margin is not met, a penalty is incurred.\nThe Softmax loss, also known as cross-entropy loss, is perhaps more intuitive. It transforms the raw scores into probabilities using the softmax function and then penalizes the model based on the (negative) log-probability assigned to the true class. The higher the probability of the correct class, the lower the loss.\nWhen you have thousands or even millions of classes (like in large language models or image datasets with very fine-grained categories), computing the sum over all possible classes in Softmax can become computationally prohibitive. Hierarchical Softmax is one technique that tries to mitigate this by creating a tree structure for classes, where decisions are made at each node, dramatically reducing the number of computations."
  },
  {
    "objectID": "cs231n/neural-network-2.html#interactive-classification-loss-plot",
    "href": "cs231n/neural-network-2.html#interactive-classification-loss-plot",
    "title": "Machine Learning",
    "section": "Interactive Classification Loss Plot",
    "text": "Interactive Classification Loss Plot\nCompare SVM and Softmax loss for a single example prediction. Adjust the correct_class_score and incorrect_class_score to see their impact on loss.\n\nviewof correct_score = Inputs.range([-3, 5], {value: 2, step: 0.1, label: \"Score for Correct Class\"});\nviewof incorrect_score = Inputs.range([-3, 5], {value: 0.5, step: 0.1, label: \"Score for Incorrect Class\"});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis interactive plot helps compare the behavior of SVM and Softmax loss functions. We simulate a scenario with two classes, where one is correct and the other is incorrect.\n\nX-axis: Represents the score assigned by the model to the incorrect class.\nY-axis: Represents the resulting loss.\nThe correct_class_score slider allows you to fix the score of the correct class.\n\nObservations:\n\nSVM Loss (Blue): Notice that when the incorrect class score is much lower than the correct class score (by at least the margin of 1), the SVM loss becomes 0. This means the SVM is “satisfied” and no longer penalizes the model. It cares only about achieving this margin.\nSoftmax Loss (Red): The Softmax loss never reaches 0, even when the incorrect score is very low. It continuously encourages the correct class score to be as high as possible and incorrect class scores to be as low as possible, pushing towards an ideal probability of 1 for the correct class.\n\nAdjust the sliders to explore different scenarios. For instance, make the incorrect_class_score higher than correct_class_score to see how both losses increase. This demonstrates their distinct behaviors in guiding the optimization process. SVM creates a “flat” loss landscape once the margin is met, while Softmax always provides a gradient to improve probabilities."
  },
  {
    "objectID": "cs231n/neural-network-2.html#attribute-classification",
    "href": "cs231n/neural-network-2.html#attribute-classification",
    "title": "Machine Learning",
    "section": "6.2 Attribute Classification",
    "text": "6.2 Attribute Classification\nAttribute Classification\n\nFor multi-label problems where an example can have multiple non-exclusive attributes (e.g., an image with multiple hashtags).\nApproach: Build a binary classifier for each attribute independently.\nSVM-like Loss: \\[L_i = \\sum_j \\max(0, 1 - y_{ij} f_j)\\]\n\n\\(y_{ij} \\in \\{+1, -1\\}\\), \\(f_j\\) is the score for attribute \\(j\\).\n\nLogistic Regression Loss: \\[L_i = -\\sum_j y_{ij} \\log(\\sigma(f_j)) + (1 - y_{ij}) \\log(1 - \\sigma(f_j))\\]\n\n\\(y_{ij} \\in \\{0, 1\\}\\), \\(\\sigma(\\cdot)\\) is the sigmoid function."
  },
  {
    "objectID": "cs231n/neural-network-2.html#regression",
    "href": "cs231n/neural-network-2.html#regression",
    "title": "Machine Learning",
    "section": "6.3 Regression",
    "text": "6.3 Regression\nRegression (Predicting Real-Valued Quantities)\n\nCommonly uses L2 or L1 norm of the difference.\nL2 Loss (Squared Error): \\[L_i = \\Vert f - y_i \\Vert_2^2\\]\nL1 Loss (Absolute Error): \\[L_i = \\Vert f - y_i \\Vert_1 = \\sum_j \\mid f_j - (y_i)_j \\mid\\]\n\n\n\n\n\n\n\nWarning\n\n\nL2 loss is much harder to optimize and less robust to outliers than Softmax. Consider quantizing outputs into bins and performing classification whenever possible for regression tasks.\n\n\n\n\nBeyond single-label classification, we encounter other types of problems. Attribute classification, also known as multi-label classification, is when an instance can belong to multiple categories simultaneously (e.g., an image of a dog and a cat). The most common approach is to treat each attribute as an independent binary classification problem, applying either an SVM-like hinge loss or a logistic regression (binary cross-entropy) loss to each attribute’s score.\nRegression, on the other hand, deals with predicting continuous, real-valued quantities. The L2 (squared error) and L1 (absolute error) norms are the standard choices. L2 loss is differentiable everywhere and heavily penalizes large errors, pushing the model to be very accurate for all points. However, this also makes it sensitive to outliers. L1 loss is more robust to outliers as it scales linearly with the error.\nCritically, the warning reminds us that L2 loss can be very fragile. Neural networks might struggle to output exact values. It is often a strong engineering heuristic to convert a regression problem into a classification problem by discretizing the output range into bins. For example, predicting house prices might become classifying into “price range” bins. This approach can be more stable and provide confidence estimates over the predicted range."
  },
  {
    "objectID": "cs231n/neural-network-2.html#summary-part-2",
    "href": "cs231n/neural-network-2.html#summary-part-2",
    "title": "Machine Learning",
    "section": "7. Summary (Part 2)",
    "text": "7. Summary (Part 2)\n\nData Preprocessing: Crucial for model stability and performance.\n\nAlways zero-center data.\nNormalize data scale (e.g., by standard deviation).\nCompute preprocessing statistics only on training data.\n\nWeight Initialization:\n\nAvoid zero initialization; use small random numbers.\nRecommended for ReLU: w = np.random.randn(n) * np.sqrt(2.0/n).\nBiases typically initialized to zero.\n\nBatch Normalization:\n\nStabilizes training and speeds up convergence.\nInsert after FC/Conv layers, before non-linearities.\nMakes networks robust to poor initialization.\n\nRegularization: Prevents overfitting.\n\nCommonly use L2 regularization and inverted Dropout (p=0.5 is a good default).\n\nLoss Functions:\n\nClassification: SVM loss, Softmax (Cross-entropy) loss.\nAttribute Classification: Per-attribute binary classifiers (SVM-like or Logistic Regression).\nRegression: L2 or L1 Loss. Prefer classification for regression when possible."
  },
  {
    "objectID": "cs231n/classification.html#what-is-image-classification",
    "href": "cs231n/classification.html#what-is-image-classification",
    "title": "Machine Learning",
    "section": "What is Image Classification?",
    "text": "What is Image Classification?\nGiven: A set of images, each labeled with a single category (e.g., “cat”, “dog”, “car”).\nGoal: Train a model to predict the category of new, unseen images.\n\n\nECE Relevance:\n\nAutonomous Systems: Object detection in self-driving cars.\nMedical Imaging: Diagnosing diseases from X-rays or MRI scans.\nQuality Control: Detecting defects in manufacturing.\nSignal Processing: Classifying radar or sonar signals into object types.\n\n\n\n\n\nBefore we jump into Nearest Neighbors, let’s set the stage. What exactly is image classification? Imagine you have a library of images, each already tagged with what’s inside – cats, dogs, cars, etc. The challenge for us is to build an intelligent system that can look at a brand new image it has never seen before and correctly assign it to one of these predefined categories.\nThis isn’t just an abstract computer science problem; it has profound implications in ECE. Think about autonomous vehicles needing to instantly recognize pedestrians, traffic signs, or other cars to ensure safety. In medical imaging, machine learning helps doctors identify anomalies in scans. In manufacturing, automated systems can ensure product quality by detecting tiny defects. Even in signal processing, we classify patterns in sensor data, like identifying different types of aircraft from radar signals. All these applications rely on effective classification."
  },
  {
    "objectID": "cs231n/classification.html#the-nearest-neighbor-nn-principle",
    "href": "cs231n/classification.html#the-nearest-neighbor-nn-principle",
    "title": "Machine Learning",
    "section": "The Nearest Neighbor (NN) Principle",
    "text": "The Nearest Neighbor (NN) Principle\n“Birds of a feather flock together.”\nThe core idea is simple: - Store all training data. - To classify a new point: Find the closest training example. - Assign the new point the label of its closest training example.\n\n\n\n\n\n\nImportant\n\n\nHow do we define “closest”? We use Distance Metrics!\n\n\n\n\nThe Nearest Neighbor, or NN, classifier is beautifully simple. Its core principle is like the old saying: “birds of a feather flock together.” If you want to know what something is, look at what it’s most similar to from things you already know.\nIn practice, this means our classifier simply memorizes all the training examples. When a new, unknown data point comes in – let’s say a new image – the classifier compares it to every single training image it has. It then identifies which training image is the “closest” or “most similar” and simply assigns that training image’s label to our new, unknown image.\nBut this raises a critical question: how do we quantitatively define “closest” or “most similar”? This is where distance metrics come into play. They provide a mathematical way to measure the dissimilarity between two data points."
  },
  {
    "objectID": "cs231n/classification.html#defining-closeness-distance-metrics",
    "href": "cs231n/classification.html#defining-closeness-distance-metrics",
    "title": "Machine Learning",
    "section": "Defining “Closeness”: Distance Metrics",
    "text": "Defining “Closeness”: Distance Metrics\nCommon choices for d(I_1, I_2) (distance between images I_1 and I_2):\n\nL1 Distance (Manhattan Distance): \\[ d_1(I_1, I_2) = \\sum_{p} |I_1(p) - I_2(p)| \\]\n\nSums absolute differences across all pixel values.\nRepresents distance if moving only horizontally or vertically.\n\nL2 Distance (Euclidean Distance): \\[ d_2(I_1, I_2) = \\sqrt{\\sum_{p} (I_1(p) - I_2(p))^2} \\]\n\nSums squared differences, then takes the square root.\nRepresents the straight-line distance in a multi-dimensional space.\n\n\n\n\n\n\n\n\nTip\n\n\nIn ECE, these distances are fundamental for comparing signals or data vectors.\n\n\n\n\nWhen we talk about images, each image can be thought of as a high-dimensional vector, where each pixel value is a dimension. So, subtracting two images means subtracting their pixel values.\nThe L1 distance, also known as Manhattan or city-block distance, is like navigating a grid. Imagine you’re in a city with perfectly laid-out streets; to get from point A to point B, you sum the horizontal and vertical distances. For images, we sum the absolute differences of each corresponding pixel.\nThe L2 distance, or Euclidean distance, is what you typically think of as “distance” in everyday life – the shortest straight line between two points. For images, we square the differences of corresponding pixels, sum them, and then take the square root. This emphasizes larger differences more than L1.\nBoth L1 and L2 distances are widely used in ECE not just for images, but for comparing sound signals, sensor readings, or any vectorized data. Understanding these basic metrics is crucial for many signal processing and machine learning tasks."
  },
  {
    "objectID": "cs231n/classification.html#k-nearest-neighbors-k-nn-classifier",
    "href": "cs231n/classification.html#k-nearest-neighbors-k-nn-classifier",
    "title": "Machine Learning",
    "section": "k-Nearest Neighbors (k-NN) Classifier",
    "text": "k-Nearest Neighbors (k-NN) Classifier\nBeyond a single neighbor\nInstead of just one neighbor, k-NN considers the k closest training examples. The label of the new point is determined by a majority vote among its k nearest neighbors.\n\n\nKey Hyperparameter: k\n\nk = 1 is the basic Nearest Neighbor.\nChoosing k &gt; 1 provides a smoother decision boundary and can reduce sensitivity to noisy data points.\n\n\n\n\n\n\n\nNote\n\n\nA small k can be sensitive to noise. A large k can blur boundaries.\n\n\n\n\n\nviewof k_value = Inputs.range([1, 15], {step: 2, value: 3, label: \"Select k:\"});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe concept of Nearest Neighbor is extended to k-Nearest Neighbors, or k-NN. Instead of just picking one closest example, k-NN looks at the k closest examples. The label for the new data point is then decided by a majority vote among these k neighbors.\nThe value of k is a crucial choice. If k is 1, it’s just the basic NN. If k is larger, like 3 or 5, the classifier tends to be more robust to noisy training data. A single outlier won’t sway the decision as much. However, if k is too large, it might smooth out the decision boundaries too much, potentially ignoring local patterns. This interactive plot on the right lets you play with the k value. Observe how increasing k changes the colored decision regions and even the classification of our ‘New Point’ by making the boundaries smoother. For ECE students, this directly relates to parameter tuning in filters or control systems, where a single parameter can dramatically alter system behavior."
  },
  {
    "objectID": "cs231n/classification.html#the-challenge-choosing-hyperparameters",
    "href": "cs231n/classification.html#the-challenge-choosing-hyperparameters",
    "title": "Machine Learning",
    "section": "The Challenge: Choosing Hyperparameters",
    "text": "The Challenge: Choosing Hyperparameters\nHyperparameters are settings that control the learning process, not learned from data.\nFor k-NN, key hyperparameters include:\n\nThe value of k.\nThe distance metric (L1, L2, etc.).\n\n\n\n\n\n\n\nCaution\n\n\nProblem: If we choose k based on how well the model performs on the test data, we are essentially “cheating.” The model would seem to perform better than it would on truly unseen data. This is called overfitting to the test set.\n\n\n\n\nSo, we know we need to choose k, and we need to choose a distance metric. These are what we call hyperparameters. They are not learned directly from the training data, like the weights in a neural network; instead, they are set before the learning process begins and influence how the model learns.\nThe critical challenge here is figuring out the best values for these hyperparameters. It’s tempting to just try different k values and pick the one that gives the highest accuracy on our test dataset. However, this is a major pitfall in machine learning. If we do this, we are effectively using the test set to train our model – implicitly, by guiding our hyperparameter choices. This leads to an overly optimistic performance estimate. Our model would look great on that specific test set, but when deployed to truly new, unseen data, its performance would likely drop significantly. This is a form of overfitting to the test set, and it’s something we absolutely must avoid to build reliable ECE systems."
  },
  {
    "objectID": "cs231n/classification.html#data-splitting-the-holy-trinity",
    "href": "cs231n/classification.html#data-splitting-the-holy-trinity",
    "title": "Machine Learning",
    "section": "Data Splitting: The Holy Trinity",
    "text": "Data Splitting: The Holy Trinity\nTo correctly tune hyperparameters, we divide our data into three distinct sets:\n\n\n\nTraining Set (e.g., 60-80%):\n\nUsed to train the model (e.g., storage for k-NN).\nThe model learns from this data.\n\nValidation Set (e.g., 10-20%):\n\nA “fake test set” used to tune hyperparameters.\nProvides an unbiased estimate of model performance during development.\n\nTest Set (e.g., 10-20%):\n\nUsed for a single, final evaluation of the chosen model.\nProvides an unbiased estimate of generalization performance on truly unseen data.\n\n\n\n\n\n\n\n\n\n\n\nImportant\n\n\nGolden Rule: The Test Set is used only once, at the very end!\n\n\n\n\nTo address the hyperparameter challenge correctly, we partition our available dataset into three distinct, non-overlapping subsets: the training set, the validation set, and the test set.\nThe training set is the largest portion. This is the data our k-NN model “sees” and “memorizes.” All of the examples it will ever use for classification will come from here.\nThe validation set acts as our crucial bridge during development. It’s like a practice test. We use it to evaluate different hyperparameter settings (like varying k). By seeing how our model performs on the validation set with different k values, we can pick the best k without ever touching our final exam data. This gives us an honest estimate of how particular hyperparameter choices impact performance.\nFinally, the test set is the most sacred. This set is kept entirely separate and unseen throughout the entire development and tuning process. Only after we have finalized our model and chosen all hyperparameters based on the validation set, do we run our model once on the test set. This single evaluation provides the most reliable measure of our model’s performance on truly unseen data – its ability to generalize.\nThe Golden Rule for all ECE machine learning projects is: The Test Set is used only once, at the very end! Never touch it for tweaking anything during development."
  },
  {
    "objectID": "cs231n/classification.html#tuning-hyperparameters-with-a-validation-set",
    "href": "cs231n/classification.html#tuning-hyperparameters-with-a-validation-set",
    "title": "Machine Learning",
    "section": "Tuning Hyperparameters with a Validation Set",
    "text": "Tuning Hyperparameters with a Validation Set\nAn example with k\n# assume we have Xtr_rows, Ytr, Xte_rows, Yte (e.g., 50,000 CIFAR-10 images)\n# Xtr_rows is 50,000 x 3072 matrix (image data)\n# Ytr are the 50,000 corresponding labels\n\n# 1. Split training data into a smaller training set and a validation set\nXval_rows = Xtr_rows[:1000, :] # Take first 1000 for validation\nYval = Ytr[:1000]\nXtr_rows = Xtr_rows[1000:, :] # Use remaining 49,000 for actual training\nYtr = Ytr[1000:]\n\n# 2. Iterate through different k values and evaluate on the validation set\nvalidation_accuracies = []\nfor k in [1, 3, 5, 10, 20, 50, 100]: # Try various 'k' values\n\n    # (Imagine a NearestNeighbor class here with a 'train' and 'predict' method)\n    # nn = NearestNeighbor()\n    # nn.train(Xtr_rows, Ytr) # Model stores the (now smaller) training data\n\n    # Yval_predict = nn.predict(Xval_rows, k = k) # Predict on validation data for current 'k'\n    # acc = np.mean(Yval_predict == Yval) # Calculate accuracy\n\n    # --- Simplified for demonstration using placeholder values ---\n    # In a real scenario, the above commented lines would compute actual accuracy.\n    # For this interactive demo, assume dummy accuracy based on 'k'.\n    if k == 1: acc = 0.38\n    elif k == 3: acc = 0.42\n    elif k == 5: acc = 0.44\n    elif k == 10: acc = 0.41\n    elif k == 20: acc = 0.35\n    elif k == 50: acc = 0.28\n    elif k == 100: acc = 0.20\n    # --- End simplified part ---\n\n    print(f'k = {k}: accuracy = {acc:.4f}')\n    validation_accuracies.append((k, acc))\n\n# 3. Choose the 'k' that gave the best accuracy on the validation set\nbest_k = max(validation_accuracies, key=lambda item: item[1])[0]\nprint(f\"\\nBest k on validation set: {best_k}\")\n\nLet’s illustrate this process with a concrete example, just like you’d see in a typical ECE project dealing with sensor data or image classification.\nHere, we start with our full training data. Our first step is to carve out a small portion – say, the first 1000 data points – to serve as our validation set. The remaining data then becomes our actual training set for the model.\nNext, we loop through different possible values for k, our hyperparameter. For each k, we conceptually “train” our Nearest Neighbor model on the reduced training set and then evaluate its performance solely on the validation set. We calculate the accuracy and record it.\nAfter testing all our desired k values, we look at the validation_accuracies and pick the k that yielded the highest performance on that validation set. This chosen k is now our optimal hyperparameter. Importantly, we still haven’t touched the final test set. In an ECE context, this careful tuning allows us to develop robust systems that perform predictably in the field."
  },
  {
    "objectID": "cs231n/classification.html#when-validation-data-is-small-cross-validation",
    "href": "cs231n/classification.html#when-validation-data-is-small-cross-validation",
    "title": "Machine Learning",
    "section": "When Validation Data is Small: Cross-Validation",
    "text": "When Validation Data is Small: Cross-Validation\n\nProblem: If your dataset is small, a single validation split might not be representative (noisy estimate).\nSolution: Cross-validation provides a more robust estimate of performance for hyperparameter tuning.\n\n\n\nHow it works (e.g., 5-fold CV):\n\nDivide the training data into N equal “folds” (e.g., 5).\nIterate N times:\n\nUse N-1 folds for training.\nUse the remaining 1 fold for validation.\nRecord performance for the current hyperparameter setting.\n\nAverage the performance across all N iterations.\n\n\n\n\n\n\n\nTip\n\n\nCommon folds: 3, 5, or 10. More folds offer a better estimate but are more computationally expensive.\n\n\n\n\n\n\n\nWhat if your dataset is quite small? If you carve out a significant portion for a validation set, your remaining training set might be too small to adequately learn patterns. Conversely, if your validation set is tiny, its performance might be very noisy and not a reliable indicator of the true quality of your hyperparameters.\nThis is where cross-validation steps in. It’s a more sophisticated and computationally intensive technique, but it gives a much more reliable estimate of hyperparameter effectiveness.\nThe idea is that instead of just one split, you perform multiple splits. For instance, in 5-fold cross-validation, you divide your entire training data into five equal segments. Then, in five separate rounds: in each round you designate one segment as the validation fold and the other four as the training folds. You train and evaluate for each hyperparameter setting for each of these five configurations. Finally, you average the performance results from these five rounds. This averaging reduces the variance in your performance estimate, making it more trustworthy. For ECE applications with limited data, such as specialized sensor readings, cross-validation is invaluable for ensuring robust model selection."
  },
  {
    "objectID": "cs231n/classification.html#practical-considerations-for-data-splits",
    "href": "cs231n/classification.html#practical-considerations-for-data-splits",
    "title": "Machine Learning",
    "section": "Practical Considerations for Data Splits",
    "text": "Practical Considerations for Data Splits\n\nTypical Split Ratios:\n\nTraining: 50-90%\nValidation: 10-20%\nTest: 10-20%\n\nWhen to favor Cross-Validation over a single split:\n\nSmall dataset size (validation set would be too small).\nIf a very accurate estimate of hyperparameter performance is crucial.\n\n\n\n\n\n\n\n\nNote\n\n\nCross-validation is computationally more expensive. Choose between a single validation split and cross-validation based on dataset size, available computational resources, and the number of hyperparameters to tune.\n\n\n\n\nIn practice, deciding on the exact proportions for your training, validation, and test sets often comes down to the specifics of your project. As a general rule of thumb, you’ll reserve the largest portion, typically 50-90%, for training your model. The validation and test sets usually make up the remaining percentages equally.\nThe decision to use a single validation split versus more complex cross-validation hinges on a few factors: If your dataset is large, a single validation split is often sufficient and computationally cheaper. However, if your data is limited, or if you have a wide range of hyperparameters that could interact in complex ways, and particularly if you need a very reliable performance estimate before deploying an ECE system, then cross-validation is the safer bet. It minimizes the risk of making hyperparameter choices that only look good on one particular arbitrary split of data."
  },
  {
    "objectID": "cs231n/classification.html#pros-of-nearest-neighbor-classifiers-in-ece",
    "href": "cs231n/classification.html#pros-of-nearest-neighbor-classifiers-in-ece",
    "title": "Machine Learning",
    "section": "Pros of Nearest Neighbor Classifiers in ECE",
    "text": "Pros of Nearest Neighbor Classifiers in ECE\n\nSimplicity & Interpretability:\n\nEasy to understand and implement.\nCan provide insight into why a decision was made (by looking at neighbors).\nUseful for quick prototyping in ECE.\n\nNo Training Time:\n\nThe model merely stores the training data.\n“Lazy learning” – computation happens during inference.\nCan be beneficial for systems where initial training needs to be minimal or dynamic.\n\nNon-parametric:\n\nMakes no assumptions about the underlying data distribution.\nCan model complex decision boundaries.\n\n\n\nNow, let’s consider where Nearest Neighbor classifiers shine, especially from an ECE perspective.\nFirst, its simplicity is a huge plus. It’s easy to grasp, implement, and even explain. In engineering prototyping phases, a simple k-NN can provide a quick baseline without a lot of setup. Its interpretability is also valuable: if you want to know why an anomaly detector classified a sensor reading as ‘faulty’, you can inspect its nearest neighbors for clues.\nSecond, k-NN is a “lazy learner” – there’s virtually no explicit training phase. All it does during “training” is store the data. All the heavy lifting happens during prediction. This can be an advantage in scenarios where you need to quickly adapt to new data without retraining a complex model, or in resource-constrained embedded systems where intensive training might not be feasible on-device.\nFinally, k-NN is non-parametric. It doesn’t assume your data fits a nice linear or Gaussian distribution, which is often a strong and incorrect assumption for real-world ECE data, especially from diverse sensors. It can adapt to very complex data patterns, making it surprisingly powerful in certain contexts."
  },
  {
    "objectID": "cs231n/classification.html#cons-of-nearest-neighbor-classifiers-in-ece",
    "href": "cs231n/classification.html#cons-of-nearest-neighbor-classifiers-in-ece",
    "title": "Machine Learning",
    "section": "Cons of Nearest Neighbor Classifiers in ECE",
    "text": "Cons of Nearest Neighbor Classifiers in ECE\n\nHigh Test-Time Cost:\n\nClassifying a new point requires comparing it to all training points.\nCritical for ECE: Unsuitable for real-time applications or embedded systems with large datasets.\n\nStorage Requirements:\n\nMust store the entire training dataset.\nProblematic for memory-constrained devices (e.g., IoT, edge AI).\n\nCurse of Dimensionality:\n\nDistances become less meaningful in high-dimensional spaces.\nThis is a major issue for image data, as we’ll see next.\n\n\n\nDespite its advantages, k-NN has significant drawbacks that often make it impractical for many real-world ECE applications.\nThe biggest hurdle is its high test-time computational cost. Each time you want to classify a new data point, the system needs to compare it against potentially tens of thousands or even millions of stored training examples. For real-time applications like autonomous driving, satellite imagery analysis, or high-speed communication systems, this latency is unacceptable. You can’t afford to take seconds or minutes to classify a single new input.\nThis also relates directly to storage requirements. k-NN needs to keep the entire training data readily accessible. For large datasets, this can mean Gigabytes or Terabytes of stored data, which is simply not feasible for memory-constrained embedded systems or many edge AI devices, where flash memory and RAM are precious.\nFinally, and perhaps most critically for image data, we encounter the curse of dimensionality. As the number of features (like pixels in an image) increases, the concept of “distance” becomes less intuitive and less discriminative. All points tend to become equidistant from each other, making the “nearest neighbor” less meaningful. Let’s see this visually with images."
  },
  {
    "objectID": "cs231n/classification.html#the-curse-of-dimensionality-image-data",
    "href": "cs231n/classification.html#the-curse-of-dimensionality-image-data",
    "title": "Machine Learning",
    "section": "The Curse of Dimensionality & Image Data",
    "text": "The Curse of Dimensionality & Image Data\nWhy pixel-based distances fail for images\nPixel-based L1 or L2 distances often correlate more with background and general color distribution than with semantic content.\n\n\n\n\n\n\n\n\n\n\nWarning\n\n\nThe image on the left is the original. The three images next to it are all equally far away by L2 pixel distance. Notice: The L2 distance suggests they are equally similar, despite huge perceptual differences.\n\n\n\n\nA truck and a horse can be “closer” if they share a similar background or lighting.\nSemantic meaning (“what the image is”) is lost in raw pixel comparisons.\n\n\n\nHere’s a stark visual example of the curse of dimensionality affecting image classification. The image on the left is the original. The three images next to it – which depict a car, a deer, and a bird – are all equally distant from the original image based on a pixel-wise L2 distance calculation. This immediately tells you that raw pixel distances are a poor measure of perceptual or semantic similarity for images.\nYou can clearly see that, to human eyes, the car and the deer are not equally similar to the original image. This problem is pervasive: a truck might be computationally “closer” to a horse if both are photographed against a similar green field, rather than to another truck on a brown road. The raw pixel values prioritize low-level features like color and texture over high-level semantic content, which is what we actually want to classify. This highlights a fundamental limitation of simple distance metrics for rich, high-dimensional data like images."
  },
  {
    "objectID": "cs231n/classification.html#visualizing-failure-t-sne-embedding-of-cifar-10",
    "href": "cs231n/classification.html#visualizing-failure-t-sne-embedding-of-cifar-10",
    "title": "Machine Learning",
    "section": "Visualizing Failure: t-SNE Embedding of CIFAR-10",
    "text": "Visualizing Failure: t-SNE Embedding of CIFAR-10\nt-SNE (t-Distributed Stochastic Neighbor Embedding) helps visualize high-dimensional data in 2D or 3D, preserving local neighborhood structures.\n\n\n\n\n\n\n\nImportant\n\n\nObservation: Images nearby in this embedding (meaning they are pixel-wise similar) are clustered by background/color, not by their semantic class (e.g., “dog”, “cat”, “car”).\n\n\n\n\nThis image further drives home the point about pixel-based distances. Here, we see a t-SNE visualization of the CIFAR-10 dataset, which contains images from 10 different classes like cars, birds, cats, dogs. t-SNE is a technique that tries to map high-dimensional data into a lower-dimensional space (here, 2D) such that points that were close in the high-dimensional space remain close in the low-dimensional space.\nWhat we observe is revealing: images that are clustered together here are not grouped by their actual semantic content (e.g., all cars together, all birds together). Instead, they are primarily grouped by factors like their background color, lighting conditions, or overall color distribution. For instance, you might see dogs and frogs clustered together if they were all photographed on a white background. This clearly demonstrates that raw pixel values are insufficient for capturing the complex, abstract features needed for robust image classification. This is a critical insight for ECE students: the raw sensor data isn’t always the best representation for ML; feature engineering or learning better representations is key."
  },
  {
    "objectID": "cs231n/classification.html#towards-smarter-features-introduction-to-convolution",
    "href": "cs231n/classification.html#towards-smarter-features-introduction-to-convolution",
    "title": "Machine Learning",
    "section": "Towards Smarter Features: Introduction to Convolution",
    "text": "Towards Smarter Features: Introduction to Convolution\nWhy ECE needs better feature extraction for images\nThe failure of pixel-wise distances indicates a need for more robust feature representations. ECE Connection: Image processing often involves filtering — a form of feature extraction.\n\n\n\n\n\n\nNote\n\n\nConvolution is a fundamental operation for extracting meaningful features from image and signal data.\n\n\n\n\n\nHow it works:\n\nA kernel (small matrix/filter) slides over the input image.\nAt each position, it computes element-wise products and sums them.\nThis generates a new “feature map” highlighting specific patterns (edges, textures).\n\n\n\nviewof k11 = Inputs.range([-1, 1], {step: 0.1, value: 0, label: \"k[0,0]\"});\nviewof k12 = Inputs.range([-1, 1], {step: 0.1, value: -1, label: \"k[0,1]\"});\nviewof k13 = Inputs.range([-1, 1], {step: 0.1, value: 0, label: \"k[0,2]\"});\nviewof k21 = Inputs.range([-1, 1], {step: 0.1, value: -1, label: \"k[1,0]\"});\nviewof k22 = Inputs.range([-1, 1], {step: 0.1, value: 4, label: \"k[1,1]\"});\nviewof k23 = Inputs.range([-1, 1], {step: 0.1, value: -1, label: \"k[1,2]\"});\nviewof k31 = Inputs.range([-1, 1], {step: 0.1, value: 0, label: \"k[2,0]\"});\nviewof k32 = Inputs.range([-1, 1], {step: 0.1, value: -1, label: \"k[2,1]\"});\nviewof k33 = Inputs.range([-1, 1], {step: 0.1, value: 0, label: \"k[2,2]\"});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe limitations of pixel-wise distances for images highlight a major challenge, and it points us towards the need for more intelligent feature extraction. This is a concept ECE students are deeply familiar with through digital signal processing and filtering. Instead of just comparing raw pixel values, what if we could extract features that do capture semantic meaning or structural properties like edges, corners, or textures?\nThis is where convolution comes in. It’s a fundamental operation that applies a small filter, or kernel, across an input image. At each step, the kernel performs element-wise multiplication with the underlying image patch and sums the results, producing a single output value for that region. By sliding this kernel across the entire image, we generate a new “feature map” where each value represents the presence (or absence) of the pattern the kernel is designed to detect.\nOn the right, you can interact with a simple convolution. We have a basic input image. You can adjust the 3x3 kernel values using the sliders. As you change the kernel, observe how the “Convolved Output” image changes. Try to create kernels that detect edges or simply blur the image. For instance, a common edge detection kernel (like a sharpening filter) highlights changes. This interactive demo is a microcosm of how modern deep learning models learn to extract complex features from raw data."
  },
  {
    "objectID": "cs231n/classification.html#summary",
    "href": "cs231n/classification.html#summary",
    "title": "Machine Learning",
    "section": "Summary",
    "text": "Summary\n\nImage Classification: Assigning labels to images.\nNearest Neighbor (k-NN): Simple, non-parametric classifier that uses proximity in feature space. Key hyperparameters: k and distance metric.\nHyperparameter Tuning: Critical for generalizing to new data. Avoid test set overfitting.\nData Splits: Use Training, Validation, and Test sets. Test set is for final evaluation only.\nCross-Validation: Robust tuning for smaller datasets.\nk-NN Limitations for Images: High test-time cost, storage, and curse of dimensionality (pixel-wise distances are inadequate).\nFuture Direction: Need for better feature extraction (e.g., Convolution).\n\n\nTo quickly recap what we’ve covered:\n\nWe started with image classification as a core machine learning problem with direct applications in ECE.\nWe then explored the Nearest Neighbor (k-NN) classifier. It’s simple, non-parametric, and works by finding the closest training examples. We identified its key hyperparameters: k and the distance metric.\nA major focus was on the importance of hyperparameter tuning. We learned that improperly tuning these parameters can lead to test set overfitting, which gives a misleadingly optimistic view of our model’s performance.\nThe solution lies in proper data splitting into training, validation, and test sets. Remember the golden rule: the test set is reserved for a single, final evaluation.\nFor smaller datasets, we discussed cross-validation as a more robust method for hyperparameter tuning.\nFinally, we critically examined the limitations of k-NN, especially for high-dimensional data like images. Its high test-time cost, storage needs, and the significant impact of the curse of dimensionality make simple pixel-wise comparisons inadequate.\nThis limitation highlighted the need for more sophisticated feature extraction techniques, paving our way to future topics like convolutional neural networks, which are very relevant in ECE for processing signals and images effectively."
  },
  {
    "objectID": "cs231n/classification.html#applying-k-nn-in-practice-ece-guidelines",
    "href": "cs231n/classification.html#applying-k-nn-in-practice-ece-guidelines",
    "title": "Machine Learning",
    "section": "Applying k-NN in Practice (ECE Guidelines)",
    "text": "Applying k-NN in Practice (ECE Guidelines)\nIf you consider k-NN (perhaps not for images, but for other sensor data):\n\nPreprocess Data: Normalize features (e.g., zero mean, unit variance). Critical for distance-based methods.\nDimensionality Reduction: For very high-dimensional ECE data (e.g., spectral analysis, multi-sensor arrays), consider PCA, NCA, or Random Projections.\nData Splitting: Robustly split data into train/validation/test. Use cross-validation if data is sparse or hyperparameters are complex.\nHyperparameter Search: Systematically evaluate k and distance metrics on the validation set.\nAccelerate Retrieval: For speed-critical ECE applications, explore Approximate Nearest Neighbor (ANN) libraries like FLANN.\nFinal Evaluation: After selecting the best hyperparameters, evaluate the model once on the untouched test set. Report this performance.\n\n\nIf you ever find yourself needing to apply k-NN in a practical ECE scenario, perhaps not for complex images but for other types of sensor data or feature vectors, here are some guidelines:\n\nData Preprocessing: Always normalize your features. This means ensuring they have zero mean and unit variance. This prevents features with larger numerical ranges from disproportionately influencing the distance calculations. In ECE, scaling sensor readings is a common practice.\nDimensionality Reduction: If your ECE data is inherently high-dimensional – for example, signals from many different channels or spectral data – consider techniques like Principal Component Analysis (PCA) or Neighborhood Components Analysis (NCA). These can project your data into a lower-dimensional space, mitigating the curse of dimensionality and making k-NN more effective. This is akin to feature extraction in signal processing.\nRobust Data Splitting: As discussed, meticulously split your data. Use cross-validation when dealing with limited datasets or when you need highly reliable hyperparameter selection, which is often the case for safety-critical ECE systems.\nSystematic Hyperparameter Search: Don’t just guess. Exhaustively search for the best k and appropriate distance metric.\nAccelerate Retrieval: If your ECE application demands real-time responses despite the inherent slowness of k-NN at test time, look into libraries for Approximate Nearest Neighbor (ANN) search, like FLANN. These algorithms provide a trade-off between exactness and speed.\nFinal Evaluation: And always remember: one final, honest evaluation on your completely untouched test set to confirm your model’s real-world performance."
  },
  {
    "objectID": "cs231n/classification.html#further-reading",
    "href": "cs231n/classification.html#further-reading",
    "title": "Machine Learning",
    "section": "Further Reading",
    "text": "Further Reading\n\nA Few Useful Things to Know about Machine Learning\n\nEspecially section 6, but the whole paper is highly recommended.\n\nRecognizing and Learning Object Categories\n\nA short course from ICCV 2005 on object categorization.\n\n\n\nFor those eager to dive deeper, here are some excellent optional resources.\n“A Few Useful Things to Know about Machine Learning” is a classic paper that offers profound insights into the field, particularly relevant for understanding the broader context of what we’ve discussed today. Section 6 directly relates to hyperparameter tuning and model evaluation, but I encourage you to read the entire paper.\n“Recognizing and Learning Object Categories” provides a historical and foundational perspective on object classification, which is a key application area for many ECE disciplines, especially computer vision.\nThank you!"
  },
  {
    "objectID": "amli/04_00-04-classification.html#classification-vs.-regression-a-quick-review",
    "href": "amli/04_00-04-classification.html#classification-vs.-regression-a-quick-review",
    "title": "Machine Learning",
    "section": "Classification vs. Regression: A Quick Review",
    "text": "Classification vs. Regression: A Quick Review\n\n\nRegression: Predicting Continuous Values\n\n\nPredicts a numeric, continuous output.\nExamples: House prices, temperature, signal strength.\nEvaluation: Measures like Mean Squared Error (MSE).\n\n\nRecall that regression attempts to predict a continuous value. In this illustration, you can see a linear regression fitting a line to a dataset. We judge the quality of our regression by measuring the distance of the actual data from our prediction line. Metrics like Mean Squared Error and Root Mean Squared Error are common. In ECE, regression might be used for predicting sensor readings or component lifetimes.\n\n\nClassification: Predicting Categories\n\n\nPredicts a categorical, discrete output.\nExamples: Spam/Not Spam, Object presence (cat/dog), Fault detection.\nEvaluation: Focuses on correct vs. incorrect assignments.\n\n\nClassification models don’t predict a continuous value, but instead attempt to predict the “class” or category of a data point. Classification algorithms can distinguish between two states (binary classification), like spam or not. They can also determine the probability that a data point belongs to one of many classes (multi-class classification), such as identifying different types of modulation in a communication signal. The illustration shows separating red and blue data points using a clear boundary. In ECE, this could be identifying a defect on a PCB, classifying speech commands, or detecting anomalies in sensor data."
  },
  {
    "objectID": "amli/04_00-04-classification.html#what-does-it-mean-to-classify",
    "href": "amli/04_00-04-classification.html#what-does-it-mean-to-classify",
    "title": "Machine Learning",
    "section": "What Does It Mean to Classify?",
    "text": "What Does It Mean to Classify?\nClassification model results are often returned as a list of confidences for each class. The model predicts the probability a data point belongs to each class."
  },
  {
    "objectID": "amli/04_00-04-classification.html#understanding-classification-confidence",
    "href": "amli/04_00-04-classification.html#understanding-classification-confidence",
    "title": "Machine Learning",
    "section": "Understanding Classification Confidence",
    "text": "Understanding Classification Confidence\n\nExample Output:\n\nTiger: 0.96\nLion: 0.75\nCougar: 0.68\n\n\n\n\n\n\n\nTip\n\n\nIn ECE, such confidence levels are critical in systems like autonomous vehicles (identifying pedestrians with high certainty), medical image diagnosis, or anomaly detection in power grids.\n\n\n\n\nClassification models often return a list of confidences, indicating the predicted probability that a given data point belongs to each possible class. For example, when analyzing an image, the model might assign a 98% confidence to “tiger,” 1% to “lion,” and 1% to “cheetah.” These confidences are not always true probabilities without further transformation, like applying a softmax function. Your code then needs to interpret these predictions to make a final decision, perhaps by selecting the class with the highest confidence or applying a specific threshold."
  },
  {
    "objectID": "amli/04_00-04-classification.html#ambiguous-cases",
    "href": "amli/04_00-04-classification.html#ambiguous-cases",
    "title": "Machine Learning",
    "section": "Ambiguous Cases",
    "text": "Ambiguous Cases\n\n\nOrange: 0.97\nGrapefruit: 0.96\nSun: 0.45\n\n\nHere’s an example of a model returning confusing predictions for an image. The model is highly confident that the image contains either an orange or a grapefruit, with very similar confidence scores. What would you do in this situation? This highlights that sometimes ML models provide ambiguous results, and the system or human operator needs to handle such cases. For instance, in an automated fruit sorting system, this might lead to a re-scan or manual inspection."
  },
  {
    "objectID": "amli/04_00-04-classification.html#common-classification-models",
    "href": "amli/04_00-04-classification.html#common-classification-models",
    "title": "Machine Learning",
    "section": "Common Classification Models",
    "text": "Common Classification Models\n\nLogistic Regression:\n\nA variation of linear regression, uses a sigmoid function for binary outcomes. Simple and interpretable.\n\nNearest Neighbors:\n\nClassifies based on the majority class among its closest data points. Intuitive, but sensitive to local data structure.\n\nDecision Trees:\n\nTree-like structure where each node tests a feature, leading to a class decision. Good for interpretability.\n\nRandom Forests:\n\nAn ensemble of many decision trees, combining their predictions for robustness and better accuracy. Often very powerful.\n\nNaive Bayes:\n\nBased on Bayes’ theorem, assumes feature independence. Useful for text classification and spam detection.\n\nDeep Learning (Neural Networks):\n\nMulti-layered networks capable of learning complex patterns. Highly effective for image, speech, and sensor data classification.\n\n\n\nThere are numerous models that can be used for classification, each with different underlying mathematical principles and strengths. Some of the more common ones we’ll encounter are listed here. In ECE, the choice of model often depends on the type of data, computational constraints (especially for embedded systems), and real-time requirements. For example, simpler models might be preferred for low-power edge devices, while deep learning excels in complex image or signal processing tasks."
  },
  {
    "objectID": "amli/04_00-04-classification.html#the-machine-learning-classification-workflow",
    "href": "amli/04_00-04-classification.html#the-machine-learning-classification-workflow",
    "title": "Machine Learning",
    "section": "The Machine Learning Classification Workflow",
    "text": "The Machine Learning Classification Workflow\n\n\n\n\n\ngraph TD\n    A[\"Raw Sensor/System Data\"] --&gt; B{\"Data Preprocessing\"}\n    B --&gt; C[\"Feature Engineering/Extraction\"]\n    C --&gt; D{\"Split Data &lt;br&gt; (Training & Testing Sets)\"}\n    D -- Training Data --&gt; E[Choose & Train ML Model]\n    E -- & Evaluation --&gt; F[Model Evaluation & Tuning]\n    D -- Testing Data --&gt; F\n    F -- Performance OK? --&gt; G[Deploy Model to ECE System]\n    F -- Needs Improvement --&gt; E\n    G --&gt; H[New Live Data Input]\n    H --&gt; I[\"Real-time Prediction / Classification\"]\n    I --&gt; J[\"Action/Decision &lt;br&gt; (e.g., Control Signal, Alert)\"]\n\n    style A fill:#f9f,stroke:#333,stroke-width:2px;\n    style G fill:#bbf,stroke:#333,stroke-width:2px;\n    style J fill:#fcf,stroke:#333,stroke-width:2px;\n    style E fill:#ccf,stroke:#333,stroke-width:2px;\n    style F fill:#dfd,stroke:#333,stroke-width:2px;\n\n\n\n\n\n\n\nThis flowchart illustrates a typical machine learning classification workflow. Notice the continuous loop for model training and evaluation, highlighting that model development is an iterative process. For ECE applications, “Raw Sensor/System Data” could be anything from acceleration data in a drone to voltage readings in a power grid. “Feature Engineering” could involve extracting frequency components, statistical moments, or energy levels from time-series signals. “Deploy Model to ECE System” represents integrating the trained model into hardware, software, or an embedded system, where it performs “Real-time Prediction” and drives “Actions,” such as adjusting a motor’s speed or triggering a safety shutdown."
  },
  {
    "objectID": "amli/04_00-04-classification.html#classification-model-performance",
    "href": "amli/04_00-04-classification.html#classification-model-performance",
    "title": "Machine Learning",
    "section": "Classification Model Performance",
    "text": "Classification Model Performance\nUnlike regression, we can’t measure continuous “distance” to evaluate classification. Instead, we count correct vs. incorrect predictions. These counts form the basis for various performance metrics.\n\nAs mentioned, determining the performance of a regression model involves measuring the distance between continuous values. In classification, we’re dealing with discrete categories, so we can’t use the same “distance” concept. Instead, we focus on how many predictions the model got right versus wrong. These counts allow us to define metrics that robustly evaluate model quality. Understanding these metrics is crucial in ECE, especially when a false positive or false negative can have significant consequences."
  },
  {
    "objectID": "amli/04_00-04-classification.html#the-confusion-matrix",
    "href": "amli/04_00-04-classification.html#the-confusion-matrix",
    "title": "Machine Learning",
    "section": "The Confusion Matrix",
    "text": "The Confusion Matrix\n\n\nTrue Positive (TP): Model predicted positive, was actually positive.\nFalse Positive (FP): Model predicted positive, was actually negative (Type I error).\nFalse Negative (FN): Model predicted negative, was actually positive (Type II error).\nTrue Negative (TN): Model predicted negative, was actually negative.\n\n\nMost of the performance measures we’ll discuss are derived from the confusion matrix. For simplicity, we often analyze binary classification or evaluate a single class as “positive” against all others. For instance, in a system detecting defects (positive), a True Positive means the system correctly identified a defect. A False Positive means it flagged a non-defect as a defect (a false alarm). A False Negative means it missed a defect (a critical failure). A True Negative means it correctly identified a non-defect. The implications of FP vs. FN can vary greatly across ECE applications; e.g., in medical diagnosis, FN is often more critical than FP, while in spam detection, FP might be more annoying than FN."
  },
  {
    "objectID": "amli/04_00-04-classification.html#accuracy",
    "href": "amli/04_00-04-classification.html#accuracy",
    "title": "Machine Learning",
    "section": "Accuracy",
    "text": "Accuracy\n\nThe fraction of all predictions that a classification model got right.\nSimply the sum of True Positives and True Negatives, divided by the total.\n\n\\[ \\text{Accuracy} = \\frac{\\text{TP} + \\text{TN}}{\\text{TP} + \\text{TN} + \\text{FP} + \\text{FN}} \\]\n\n\nAccuracy seems like a straightforward measure, but it can be misleading, especially with imbalanced datasets. Imagine a system trying to detect a rare fault in an industrial machine that occurs only 1% of the time. If our model simply predicts “no fault” all the time, it would achieve 99% accuracy, but it would completely fail to detect any actual faults. In ECE, relying solely on accuracy for rare event detection, like critical system failures or cybersecurity intrusions, can be very dangerous. This is why we need more nuanced metrics."
  },
  {
    "objectID": "amli/04_00-04-classification.html#motivation-for-precision",
    "href": "amli/04_00-04-classification.html#motivation-for-precision",
    "title": "Machine Learning",
    "section": "Motivation for Precision",
    "text": "Motivation for Precision\nWhen the model predicted positive, how often was it correct?\nWhat is the probability that a detected anomaly in our sensor data is an actual* anomaly, given that our model flagged it?*\n\nIn many ECE scenarios, precision is crucial. For example, in a robotic arm that picks up defective items, high precision means fewer good items are accidentally discarded (fewer false positives). While accuracy might be high, if the FP rate is unacceptably high, it leads to waste or unnecessary actions. Precision directly answers the question: “Of all the times the model said ‘yes,’ how many times was it actually ‘yes’?”"
  },
  {
    "objectID": "amli/04_00-04-classification.html#precision",
    "href": "amli/04_00-04-classification.html#precision",
    "title": "Machine Learning",
    "section": "Precision",
    "text": "Precision\n\nThe fraction of correct positive predictions out of all positive predictions made by the model.\n\n\\[ \\text{Precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}} \\]\n\n\nPrecision focuses on the accuracy of positive predictions. A high precision indicates a low rate of false positives. In ECE, high precision is desirable in applications where false alarms are costly or disruptive. Consider a system for chip manufacturing QA: discarding a good chip because it was misclassified as defective is costly. Here, precision helps minimize such errors. Precision of 1 means every time the model said “positive,” it was truly positive, but it doesn’t tell us if it missed any actual positives."
  },
  {
    "objectID": "amli/04_00-04-classification.html#motivation-for-recall",
    "href": "amli/04_00-04-classification.html#motivation-for-recall",
    "title": "Machine Learning",
    "section": "Motivation for Recall",
    "text": "Motivation for Recall\nOut of all the actual positive cases, how many did the model correctly identify?\nWhat is the probability that our model will detect a ‘critical’ electromagnetic interference event, given that it actually occurred?\n\nRecall addresses a different but equally important question: “Of all the actual ‘yes’ cases, how many did the model find?” In safety-critical ECE applications, missing an actual positive (a false negative) can be devastating. This is where recall shines."
  },
  {
    "objectID": "amli/04_00-04-classification.html#recall",
    "href": "amli/04_00-04-classification.html#recall",
    "title": "Machine Learning",
    "section": "Recall",
    "text": "Recall\n\nThe fraction of correct positive predictions out of all actual positive cases.\n\n\\[ \\text{Recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} \\]\n\n\nRecall, also known as sensitivity or true positive rate, is about how complete the model’s positive detections are. A high recall means a low rate of false negatives. In ECE, high recall is crucial for applications where missing a positive event is more detrimental than a false alarm. Examples include detecting equipment failures, security breaches, or health monitoring systems where failing to detect a critical condition is unacceptable. A recall of 1 means the model caught every single positive instance, but it doesn’t say anything about how many false positives it had along the way."
  },
  {
    "objectID": "amli/04_00-04-classification.html#precision-vs.-recall-a-trade-off",
    "href": "amli/04_00-04-classification.html#precision-vs.-recall-a-trade-off",
    "title": "Machine Learning",
    "section": "Precision vs. Recall: A Trade-Off",
    "text": "Precision vs. Recall: A Trade-Off\n\n\nIncreasing one often decreases the other.\nThe optimal balance depends on the application’s cost of FP vs. FN.\n\n\nBalancing precision and recall is often a “tug-of-war.” If you want to increase recall (catch more positives), you might lower your decision threshold, potentially increasing false positives and thus lowering precision. Conversely, if you want to increase precision (be more certain of your positives), you’d raise the threshold, which might cause you to miss some actual positives, lowering recall. Finding the optimal point where these two metrics are acceptable for your specific ECE application is critical. For instance, in a fire detection system, high recall is paramount, even if it means some false alarms (lower precision)."
  },
  {
    "objectID": "amli/04_00-04-classification.html#f1-score",
    "href": "amli/04_00-04-classification.html#f1-score",
    "title": "Machine Learning",
    "section": "F1 Score",
    "text": "F1 Score\n\nThe harmonic mean of precision and recall.\nHigh F1 indicates both precision and recall are high.\n\n\\[ F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\]\n\n\nThe F1 score provides a single metric that balances both precision and recall. It’s particularly useful when you have an uneven class distribution, as it penalizes models that favor one metric over the other. The harmonic mean gives more weight to lower values, meaning a model needs both good precision and good recall to achieve a high F1 score. It’s a common metric when you need a general measure of a model’s effectiveness in ECE applications where both missing events and false alarms are important to manage."
  },
  {
    "objectID": "amli/04_00-04-classification.html#f1-score-simplified",
    "href": "amli/04_00-04-classification.html#f1-score-simplified",
    "title": "Machine Learning",
    "section": "F1 Score: Simplified",
    "text": "F1 Score: Simplified\nThe F1 formula can be reduced to:\n\\[ F_1 = \\frac{2 \\cdot \\text{TP}}{2 \\cdot \\text{TP} + \\text{FP} + \\text{FN}} \\]\n\n\nThis simplified form of the F1 score can be directly calculated from the True Positives, False Positives, and False Negatives, making it convenient for quick computations."
  },
  {
    "objectID": "amli/04_00-04-classification.html#interactive-metric-calculator",
    "href": "amli/04_00-04-classification.html#interactive-metric-calculator",
    "title": "Machine Learning",
    "section": "Interactive Metric Calculator",
    "text": "Interactive Metric Calculator\nAdjust the True Positives, False Positives, False Negatives, and True Negatives to see how Accuracy, Precision, Recall, and F1 Score change.\n\nviewof tp_val = Inputs.range([0, 100], {value: 1, step: 1, label: \"True Positives (TP)\"});\nviewof fp_val = Inputs.range([0, 100], {value: 1, step: 1, label: \"False Positives (FP)\"});\nviewof fn_val = Inputs.range([0, 100], {value: 8, step: 1, label: \"False Negatives (FN)\"});\nviewof tn_val = Inputs.range([0, 100], {value: 90, step: 1, label: \"True Negatives (TN)\"});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis interactive tool allows you to directly manipulate the components of a confusion matrix and observe their impact on the key classification metrics. By adjusting the sliders, you can simulate different model behaviors and gain an intuitive understanding of how True Positives, False Positives, False Negatives, and True Negatives affect Accuracy, Precision, Recall, and the F1 Score. This hands-on experience is crucial for ECE students to grasp the trade-offs involved in designing and evaluating ML systems."
  },
  {
    "objectID": "amli/04_00-04-classification.html#which-metric-do-i-use",
    "href": "amli/04_00-04-classification.html#which-metric-do-i-use",
    "title": "Machine Learning",
    "section": "Which Metric Do I Use?",
    "text": "Which Metric Do I Use?\n\n\n\n\n\n\nNote\n\n\nThe answer is always: it depends on your specific ECE application!\n\n\n\n\nAccuracy: Rarely a sufficient standalone metric, especially with imbalanced classes.\nPrecision: Crucial when False Positives are costly (e.g., discarding good products in QA, false alarms in security).\nRecall: Critical when False Negatives are costly (e.g., missing a fault in critical infrastructure, failing to detect a disease).\nF1 Score: A good general measure when you need to balance both precision and recall, particularly with imbalanced datasets.\n\n\nJust remember, there’s no single “best” metric. In ECE, the choice depends heavily on the cost associated with different types of errors. In some contexts, a false positive might just be an annoyance, while in others (like a medical diagnosis or a safety system), it could lead to significant financial loss or danger. Conversely, a false negative in a critical fault detection system could lead to catastrophic equipment failure. Always consider the real-world consequences of your model’s mistakes when choosing which metrics to prioritize. Later, we’ll discuss more advanced measures and graphical tools that help provide a more complete picture."
  },
  {
    "objectID": "amli/04_00-04-classification.html#confusion-matrix-example",
    "href": "amli/04_00-04-classification.html#confusion-matrix-example",
    "title": "Machine Learning",
    "section": "Confusion Matrix Example",
    "text": "Confusion Matrix Example\nScenario: A model predicts if a tumor is malignant.\n(Positive Class: Malignant, Negative Class: Benign)\n\n\nLet’s practice calculating these metrics using a concrete example. Focus on a model designed to predict if a tumor is malignant. A “positive” outcome from the model means it predicts the tumor is malignant. We will walk through the components of the confusion matrix again with this scenario in mind. Remember:\n\nTrue Positive: Model said malignant, and it was malignant.\nTrue Negative: Model said benign, and it was benign.\nFalse Positive: Model said malignant, but it was benign (Type I error - false alarm, patient undergoes unnecessary procedure).\nFalse Negative: Model said benign, but it was malignant (Type II error - dangerous miss, patient doesn’t get treatment)."
  },
  {
    "objectID": "amli/04_00-04-classification.html#confusion-matrix-example-data",
    "href": "amli/04_00-04-classification.html#confusion-matrix-example-data",
    "title": "Machine Learning",
    "section": "Confusion Matrix Example: Data",
    "text": "Confusion Matrix Example: Data\nModel to predict if a tumor is malignant\n\nGiven these values:\n\nTP = 1\nFP = 1\nFN = 8\nTN = 90"
  },
  {
    "objectID": "amli/04_00-04-classification.html#solution-accuracy",
    "href": "amli/04_00-04-classification.html#solution-accuracy",
    "title": "Machine Learning",
    "section": "Solution: Accuracy",
    "text": "Solution: Accuracy\n\\[\\text{Accuracy} = \\frac{1 + 90}{1 + 1 + 8 + 90} = \\frac{91}{100} = 0.91\\]\n\n\nAs you can see, the accuracy is 91%. This looks quite good on its own. However, let’s see how the other metrics inform our understanding of this model. Remember our earlier discussion about accuracy with imbalanced datasets and the potential for false confidence."
  },
  {
    "objectID": "amli/04_00-04-classification.html#solution-precision",
    "href": "amli/04_00-04-classification.html#solution-precision",
    "title": "Machine Learning",
    "section": "Solution: Precision",
    "text": "Solution: Precision\n\\[\\text{Precision} = \\frac{1}{1 + 1} = \\frac{1}{2} = 0.50\\]\n\n\nThe precision is 0.50, or 50%. This means that when the model predicts a tumor is malignant, it’s only correct half the time. While the overall accuracy was high, the model frequently gives false alarms for malignancy. This would lead to many patients undergoing potentially stressful and invasive follow-up tests unnecessarily."
  },
  {
    "objectID": "amli/04_00-04-classification.html#solution-recall",
    "href": "amli/04_00-04-classification.html#solution-recall",
    "title": "Machine Learning",
    "section": "Solution: Recall",
    "text": "Solution: Recall\n\\[\\text{Recall} = \\frac{1}{1 + 8} = \\frac{1}{9} \\approx 0.11\\]\n\n\nThe recall is approximately 0.11, or 11%. This is a very low recall score. It means the model only correctly identifies about 11% of the actual malignant tumors. In this medical context, missing 89% of malignant tumors (false negatives) is a severe problem. This highlights a critical failure of the model despite its seemingly high accuracy. Without surgical intervention, the consequences of a malignant tumor would be dire."
  },
  {
    "objectID": "amli/04_00-04-classification.html#solution-f1-score",
    "href": "amli/04_00-04-classification.html#solution-f1-score",
    "title": "Machine Learning",
    "section": "Solution: F1 Score",
    "text": "Solution: F1 Score\n\\[ F_1 = \\frac{2 \\cdot 0.50 \\cdot 0.11}{0.50 + 0.11} = \\frac{0.11}{0.61} \\approx 0.18 \\]\nOr, using the simplified formula:\n\\[ F_1 = \\frac{2 \\cdot 1}{2 \\cdot 1 + 1 + 8} = \\frac{2}{11} \\approx 0.18 \\]"
  },
  {
    "objectID": "amli/04_00-04-classification.html#solution-f1-score-1",
    "href": "amli/04_00-04-classification.html#solution-f1-score-1",
    "title": "Machine Learning",
    "section": "Solution: F1 Score",
    "text": "Solution: F1 Score\n\n\nThe F1 score is very low, approximately 0.18. This low F1 score correctly reflects the poor performance of the model by penalizing the low recall, despite the relatively high precision (0.50) and high accuracy (0.91). This example vividly demonstrates why looking at all metrics, especially F1, is crucial and why relying solely on accuracy can be misleading in applications where class imbalance or the cost of different error types is significant."
  },
  {
    "objectID": "amli/04_00-04-classification.html#weather-prediction",
    "href": "amli/04_00-04-classification.html#weather-prediction",
    "title": "Machine Learning",
    "section": "Weather Prediction",
    "text": "Weather Prediction\nScenario: Predict “Rain” or “No Rain”.\n\nCreate a Confusion Matrix from this data.\n\nHere’s another chance to practice. Given this weather prediction scenario for a week, where ‘R’ denotes Rain and ‘NR’ denotes No Rain, first, construct the confusion matrix based on the model’s predictions versus the actual weather."
  },
  {
    "objectID": "amli/04_00-04-classification.html#your-turn-calculate-metrics",
    "href": "amli/04_00-04-classification.html#your-turn-calculate-metrics",
    "title": "Machine Learning",
    "section": "Your Turn: Calculate Metrics",
    "text": "Your Turn: Calculate Metrics\nNow that you have constructed the confusion matrix for the weather prediction:\n\nAccuracy = ?\nPrecision = ?\nRecall = ?\nF1 Score = ?\n\n\nOnce you’ve built the confusion matrix, calculate the Accuracy, Precision, Recall, and F1 Score. Take a few moments to work through these."
  },
  {
    "objectID": "amli/04_00-04-classification.html#solution-weather-prediction",
    "href": "amli/04_00-04-classification.html#solution-weather-prediction",
    "title": "Machine Learning",
    "section": "Solution: Weather Prediction",
    "text": "Solution: Weather Prediction"
  },
  {
    "objectID": "amli/04_00-04-classification.html#solution-weather-prediction-1",
    "href": "amli/04_00-04-classification.html#solution-weather-prediction-1",
    "title": "Machine Learning",
    "section": "Solution: Weather Prediction",
    "text": "Solution: Weather Prediction\nConfusion Matrix:\n\nTP (Actual Rain, Predicted Rain): 2\nFP (Actual No Rain, Predicted Rain): 2\nFN (Actual Rain, Predicted No Rain): 2\nTN (Actual No Rain, Predicted No Rain): 1\n\nMetrics:\n\nAccuracy: (2+1) / (2+2+2+1) = 3/7\nPrecision: 2 / (2+2) = 2/4\nRecall: 2 / (2+2) = 2/4\nF1 Score: 2/4\n\n\nHere are the solutions. This example shows a more balanced performance compared to the tumor prediction model, where all metrics are relatively consistent around two-thirds. This indicates a more even-handed performance from the classifier."
  },
  {
    "objectID": "amli/04_00-04-classification.html#graphical-measurements-for-classification",
    "href": "amli/04_00-04-classification.html#graphical-measurements-for-classification",
    "title": "Machine Learning",
    "section": "Graphical Measurements for Classification",
    "text": "Graphical Measurements for Classification\nBeyond single scalar metrics, graphical tools offer deeper insights into model performance across different decision thresholds."
  },
  {
    "objectID": "amli/04_00-04-classification.html#precision-vs.-recall-curve",
    "href": "amli/04_00-04-classification.html#precision-vs.-recall-curve",
    "title": "Machine Learning",
    "section": "Precision vs. Recall Curve",
    "text": "Precision vs. Recall Curve\n\n\nPlots Precision against Recall for different threshold values.\nHelps select an optimal operating point based on FP/FN costs.\n\n\nThe Precision-Recall curve visualizes the trade-off. Each point on the curve represents the precision and recall achievable at a specific classification threshold. For example, if your ECE system needs extremely high precision (e.g., avoiding false alarms for a critical alert), you might choose an operating point far to the right on the curve, even if it means lower recall. Conversely, if high recall is paramount (e.g., never missing a faulty component), you would choose a point further to the left, accepting more false positives. This curve is especially useful when one class is significantly rarer than the other, and helps you tune your ML model for the specific operational constraints of your ECE application."
  },
  {
    "objectID": "amli/04_00-04-classification.html#receiver-operating-characteristic-roc-curve",
    "href": "amli/04_00-04-classification.html#receiver-operating-characteristic-roc-curve",
    "title": "Machine Learning",
    "section": "Receiver Operating Characteristic (ROC) Curve",
    "text": "Receiver Operating Characteristic (ROC) Curve\n\n\nPlots True Positive Rate (Recall) against False Positive Rate.\nHelps compare models across all possible thresholds.\n\n\nAnother powerful graphical tool is the ROC curve. It plots the True Positive Rate, which is identical to Recall, against the False Positive Rate for various sensitivity thresholds. The False Positive Rate quantifies how many negative instances the model incorrectly classified as positive. A perfect classifier would reach the top-left corner (100% TPR, 0% FPR). The dotted line represents a random classifier."
  },
  {
    "objectID": "amli/04_00-04-classification.html#roc-curve-true-positive-rate-tpr-recall",
    "href": "amli/04_00-04-classification.html#roc-curve-true-positive-rate-tpr-recall",
    "title": "Machine Learning",
    "section": "ROC Curve: True Positive Rate (TPR) / Recall",
    "text": "ROC Curve: True Positive Rate (TPR) / Recall\n\\[ \\text{TPR (Recall)} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} \\]\n\n\nThe Y-axis of the ROC curve is the True Positive Rate, which is simply our familiar Recall. It tells us, out of all actual positive cases, what fraction the model correctly identified."
  },
  {
    "objectID": "amli/04_00-04-classification.html#roc-curve-false-positive-rate-fpr",
    "href": "amli/04_00-04-classification.html#roc-curve-false-positive-rate-fpr",
    "title": "Machine Learning",
    "section": "ROC Curve: False Positive Rate (FPR)",
    "text": "ROC Curve: False Positive Rate (FPR)\n\\[ \\text{FPR} = \\frac{\\text{FP}}{\\text{FP} + \\text{TN}} \\]\n\n\nFPR is 1 minus the True Negative Rate (TNR, Specificity).\nMeasures how many actual negative examples were falsely predicted as positive.\n\n\nThe X-axis of the ROC curve is the False Positive Rate. This is 1 minus Specificity, where Specificity is the True Negative Rate. FPR indicates the proportion of actual negative cases that were incorrectly classified as positive. So, if we have a system for detecting anomalies, a high FPR means we get a lot of false alarms from normal operations."
  },
  {
    "objectID": "amli/04_00-04-classification.html#interpreting-the-roc-curve",
    "href": "amli/04_00-04-classification.html#interpreting-the-roc-curve",
    "title": "Machine Learning",
    "section": "Interpreting the ROC Curve",
    "text": "Interpreting the ROC Curve\n\n\nTPR (Y-axis): Proportion of actual positives correctly identified.\nFPR (X-axis): Proportion of actual negatives incorrectly identified as positive.\nDotted Line: Represents a random classifier (AUC = 0.5).\nArea Under Curve (AUC): Single scalar metric to summarize the curve.\n\nAUC near 1.0 indicates excellent discriminative power.\nAUC near 0.5 suggests poor or random classification.\n\n\n\nAn ideal ROC curve hugs the top-left corner, signifying high TPR and low FPR across various thresholds. The Area Under the Curve (AUC) provides a single value summary of the model’s performance across all possible classification thresholds. An AUC of 1.0 is a perfect classifier, while 0.5 is no better than random guessing. AUC is a robust metric for comparing different models, especially when the class distribution is balanced or when the cost of FP and FN is similar. In ECE, AUC is commonly used for evaluating diagnostic systems, anomaly detection, and classification problems where overall discriminative ability is key, regardless of a specific operating point initially."
  },
  {
    "objectID": "amli/04_00-04-classification.html#binary-classification-two-outcomes",
    "href": "amli/04_00-04-classification.html#binary-classification-two-outcomes",
    "title": "Machine Learning",
    "section": "Binary Classification: Two Outcomes",
    "text": "Binary Classification: Two Outcomes\n\nYes or No\nPredicts one of two discrete values or states.\nCommonly encoded as 0 or 1.\nExamples:\n\nSpam / Not Spam\nFault / No Fault\nSignal Present / Signal Absent\nPass / Fail for product testing\n\n\n\nBinary classification problems involve predicting one of only two possible outcomes. These outcomes are often represented as a positive class (e.g., 1) and a negative class (e.g., 0). In ECE, binary classification is ubiquitous. Think of a sensor determining if a component’s temperature is “over threshold” or “normal,” a communications system detecting if a packet contains “error” or “no error,” or an embedded system classifying a touch input as “press” or “release.”"
  },
  {
    "objectID": "amli/04_00-04-classification.html#binary-classification-common-models",
    "href": "amli/04_00-04-classification.html#binary-classification-common-models",
    "title": "Machine Learning",
    "section": "Binary Classification: Common Models",
    "text": "Binary Classification: Common Models\n\nLogistic Regression: Transforms linear regression output into a probability (0-1).\nDecision Trees & Random Forests: Can naturally split data into two categories.\nSupport Vector Machines (SVM): Finds an optimal hyperplane to separate classes with the largest margin.\nBayesian Networks: Probabilistic graphical models used for classification.\nNeural Networks: Highly versatile, learn complex non-linear boundaries.\n\n\nMany different machine learning models can be adapted for binary classification. Each has its own strengths and weaknesses regarding computational complexity, interpretability, and ability to handle different data distributions. We will explore several of these throughout the course. For an ECE context, the choice often depends on the available computational resources on a chip or embedded system, the latency requirements, and the complexity of the decision boundary needed."
  },
  {
    "objectID": "amli/04_00-04-classification.html#binary-classification-logistic-regression-example",
    "href": "amli/04_00-04-classification.html#binary-classification-logistic-regression-example",
    "title": "Machine Learning",
    "section": "Binary Classification: Logistic Regression Example",
    "text": "Binary Classification: Logistic Regression Example\n\nClassification\nFinds a logistic function to separate two classes.\nOutputs a probability value (0-1) which is then thresholded for classification.\nRelatively easy to interpret.\n\n\nIn the upcoming lab, we will build a logistic regression model. This algorithm is particularly useful for binary classification. It applies a sigmoid function to the output of a linear model, squeezing the result into a range between 0 and 1, which can be interpreted as a probability. You can then set a threshold (e.g., 0.5) to classify points. While straightforward, it performs best when the data is linearly separable or can be made so with feature engineering. This is a good starting point for many ECE tasks due to its computational efficiency."
  },
  {
    "objectID": "amli/04_00-04-classification.html#lab-preview-fruit-classification",
    "href": "amli/04_00-04-classification.html#lab-preview-fruit-classification",
    "title": "Machine Learning",
    "section": "Lab Preview: Fruit Classification",
    "text": "Lab Preview: Fruit Classification\n\nFruit Classification\nObjective: Differentiate between oranges and grapefruit.\nDataset: Contains features like weight, size, and color.\nModel: We will build a logistic regression model.\n\n\nIn our hands-on lab, you’ll tackle a binary classification problem: distinguishing between oranges and grapefruits. We’ll utilize a dataset rich with physical characteristics like weight, size, and color. This is a practical example of how classification can be used in areas like automated sorting systems in agriculture or quality control in food processing, which are relevant to ECE."
  },
  {
    "objectID": "amli/04_00-04-classification.html#lab-preview-hyperparameter-tuning-with-grid-search",
    "href": "amli/04_00-04-classification.html#lab-preview-hyperparameter-tuning-with-grid-search",
    "title": "Machine Learning",
    "section": "Lab Preview: Hyperparameter Tuning with Grid Search",
    "text": "Lab Preview: Hyperparameter Tuning with Grid Search\nsearch = GridSearchCV(model, {\n  'learning_rate': [1e-3, 1e-4],\n  'max_iter': [10000, 15000],\n  'C': 1,\n})\n\nGrid Search: Systematically explores a combination of hyperparameters.\nHelps find the best parameter settings for your model.\nCan be computationally intensive, especially with many parameters.\n\n\nIn the lab, you’ll also encounter GridSearchCV, a powerful technique for hyperparameter tuning. Instead of manually trying different learning_rate or max_iter values, Grid Search automates this process. It tries every possible combination of the provided hyperparameter values, trains a model for each combination, and evaluates its performance to find the optimal set. While incredibly useful for robust model development, remember that the number of combinations grows factorially, which can make it time-consuming, especially for complex ECE models running on limited embedded hardware."
  },
  {
    "objectID": "amli/04_00-04-classification.html#lab-preview-confusion-matrix-generation",
    "href": "amli/04_00-04-classification.html#lab-preview-confusion-matrix-generation",
    "title": "Machine Learning",
    "section": "Lab Preview: Confusion Matrix Generation",
    "text": "Lab Preview: Confusion Matrix Generation\n\nConfusion Matrix\nYou will generate your first confusion matrix.\nVisualizing TP, FP, FN, TN for your fruit classifier.\n\n\nFinally, the lab will guide you through creating your first confusion matrix, just like we discussed earlier. This will allow you to see the real-world performance of your logistic regression model on the fruit classification task and apply the metrics we’ve learned today."
  },
  {
    "objectID": "amli/04_00-04-classification.html#your-turn-binary-classification-lab",
    "href": "amli/04_00-04-classification.html#your-turn-binary-classification-lab",
    "title": "Machine Learning",
    "section": "Your Turn: Binary Classification Lab",
    "text": "Your Turn: Binary Classification Lab\nLet’s apply these concepts and build a binary classifier!\n\nNow it’s time to put what you’ve learned into practice! Head over to the lab environment to begin working on the binary classification exercise."
  },
  {
    "objectID": "amli/04_00-04-classification.html#multiclass-classification-many-outcomes",
    "href": "amli/04_00-04-classification.html#multiclass-classification-many-outcomes",
    "title": "Machine Learning",
    "section": "Multiclass Classification: Many Outcomes",
    "text": "Multiclass Classification: Many Outcomes\n\ncenter\nClassification problems with more than two classes.\nExamples:\n\nDigit recognition (0-9)\nSpeech command recognition (e.g., “activate,” “mute,” “volume up”)\nModulation scheme identification (e.g., BPSK, QPSK, 16-QAM)\nComponent type classification\n\n\n\n“Multiclass classification” refers to problems where a data point needs to be assigned to one of several possible categories. This is distinct from binary classification, which handles only two categories. In ECE, multi-class problems are prevalent: classifying different types of electrical faults, recognizing multiple speech commands for a microcontroller, identifying different types of cybersecurity attacks, or classifying different materials using sensor data."
  },
  {
    "objectID": "amli/04_00-04-classification.html#multiclass-strategies-one-vs-all-ova-one-vs-one-ovo",
    "href": "amli/04_00-04-classification.html#multiclass-strategies-one-vs-all-ova-one-vs-one-ovo",
    "title": "Machine Learning",
    "section": "Multiclass Strategies: One-vs-All (OvA) & One-vs-One (OvO)",
    "text": "Multiclass Strategies: One-vs-All (OvA) & One-vs-One (OvO)\n\nOne-vs-All (OvA):\n\nTrains k binary classifiers for k classes.\nEach classifier distinguishes one class from all others.\nFinal prediction is the class with the highest confidence.\n\nOne-vs-One (OvO):\n\nTrains k * (k-1) / 2 binary classifiers.\nEach classifier distinguishes one class from another specific class.\nFinal prediction is derived by a voting scheme among classifiers.\n\n\n\nMany binary classification algorithms can be extended to handle multi-class problems using strategies like One-vs-All (OvA) or One-vs-One (OvO). OvA is simpler: for each class, you train a binary classifier to decide if an instance belongs to that specific class or any other class. OvO is more complex, training a binary classifier for every unique pair of classes, and then aggregating their votes. While often hidden from the user in modern ML libraries, understanding these strategies helps in debugging and selecting appropriate models, especially in resource-constrained ECE systems where computational efficiency matters. Some models, like Decision Trees, naturally handle multiple classes without needing these decomposition strategies."
  },
  {
    "objectID": "amli/04_00-04-classification.html#lab-preview-the-iris-dataset",
    "href": "amli/04_00-04-classification.html#lab-preview-the-iris-dataset",
    "title": "Machine Learning",
    "section": "Lab Preview: The Iris Dataset",
    "text": "Lab Preview: The Iris Dataset\n\ncenter\nClassic ML Dataset: Widely used for multiclass classification.\nFeatures: Sepal length, sepal width, petal length, petal width.\nTarget: Three species of Iris flowers (Setosa, Versicolor, Virginica).\n\n\nFor our multiclass classification lab, we’ll use the famous Iris dataset. This dataset is a cornerstone in machine learning and provides a perfect example for practicing multi-class problems. The features are physical measurements of different parts of the flower, and the goal is to classify the species. This type of problem is analogous to classifying different types of electronic components based on their physical or electrical characteristics, which could be relevant in automated manufacturing and quality control in ECE."
  },
  {
    "objectID": "amli/04_00-04-classification.html#lab-preview-cross-fold-validation",
    "href": "amli/04_00-04-classification.html#lab-preview-cross-fold-validation",
    "title": "Machine Learning",
    "section": "Lab Preview: Cross-Fold Validation",
    "text": "Lab Preview: Cross-Fold Validation\n\ncenter\nShuffle data.\nSplit into k groups (folds).\nIterate k times:\n\nUse one fold as test set.\nUse remaining k-1 folds as training set.\nTrain model on training data.\nEvaluate on test data and record performance.\n\nAverage performance metrics across k iterations.\n\n\nIn this lab, we’ll also introduce cross-fold validation. This technique is crucial for robust model evaluation, especially with smaller datasets, as it ensures that your model’s performance isn’t just an artifact of a particular train-test split. By repeatedly partitioning your data and evaluating the model, you get a much more reliable estimate of its generalization performance. For ECE applications, this means you can be more confident that a model trained in the lab will perform similarly when deployed in real-world conditions, preventing unexpected behavior in critical systems."
  },
  {
    "objectID": "amli/04_00-04-classification.html#lab-preview-wine-producer-identification",
    "href": "amli/04_00-04-classification.html#lab-preview-wine-producer-identification",
    "title": "Machine Learning",
    "section": "Lab Preview: Wine Producer Identification",
    "text": "Lab Preview: Wine Producer Identification\n\ncenter\nChallenge: Identify wine producers based on chemical properties.\nDataset: Chemical analysis of different wines.\nYour Task: Apply your ML skills with minimal guidance.\n\n\nFor your final exercise in the lab, you’ll tackle another multiclass problem: identifying the producer of a wine based on its chemical composition. This exercise will provide less guidance, challenging you to independently apply the machine learning skills you’ve acquired. This scenario mirrors many real-world ECE problems where sensor data (e.g., from spectroscopy or chemical analysis) is used for classification tasks like material identification, quality control, or authentication."
  },
  {
    "objectID": "amli/04_00-04-classification.html#your-turn-multiclass-classification-lab",
    "href": "amli/04_00-04-classification.html#your-turn-multiclass-classification-lab",
    "title": "Machine Learning",
    "section": "Your Turn: Multiclass Classification Lab",
    "text": "Your Turn: Multiclass Classification Lab\nTime to apply your knowledge to solve multiclass problems!\n\nYou’ve now covered the theoretical foundations of multiclass classification and learned about powerful evaluation techniques like cross-fold validation. The lab awaits, where you’ll get hands-on experience with these concepts, culminating in a challenge to really test your machine learning prowess. Good luck!"
  },
  {
    "objectID": "amli/04_00-04-classification.html#dataset-uci-heart-disease",
    "href": "amli/04_00-04-classification.html#dataset-uci-heart-disease",
    "title": "Machine Learning",
    "section": "Dataset: UCI Heart Disease",
    "text": "Dataset: UCI Heart Disease\nPredicting the presence of heart disease\n\n\n\n\n\n\nNote\n\n\nThis will be a binary classification problem: 0 = does not have heart disease 1 = has heart disease\n\n\n\n\nThe dataset we’ll use is the UCI Heart Disease dataset. This dataset contains health information about patients, as well as a “presence of heart disease” indicator. This indicator is a 1 for “has heart disease” and 0 for “does not have heart disease.” As you can probably guess, the model that we will build will be a binary classification model. This medical application highlights the ethical and high-stakes nature of such predictions, relevant to bio-medical engineering aspects of ECE."
  },
  {
    "objectID": "amli/04_00-04-classification.html#dataset-features",
    "href": "amli/04_00-04-classification.html#dataset-features",
    "title": "Machine Learning",
    "section": "Dataset: Features",
    "text": "Dataset: Features\n\n\n\n\n\n\n\nFeature\nDescription\n\n\n\n\nage\nAge in years.\n\n\nsex\nSex (0 = female, 1 = male).\n\n\ncp\nChest pain type (1 = typical angina, 2 = atypical angina, 3 = non-anginal pain, 4 = asymptomatic).\n\n\n\n\nThe dataset contains 13 features. ‘age’ is an integer value representing the patient’s age in years. ‘sex’ is a categorical column with zero representing female and one representing male. ‘cp’ stands for chest pain. It is a categorical column with the four values shown. These features are typical inputs for many data-driven ECE systems that process various sensor or clinical data."
  },
  {
    "objectID": "amli/04_00-04-classification.html#dataset-features-continued",
    "href": "amli/04_00-04-classification.html#dataset-features-continued",
    "title": "Machine Learning",
    "section": "Dataset: Features (continued)",
    "text": "Dataset: Features (continued)\n\n\n\n\n\n\n\nFeature\nDescription\n\n\n\n\ntrestbps\nResting blood pressure in Hg.\n\n\nchol\nSerum cholesterol in mg/dl.\n\n\nfbs\nIs fasting blood sugar &gt; 120 mg/dl (0 = false, 1 = true).\n\n\nrestecg\nResults of a resting electrocardiograph (0 = normal, 1 = ST-T wave abnormality, 2 = left ventricular hypertrophy).\n\n\n\n\ntrestbps is the resting blood pressure of the patient upon admission to the hospital. chol is a variable representing cholesterol. fbs is a measure of fasting blood sugar, but it is represented as a categorical column that measures if blood sugar is over a threshold. restecg is a categorical column with the three values shown. These are physiological signals, often acquired through sensor arrays, that ECE engineers would be responsible for designing and processing."
  },
  {
    "objectID": "amli/04_00-04-classification.html#dataset-features-continued-1",
    "href": "amli/04_00-04-classification.html#dataset-features-continued-1",
    "title": "Machine Learning",
    "section": "Dataset: Features (continued)",
    "text": "Dataset: Features (continued)\n\n\n\n\n\n\n\nFeature\nDescription\n\n\n\n\nthalach\nMax heart rate.\n\n\nexang\nExercise induced angina (0 = no, 1 = yes).\n\n\noldpeak\nMeasurement of an abnormal ST depression.\n\n\nslope\nSlope of peak of exercise ST segment (1 = upslope, 2 = flat, 3 = downslope).\n\n\n\n\nThe next two columns have to do with an exercise stress test the patients completed. thalach is the maximum heart rate the patient achieved during the exercise session. exang is a categorical variable that lets us know if the exercise caused angina. oldpeak is a variable that measures ST depression. ST depression is a curve on an electrocardiogram graph where the ST segment line is very low when compared to a baseline. slope is a categorical variable that lets you know which direction the line was going at the peak exercise ST segment. These stress test parameters are derived from complex biomedical signal processing, a core area of ECE."
  },
  {
    "objectID": "amli/04_00-04-classification.html#dataset-features-continued-2",
    "href": "amli/04_00-04-classification.html#dataset-features-continued-2",
    "title": "Machine Learning",
    "section": "Dataset: Features (continued)",
    "text": "Dataset: Features (continued)\n\n\n\n\n\n\n\nFeature\nDescription\n\n\n\n\nca\nCount of major blood vessels colored by fluoroscopy (0, 1, 2, 3, or 4).\n\n\nthal\nPresence heart condition (0 = unknown, 1 = normal, 2 = fixed defect, 3 = reversible defect).\n\n\n\n\nca is a count of major blood vessels colored by fluoroscopy. The values are 0, 1, 2, or 3, and are limited by biology, though occasionally 4 appears due to data quirks. thal relates to a heart defect, describing if it exists and its nature. You might notice the values on the slides for some of these columns differ from the documentation. For instance, the documentation for ‘ca’ states that the values range from 0-3, but there are 4s in the data. And the documentation for ‘thal’ says that the values are 3, 6, and 7, but the actual values in the data are 0, 1, 2, and 3. The takeaway from this is that you should always read the documentation, but you should also always look at the data and verify that the documentation is accurate. When there are questions, you should do research. If you are in contact with the source of the data, ask for clarification. Though documentation is great and can really help in data science, the dataset itself is the actual ground truth. This is a critical lesson for ECE engineers handling data from new sensors or instruments."
  },
  {
    "objectID": "amli/04_00-04-classification.html#the-model-output-layer-activation",
    "href": "amli/04_00-04-classification.html#the-model-output-layer-activation",
    "title": "Machine Learning",
    "section": "The Model: Output Layer Activation",
    "text": "The Model: Output Layer Activation\n    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n\nFor binary classification, the final layer typically has 1 neuron.\nUses a sigmoid activation function.\nOutput range [0.0, 1.0] interpreted as prediction confidence.\nThreshold determines final class.\n\n\nThe model in this lab won’t look too different from the TensorFlow Keras models we built for regression analysis. The primary difference is the final layer in the model. We want to create a binary prediction that will let us know if a patient has heart disease or not. If we stick with a ReLU activation function for the output, then there is no bound for the maximum output value, so it would be impossible to understand what the prediction confidence is. Instead, we’ll use an activation function that limits the output value. In this particular lab, we use a sigmoid function, so the output is limited to the range of 0.0 to 1.0. This output is then a measure of confidence that a patient has heart disease (since “has heart disease” is the 1.0 value). We can then decide how much confidence it takes to classify the patient as having heart disease. The choice of threshold is very important for model performance, and remember that we can measure performance at different thresholds with an ROC curve. This is directly applicable to digital circuit design for ML acceleration, where the choice of activation impacts hardware implementation efficiency."
  },
  {
    "objectID": "amli/04_00-04-classification.html#the-model-loss-function-optimizer",
    "href": "amli/04_00-04-classification.html#the-model-loss-function-optimizer",
    "title": "Machine Learning",
    "section": "The Model: Loss Function & Optimizer",
    "text": "The Model: Loss Function & Optimizer\n    model.compile(\n        loss='binary_crossentropy',\n        optimizer='Adam',\n        metrics=['accuracy']\n    )\n\nLoss Function: binary_crossentropy is standard for binary classification.\nOptimizer: Adam is an adaptive learning rate optimization algorithm.\n\nAdjusts learning rate for each parameter, often faster convergence.\n\n\n\nHow we measure loss is also very important. For binary classification problems, we need to use binary cross-entropy, which is specifically designed to quantify the difference between two probability distributions. Although we’ve talked a lot about using gradient descent for optimization, there are other methods as well. Adam is one of these methods. Adam uses an adaptive learning rate. That is, it uses a different learning rate for each of the different parameters in the model. This differs from stochastic gradient descent which uses a single learning rate for all parameters. While Adam often offers faster convergence, selecting the right optimizer is a non-trivial part of ECE machine learning, influencing training time and model accuracy on specialized hardware. A lot of research is being done to understand the conditions under which different optimizers perform better."
  },
  {
    "objectID": "amli/04_00-04-classification.html#the-model-early-stopping",
    "href": "amli/04_00-04-classification.html#the-model-early-stopping",
    "title": "Machine Learning",
    "section": "The Model: Early Stopping",
    "text": "The Model: Early Stopping\n    tf.keras.callbacks.EarlyStopping(\n        monitor='loss',\n        min_delta=1e-3,\n        patience=5,\n    )\n\nPurpose: Prevents overfitting and reduces training time.\nMechanism: Stops training when a monitored metric (e.g., loss) stops improving significantly.\n\nmonitor='loss': Watches the validation loss.\nmin_delta=1e-3: Minimum change in the monitored quantity to qualify as an improvement.\npatience=5: Number of epochs with no improvement after which training will be stopped.\n\n\n\nWe’ll also visit early stopping in this lab. Early stopping is a model-fitting strategy where you monitor some metric - say, loss - and stop training when that metric doesn’t change enough across a number of epochs. In this example we monitor the validation loss and stop early if the loss hasn’t changed by at least 0.001 during any of the last five epochs. This technique is critical in practical ECE ML deployments to save computational resources and ensure the model generalizes well to unseen data, preventing wasted energy and time on embedded or cloud-based training platforms."
  },
  {
    "objectID": "amli/04_00-04-classification.html#your-turn-tensorflow-lab",
    "href": "amli/04_00-04-classification.html#your-turn-tensorflow-lab",
    "title": "Machine Learning",
    "section": "Your Turn: TensorFlow Lab",
    "text": "Your Turn: TensorFlow Lab\nNow, it’s your turn to perform binary classification using TensorFlow Keras and deep neural networks!\n\nThis lab will connect the theoretical concepts of classification with the powerful, industry-standard tools for deep learning. You’ll gain practical experience in building, training, and evaluating a neural network for a real-world ECE-relevant problem."
  },
  {
    "objectID": "amli/04_00-04-classification.html#the-titanic-shipwreck-challenge",
    "href": "amli/04_00-04-classification.html#the-titanic-shipwreck-challenge",
    "title": "Machine Learning",
    "section": "The Titanic Shipwreck Challenge",
    "text": "The Titanic Shipwreck Challenge\n\ncenter\nGoal: Achieve a high accuracy score in predicting passenger survival.\nApplication: A canonical challenge for applying binary classification.\n\n\nThe challenge is to achieve a high accuracy score while trying to predict which passengers survived the Titanic shipwreck. This is a classic dataset for introductory machine learning due to its mix of numerical and categorical features, missing data, and clear binary classification target. It’s an excellent way to practice data preprocessing and feature engineering, skills directly transferable to ECE applications involving sensor data or system logs."
  },
  {
    "objectID": "amli/04_00-04-classification.html#review-types-of-classification",
    "href": "amli/04_00-04-classification.html#review-types-of-classification",
    "title": "Machine Learning",
    "section": "Review: Types of Classification",
    "text": "Review: Types of Classification\nWhat types of classification have we learned about?\n\nLet’s take a moment to review before diving into the project. What are the key categories of classification problems we’ve covered? (Expected answers: Binary classification, Multiclass classification). Can you give examples of when each is appropriate, perhaps from an ECE context? For instance, binary for fault detection (fault/no fault) and multiclass for identifying different types of signal modulation (e.g., PSK, FSK, QAM)."
  },
  {
    "objectID": "amli/04_00-04-classification.html#review-ml-tools-for-classification",
    "href": "amli/04_00-04-classification.html#review-ml-tools-for-classification",
    "title": "Machine Learning",
    "section": "Review: ML Tools for Classification",
    "text": "Review: ML Tools for Classification\nWhat tools have we learned about for classification?\n\nWe have learned many different models and tools for performing classification. What are some of those models and tools? (Expected answers: Scikit-learn (e.g., Logistic Regression), TensorFlow/Keras for Deep Neural Networks, concepts like OvO/OvA for multiclass conversion). Briefly explain a bit about each of the tools and when you might choose one over the other in an ECE scenario, considering factors like complexity, speed, and interpretability."
  },
  {
    "objectID": "amli/04_00-04-classification.html#review-evaluation-metrics",
    "href": "amli/04_00-04-classification.html#review-evaluation-metrics",
    "title": "Machine Learning",
    "section": "Review: Evaluation Metrics",
    "text": "Review: Evaluation Metrics\nWhat metrics have we learned for evaluating classification models?\n\nNow, let’s talk about how we measure success. What are some of the evaluation metrics we’ve discussed for classification models? (Expected answers: Confusion Matrix, Accuracy, Precision, Recall, F1 Score, ROC Curve, AUC). Have students discuss what each metric measures and how we interpret them, emphasizing the importance of choosing the right metric based on the application’s cost function for FP and FN errors in ECE."
  },
  {
    "objectID": "amli/04_00-04-classification.html#review-other-useful-techniques",
    "href": "amli/04_00-04-classification.html#review-other-useful-techniques",
    "title": "Machine Learning",
    "section": "Review: Other Useful Techniques",
    "text": "Review: Other Useful Techniques\nWhat other useful techniques have we learned, and what are they used for?\n\nWe’ve covered a few other techniques that can be useful for model training and testing. Can you name a few and describe their purpose? (Expected answers: Hyperparameter tuning (e.g., Grid Search), Cross-validation, Early Stopping, Data preprocessing (normalization, encoding categorical features)). Discuss how these techniques contribute to building robust and generalized ML models for real-world ECE systems."
  },
  {
    "objectID": "amli/04_00-04-classification.html#classification-project-the-data",
    "href": "amli/04_00-04-classification.html#classification-project-the-data",
    "title": "Machine Learning",
    "section": "Classification Project: The Data",
    "text": "Classification Project: The Data\n\n\n\nColumn\nType\nDescription\n\n\n\n\nSurvived\nnumber\n1 or 0 ( target )\n\n\nName\nstring\nPassenger name\n\n\nPclass\nnumber\nTicket class\n\n\nSex\nstring\nmale or female\n\n\nAge\nnumber\nPassenger age\n\n\nSibSp\nnumber\n# of siblings/spouses on board\n\n\nEmbarked\nstring\nPort of Embarkation\n\n\n\n\nThe dataset we’re using comes from Kaggle. Here are just a few of the columns of data you’ll be working with. As you can see, we have both numbers and strings. The target column is Survived, and it is a number that is either 0 or 1. This mix of data types is very common in ECE applications, where you might deal with numerical sensor readings, categorical status codes, and potentially textual log data. You’ll need to think about how to preprocess these different types of features."
  },
  {
    "objectID": "amli/04_00-04-classification.html#classification-project-kaggle-competition",
    "href": "amli/04_00-04-classification.html#classification-project-kaggle-competition",
    "title": "Machine Learning",
    "section": "Classification Project: Kaggle Competition",
    "text": "Classification Project: Kaggle Competition\nTitanic: Machine Learning from Disaster\n\nEngage with a global community of ML practitioners.\nUpload your results to compare your model’s performance.\n\n\nKaggle hosts several competitions that are open to users. It’s an exciting way to engage with the broader machine learning community and learn new things. At the end of this lab, you will upload your results to the Kaggle competition and see how your model compares to the over 17,000 other models people have created! This provides a real-world context for competition and benchmarking, akin to engineering design challenges."
  },
  {
    "objectID": "amli/04_00-04-classification.html#classification-project-your-turn",
    "href": "amli/04_00-04-classification.html#classification-project-your-turn",
    "title": "Machine Learning",
    "section": "Classification Project: Your Turn",
    "text": "Classification Project: Your Turn\n\nExploratory Data Analysis (EDA):\n\nUnderstand the data, identify obvious problems, and perform initial cleaning.\nConsider pros/cons of using ML for this problem.\n\nModel Building & Evaluation:\n\nChoose your model (scikit-learn or TensorFlow).\nTrain and evaluate your model, discussing chosen metrics.\n\nMake Predictions & Upload to Kaggle:\n\nGenerate predictions for the test dataset.\nSubmit your predictions to the Kaggle competition.\n\nIterate on Your Model:\n\nTweak hyperparameters, try different models, explore new features.\nDiscuss your methodical approach to improvement.\nResearch and compare with other solutions for deeper insights.\n\n\n\nIt is now your turn to perform a classification from end-to-end. The lab you are about to be given is divided into four primary parts. In the first section, you’ll acquire and explore the data. Here we expect you to write code and prose about the data. Does the data have obvious problems? Do any model-independent changes need to be made to the data? EDA is the place to reason about and perform these tasks. This is also a good time to think about the pros and cons of using machine learning to solve this problem. In the next section, you will build and evaluate your model. You may choose to use scikit-learn or Tensorflow. You may even try multiple approaches and compare your results. Here you should also evaluate your model and discuss your particular evaluation metrics, including why you chose them and what they say. Finally, you will make predictions on the features found in the test.csv file and upload them to Kaggle using the Kaggle API. Your lab should discuss your predictions as well as your Kaggle results. Last but not least, iterate on your model. Tweak hyperparameters, and see if you can improve your model. Discuss your method for changing specific hyperparameters. Be thoughtful and methodical; don’t just do it at random! Since this is a popular Kaggle dataset and competition, research other users’ solutions. Try looking at solutions that both do and don’t use ML, and discuss their relative merits. Take your time. Experiment. Don’t be afraid to throw away some work along the way. This iterative process is crucial for ECE engineers developing and refining complex systems."
  },
  {
    "objectID": "amli/03_00-04-regression.html#regression",
    "href": "amli/03_00-04-regression.html#regression",
    "title": "Machine Learning",
    "section": "Regression",
    "text": "Regression\n\nRegression Introduction Image\nHas anyone seen a crime show or heard of an investigation where they used a footprint to determine a suspect’s height? It’s a tactic frequently mentioned in connection to forensics, but does it actually work? Let’s try it out!\nExercise (15 minutes): Use your own shoe size and height as the suspect’s, and tell students to keep in mind that US men’s size equals US women’s size - 2. Don’t tell them the suspect’s height, but tell them the suspect’s shoe size and tell them that their task will be to guess the suspect’s height.\nSplit the students into groups of ~6 each and give each group a sheet of graph paper.\nAsk the groups to plot each group member’s shoe size on the x-axis and height on the y-axis. What do they think is the suspect’s height based on the suspect’s shoe size?\nThen have the groups share data, so each has a plot of the whole class’s information. Make another guess per group. Does anyone come close?\nThey should theoretically have better guesses with more data, but shoe size might not actually be well correlated to height, so they might not."
  },
  {
    "objectID": "amli/03_00-04-regression.html#mathematical-model",
    "href": "amli/03_00-04-regression.html#mathematical-model",
    "title": "Machine Learning",
    "section": "Mathematical Model",
    "text": "Mathematical Model\n\nMathematical Model for Linear Regression\nLinear regression has a simple goal: to find a straight line that best fits a set of data. This model is foundational in many ECE applications, such as predicting sensor outputs or analyzing circuit performance based on input parameters."
  },
  {
    "objectID": "amli/03_00-04-regression.html#features-go-in-targets-come-out",
    "href": "amli/03_00-04-regression.html#features-go-in-targets-come-out",
    "title": "Machine Learning",
    "section": "Features Go In, Targets Come Out",
    "text": "Features Go In, Targets Come Out\n\nFeatures and Targets in Machine Learning\nRecall that the equation for a line is y = m * x + b, where x denotes our input variable and y is our output. In the case of machine learning, x represents input features and y represents target outputs. For example, if we were trying to forecast the power consumption of a device from its operating frequency, the operating frequency would be the input feature, and the power consumption would be the target output."
  },
  {
    "objectID": "amli/03_00-04-regression.html#what-is-the-machine-learning",
    "href": "amli/03_00-04-regression.html#what-is-the-machine-learning",
    "title": "Machine Learning",
    "section": "What is the Machine “Learning?”",
    "text": "What is the Machine “Learning?”\n\nWeights and Biases in Linear Regression\nUsing the data, simple linear regression “learns” two values. The first is m, which you may have called “slope” and which we’ll refer to as a “weight / coefficient.” This represents how much a change in the feature value (x) should affect our prediction (y). In other words, a 1 unit increase in x yields an m unit change in y.\nThe second is b, which you may have called an “intercept” and which we’ll refer to as a “bias.” The bias represents the prediction we would make if our input features are all zero. For example, you may expect an electronic component to draw some baseline current even with zero input signal; this baseline would be analogous to the bias."
  },
  {
    "objectID": "amli/03_00-04-regression.html#multiple-features",
    "href": "amli/03_00-04-regression.html#multiple-features",
    "title": "Machine Learning",
    "section": "Multiple Features",
    "text": "Multiple Features\n\nMultiple Features in Regression\nRealistically, the performance of an ECE system might depend on several factors (e.g., current drawn depends on voltage, temperature, and load resistance). Now, our model needs to learn three weights (one for each input feature) and one bias.\nThe concept of weights and biases is important to most machine learning models, even complex neural networks. The model uses data to learn how each input feature affects the output and it learns a bias to linearly shift its predictions to fit the data. This is like shifting a y-intercept."
  },
  {
    "objectID": "amli/03_00-04-regression.html#machine-learning-process",
    "href": "amli/03_00-04-regression.html#machine-learning-process",
    "title": "Machine Learning",
    "section": "Machine Learning Process",
    "text": "Machine Learning Process\n\nInfer/Predict/Forecast\nCalculate Error/Loss/Cost\nTrain/Learn (Update parameters)\nIterate/Repeat (until some stopping condition)\n\n\n\n\n\n\n\nNote\n\n\nThis iterative cycle is fundamental to how most machine learning algorithms “learn” from data.\n\n\n\n\nBut how do we “learn” the weights and biases? Typically, in machine learning we use the following iterative process.\n\nGiven an input value, we forecast (or guess) the potential target value.\nWe calculate the error (or difference) between the actual target value and the target we guessed.\nWe update the weights and biases to produce a guess that is closer to the actual target.\nWe iterate. That is, we repeat these steps until some stopping condition. (The stopping condition could be a small enough error, or that the error is no longer changing between iterations.)"
  },
  {
    "objectID": "amli/03_00-04-regression.html#machine-learning-process-flow",
    "href": "amli/03_00-04-regression.html#machine-learning-process-flow",
    "title": "Machine Learning",
    "section": "Machine Learning Process Flow",
    "text": "Machine Learning Process Flow\n\n\n\n\n\ngraph TD\n    A[Start] --&gt; B{Data Input};\n    B --&gt; C[Predict Target];\n    C --&gt; D[Compare to Actual Target];\n    D --&gt; E[Calculate Error/Loss];\n    E --&gt; F[\"Update Model Parameters &lt;br&gt; (Weights & Bias)\"];\n    F --&gt; G{Stopping Condition Met?};\n    G -- No --&gt; C;\n    G -- Yes --&gt; H[Model Converged];\n\n\n\n\n\n\n\nThis flowchart visually represents the iterative machine learning process. Data is fed in, a prediction is made, the error is calculated, parameters are updated, and the cycle repeats until the model achieves a satisfactory level of accuracy or reaches a predefined limit."
  },
  {
    "objectID": "amli/03_00-04-regression.html#predict-the-selling-price-of-a-house",
    "href": "amli/03_00-04-regression.html#predict-the-selling-price-of-a-house",
    "title": "Machine Learning",
    "section": "Predict the Selling Price of a House",
    "text": "Predict the Selling Price of a House\n\nHouse Price Data\nHere are four data points. The feature (x-value) is square footage of a house (in thousands of square feet), and the target (y-value) is the price of the house (in thousands of dollars). We will use this simple example to trace the machine learning process."
  },
  {
    "objectID": "amli/03_00-04-regression.html#predict-the-price-of-a-house-using-the-machine-learning-process",
    "href": "amli/03_00-04-regression.html#predict-the-price-of-a-house-using-the-machine-learning-process",
    "title": "Machine Learning",
    "section": "Predict the Price of a House Using the Machine Learning Process",
    "text": "Predict the Price of a House Using the Machine Learning Process\n\nHouse Price Scatter Plot\nHere is a different depiction of the same four data points. It is a simple scatter plot, where the x-axis is the size of a house (our feature), and on the y-axis we have the price of the house (our target)."
  },
  {
    "objectID": "amli/03_00-04-regression.html#predict-the-price-of-a-house-using-the-machine-learning-process-1",
    "href": "amli/03_00-04-regression.html#predict-the-price-of-a-house-using-the-machine-learning-process-1",
    "title": "Machine Learning",
    "section": "Predict the Price of a House Using the Machine Learning Process",
    "text": "Predict the Price of a House Using the Machine Learning Process\n\nInitial Guess for Line\nTo begin the iterative machine learning process, we make an initial guess at the weights and biases. In this case, we have one weight, m, and one bias, b. Glancing at the data (but not agonizing too hard), we make a simple guess: b = 160 and m = 1."
  },
  {
    "objectID": "amli/03_00-04-regression.html#predict-the-price-of-a-house-using-the-machine-learning-process-2",
    "href": "amli/03_00-04-regression.html#predict-the-price-of-a-house-using-the-machine-learning-process-2",
    "title": "Machine Learning",
    "section": "Predict the Price of a House Using the Machine Learning Process",
    "text": "Predict the Price of a House Using the Machine Learning Process\n\nLine from Initial Guess\nWe now have an initial guess for our model’s parameters, and we use them to create the linear equation y = mx + b. This line represents our initial prediction model."
  },
  {
    "objectID": "amli/03_00-04-regression.html#predict-the-price-of-a-house-using-the-machine-learning-process-3",
    "href": "amli/03_00-04-regression.html#predict-the-price-of-a-house-using-the-machine-learning-process-3",
    "title": "Machine Learning",
    "section": "Predict the Price of a House Using the Machine Learning Process",
    "text": "Predict the Price of a House Using the Machine Learning Process\n\nPredicted Values Example\nNow, we use this line to forecast predicted output values. For each point in our training data set (x_k, y_k), we calculate y_pred = m(x_k) + b. These are the predictions the model makes given its current parameters."
  },
  {
    "objectID": "amli/03_00-04-regression.html#predict-the-price-of-a-house-using-the-machine-learning-process-4",
    "href": "amli/03_00-04-regression.html#predict-the-price-of-a-house-using-the-machine-learning-process-4",
    "title": "Machine Learning",
    "section": "Predict the Price of a House Using the Machine Learning Process",
    "text": "Predict the Price of a House Using the Machine Learning Process\n\nActual vs Forecasted Values\nHere we have the actual target outputs (blue dots) and the forecasted outputs that came from our model (purple points on the line). We’ve completed the infer/predict/forecast step. Notice the vertical distance between the blue dots and the purple points; these represent the errors."
  },
  {
    "objectID": "amli/03_00-04-regression.html#predict-the-price-of-a-house-using-the-machine-learning-process-5",
    "href": "amli/03_00-04-regression.html#predict-the-price-of-a-house-using-the-machine-learning-process-5",
    "title": "Machine Learning",
    "section": "Predict the Price of a House Using the Machine Learning Process",
    "text": "Predict the Price of a House Using the Machine Learning Process\n\nError Calculation Illustration\nNow we move onto step 2, which is to compute error/loss/cost. We calculate the error between the actual target values, and the forecasted values. The metric we use to calculate this error can be simple Euclidean distance, but there are other measures as well. We will talk about error/cost functions in a minute, but for now it’s okay to think of the vertical distance between the actual value and the forecasted value."
  },
  {
    "objectID": "amli/03_00-04-regression.html#predict-the-price-of-a-house-using-the-machine-learning-process-6",
    "href": "amli/03_00-04-regression.html#predict-the-price-of-a-house-using-the-machine-learning-process-6",
    "title": "Machine Learning",
    "section": "Predict the Price of a House Using the Machine Learning Process",
    "text": "Predict the Price of a House Using the Machine Learning Process\n\nUpdated Line Illustration\nFinally, we update the weight and bias such that we reduce the error. The machine learning algorithm adjusts m and b in a way that minimizes the overall error. This leads to a new, better-fitting line. Now we have new m and b values, and we start at step 1 using these new parameters (predict, calculate error, update, repeat). This iterative refinement continues until the model converges or a stopping condition is met."
  },
  {
    "objectID": "amli/03_00-04-regression.html#interactive-tuning-our-regression-model",
    "href": "amli/03_00-04-regression.html#interactive-tuning-our-regression-model",
    "title": "Machine Learning",
    "section": "Interactive: Tuning Our Regression Model",
    "text": "Interactive: Tuning Our Regression Model\nAdjust the weight (slope) and bias (intercept) to fit the data and minimize the Mean Squared Error (MSE).\n\nviewof weight_m = Inputs.range([-10, 10], {value: 1, step: 0.1, label: \"Weight (m)\"});\nviewof bias_b = Inputs.range([100, 200], {value: 160, step: 1, label: \"Bias (b)\"});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis interactive plot demonstrates how drastically changing the weight (m) and bias (b) affects the regression line and, consequently, the Mean Squared Error. Try to find the optimal m and b that result in the lowest MSE. For this simple dataset, the optimal values are m=2 and b=159, which yield an MSE of 0.00. This exercise visually reinforces the goal of regression: minimizing the error between predicted and actual values by adjusting model parameters."
  },
  {
    "objectID": "amli/03_00-04-regression.html#errorlosscost-functions",
    "href": "amli/03_00-04-regression.html#errorlosscost-functions",
    "title": "Machine Learning",
    "section": "Error/Loss/Cost Functions",
    "text": "Error/Loss/Cost Functions\n\nCommon Loss Functions\nNow let’s look at a few common loss/cost functions. Remember we use these functions to determine the error that results from a particular set of weights and biases. These are not the only loss functions, but they are very common.\n\nL1 Loss (Least Absolute Deviations or LAE): L1 is resistant to outliers in the data (i.e. robust). If your data has outliers that can be ignored, then L1 is a good choice. If it is important to pay attention to any and all outliers, the method of least squares is a better choice.\nL2 Loss (Least Squares): Generally, L2 loss is preferred to L1, but when outliers are present in the data, then L2 may not perform well. The reason for this is because we are squaring the difference between the actual target and the predicted target. So if the error is large (in the case of an extreme outlier), then the error function will overcompensate.\nMean Squared Error (MSE): MSE is the average of the squared differences between predicted targets and actual targets. Due to squaring, predictions which are far away from actual values are penalized heavily in comparison to less deviated predictions (similar to L2). MSE also has nice mathematical properties which make it easier to calculate gradients, which are used to update the model parameters (weights and biases). It’s widely used in ECE for tasks like signal reconstruction error or system identification."
  },
  {
    "objectID": "amli/03_00-04-regression.html#housing-example",
    "href": "amli/03_00-04-regression.html#housing-example",
    "title": "Machine Learning",
    "section": "Housing Example",
    "text": "Housing Example\n\nHousing Example Data Table\nLet’s practice calculating each of these loss functions for the data in the housing example, with the initial model y = 70x + 100000.\nExercise (15 minutes): Have students work in small groups to calculate the loss functions based on the data in the table. It may be helpful to write the loss functions on the board at this point or flip back to the slide with the loss functions and allow students to write them down."
  },
  {
    "objectID": "amli/03_00-04-regression.html#housing-example-l1-loss",
    "href": "amli/03_00-04-regression.html#housing-example-l1-loss",
    "title": "Machine Learning",
    "section": "Housing Example (L1 Loss)",
    "text": "Housing Example (L1 Loss)\n\nL1 Loss Calculation\nThe L1 Loss, also known as Mean Absolute Error (MAE), for our initial model y = 7x + 100000 for the housing data is 1.0. This is the sum of the absolute differences between the actual and predicted values."
  },
  {
    "objectID": "amli/03_00-04-regression.html#housing-example-l2-loss",
    "href": "amli/03_00-04-regression.html#housing-example-l2-loss",
    "title": "Machine Learning",
    "section": "Housing Example (L2 Loss)",
    "text": "Housing Example (L2 Loss)\n\nL2 Loss Calculation\nThe L2 Loss for our initial model y = 7x + 100000 for the housing data is …. This is the sum of the squared differences between the actual and predicted values. Notice how squaring penalizes larger errors more significantly."
  },
  {
    "objectID": "amli/03_00-04-regression.html#housing-example-mse",
    "href": "amli/03_00-04-regression.html#housing-example-mse",
    "title": "Machine Learning",
    "section": "Housing Example (MSE)",
    "text": "Housing Example (MSE)\n\nMSE Calculation\nThe Mean Squared Error (MSE) for our initial model y = 7x + 100000 for the housing data is …. This is the average of the squared differences. This metric is a cornerstone for optimizing many ECE-related ML models due to its smooth, differentiable nature."
  },
  {
    "objectID": "amli/03_00-04-regression.html#computer-vs.-human-jobs",
    "href": "amli/03_00-04-regression.html#computer-vs.-human-jobs",
    "title": "Machine Learning",
    "section": "Computer vs. Human Jobs",
    "text": "Computer vs. Human Jobs\n\n\nThe computer’s job:\n\nStart with an arbitrary guess of parameters.\nTweak these parameters to reduce loss.\nThe less the loss is changing, the less the value should be tweaked.\n\n\nThe human’s job:\n\nChoose the learning rate, a constant value which scales how far we tweak the value during each iteration.\n\n\n\n\n\n\n\nImportant\n\n\nLearning rate is a hyperparameter - not a parameter in the actual model.\n\n\n\n\n\nA hyperparameter is not a parameter in the model. In other words, it’s not a weight or bias. It is a value that is chosen by the machine learning specialist that controls how the algorithm “learns” the model parameters. This is a subtle but important distinction. In ECE terms, it’s like choosing the gain in a control loop: it’s part of the controller’s design, not a variable being optimized by the system itself during operation."
  },
  {
    "objectID": "amli/03_00-04-regression.html#gradient-descent",
    "href": "amli/03_00-04-regression.html#gradient-descent",
    "title": "Machine Learning",
    "section": "Gradient Descent",
    "text": "Gradient Descent\n\nGradient Descent Illustration\nHow does the model “iteratively” update its parameters? We can think of our goal as an optimization problem, where we’d like to optimize (minimize) a loss function. Machine learning models then use an “optimizer,” an algorithm to perform that optimization.\nThe most common optimizer is gradient descent, where the model starts by picking random values for each parameter. It then changes each in the direction that reduces loss the most. On each iteration or “step,” the model should get closer to the minimal loss until it “converges,” or reaches a point where the loss isn’t changing much between steps. (Usually this is based on some threshold, like the loss function changing by less than 0.001 between steps.) Since this isn’t a closed-form solution, gradient descent isn’t guaranteed to converge to the absolute lowest loss possible. There are more sophisticated optimizers that can sometimes do better.\nYou can control gradient descent by choosing the learning rate, which determines how much you tweak each parameter on each step. We call this a hyperparameter: a value you can change to change model performance, but one that isn’t “learned” by the model. This is analogous to tuning PID controller gains in an ECE system to optimize stability and response time."
  },
  {
    "objectID": "amli/03_00-04-regression.html#linear-algebra-notation-for-ymxb",
    "href": "amli/03_00-04-regression.html#linear-algebra-notation-for-ymxb",
    "title": "Machine Learning",
    "section": "Linear Algebra Notation for \\(y=mx+b\\)",
    "text": "Linear Algebra Notation for \\(y=mx+b\\)\n\nLinear Algebra Notation for Single Feature\nHere \\(\\theta_0\\) is the bias and \\(\\theta_1\\) is the weight (i.e. \\(\\theta_0 = b\\) and \\(\\theta_1 = m\\)). This notation is helpful in ECE when dealing with system identification or control, allowing for a compact representation of input-output relationships."
  },
  {
    "objectID": "amli/03_00-04-regression.html#linear-algebra-notation-for-ymxb-1",
    "href": "amli/03_00-04-regression.html#linear-algebra-notation-for-ymxb-1",
    "title": "Machine Learning",
    "section": "Linear Algebra Notation for \\(y=mx+b\\)",
    "text": "Linear Algebra Notation for \\(y=mx+b\\)\n\nCompact Linear Algebra Notation\nUsing matrix/vector notation we can rewrite the equation of the line more compactly as \\(\\theta^T X\\). This compact form is efficient for computations, especially when dealing with large datasets or multiple features, and simplifies theoretical analysis."
  },
  {
    "objectID": "amli/03_00-04-regression.html#multiple-regression-i.e.-multiple-features",
    "href": "amli/03_00-04-regression.html#multiple-regression-i.e.-multiple-features",
    "title": "Machine Learning",
    "section": "Multiple Regression (i.e. Multiple Features)",
    "text": "Multiple Regression (i.e. Multiple Features)\n\nMultiple Features in Multiple Regression\nThis notational convenience can be extended to regression with multiple features. Recall our example from before where energy is a function of coffee, time of day, and temperature. In ECE, this could be predicting system latency based on processor clock speed, memory usage, and ambient temperature."
  },
  {
    "objectID": "amli/03_00-04-regression.html#multiple-regression-notation",
    "href": "amli/03_00-04-regression.html#multiple-regression-notation",
    "title": "Machine Learning",
    "section": "Multiple Regression Notation",
    "text": "Multiple Regression Notation\n\nMultiple Regression Compact Notation\nAgain, we can use \\(\\theta^T X\\) to represent the regression equation, even with multiple features. Here, \\(X\\) becomes a vector of features for each data point, and \\(\\theta\\) becomes a vector of corresponding weights (coefficients) and bias. This generalizes the single-feature case efficiently."
  },
  {
    "objectID": "amli/03_00-04-regression.html#closed-form-exact-solution",
    "href": "amli/03_00-04-regression.html#closed-form-exact-solution",
    "title": "Machine Learning",
    "section": "Closed Form, Exact Solution",
    "text": "Closed Form, Exact Solution\n\\[ \\theta = (X^{T} \\cdot X)^{-1} \\cdot X^{T} \\cdot y \\]\n\nGood for small datasets\nFinds optimal solution\nCan be computationally expensive\nRequires an invertible matrix\n\n\nHow does the model actually “learn” those values? Through linear algebra, there is an exact (closed form) solution. All you need to do is plug in your \\(X\\) (features) and \\(y\\) (targets) values, and calculate to get your weight and bias values (\\(\\theta\\)).\n\\(X\\) is an \\(m \\times n\\) matrix. \\(X^T X\\) is invertible if and only if \\(m \\leq n\\) and rank(X) = m. This method is an elegant mathematical solution, typically used when computational resources aren’t a concern or for smaller, well-behaved datasets. In ECE, direct matrix methods are common in signal processing and control for static or well-defined systems."
  },
  {
    "objectID": "amli/03_00-04-regression.html#batched-data",
    "href": "amli/03_00-04-regression.html#batched-data",
    "title": "Machine Learning",
    "section": "Batched Data",
    "text": "Batched Data\nBreak data into smaller batches.\n\nWe’ll use a new batch on each learning step.\nNew hyperparameter batch size controls how much data is used for each learning step.\n\n\nBatched Data for Training\nAnother important hyperparameter is batch size. While you could perform gradient descent based on your full dataset every step, it may require too much memory, and take longer to converge. To combat both, we split the data into smaller batches. On each step, we’ll use a new batch to update parameters. You can control how large these batches are. This is particularly relevant in ECE for real-time processing or embedded systems with limited memory, where processing data in chunks is necessary."
  },
  {
    "objectID": "amli/03_00-04-regression.html#hyperparameters-we-care-about",
    "href": "amli/03_00-04-regression.html#hyperparameters-we-care-about",
    "title": "Machine Learning",
    "section": "Hyperparameters We Care About",
    "text": "Hyperparameters We Care About\n\nHyperparameter Tuning Guidelines\nAfter setting up a model, you may find you need to perform “hyperparameter tuning” to achieve better results. Different problems work well with different combinations of hyperparameter values. You’ll often need to experiment or “tune” those combinations. Here are some rough guidelines for potential problems with learning rate and batch size that might suggest increasing or decreasing their values. This tuning process is similar to empirically optimizing parameters in hardware or control systems to meet specific performance requirements."
  },
  {
    "objectID": "amli/03_00-04-regression.html#scikit-learn",
    "href": "amli/03_00-04-regression.html#scikit-learn",
    "title": "Machine Learning",
    "section": "scikit-Learn",
    "text": "scikit-Learn\n\nScikit-learn.org is the primary website for the scikit-learn project. Here you will find information pertaining to scikit-learn, including instructions on installation, documentation, and even the project source code.\nLet’s take a few moments to look around the project website.\nExercise (10 minutes): Either navigate to scikit-learn.org on your own computer and present your computer screen to the students (recommended), or ask them to open their laptops to scikit-learn.org. Take the time to point out the following elements on the website: * The classification, regression, clustering, dimensionality reduction, model selection, and preprocessing sections on the main page. These represent core groupings of features provided by scikit-learn. * The top-page navigation with links on how to install the toolkit, documentation, and examples. * The banner on the upper right corner that says “Fork me on GitHub.” This leads to the source code. * When you click the ‘Documentation’ drop-down in the upper navigation, it tells you the current stable version and has a link to ‘All available versions.’ Tell students to be sure to check the version of scikit-learn they’re working with once they start the lab. * The ‘Examples’ linked in the top navigation are not just API usage examples; they also contain some interesting machine learning insights."
  },
  {
    "objectID": "amli/03_00-04-regression.html#datasets",
    "href": "amli/03_00-04-regression.html#datasets",
    "title": "Machine Learning",
    "section": "Datasets",
    "text": "Datasets\n\nScikit-learn comes with support for acquiring and generating datasets. The library even comes packaged with some datasets that are commonly used for exploring new models. Let’s look at some of the ways you can acquire data with scikit-learn: loading built-in datasets, fetching external ones, and generating synthetic data. This versatility makes it ideal for testing ECE algorithms against various data contexts without needing complex data acquisition setups initially."
  },
  {
    "objectID": "amli/03_00-04-regression.html#loading",
    "href": "amli/03_00-04-regression.html#loading",
    "title": "Machine Learning",
    "section": "Loading",
    "text": "Loading\n\n\n\n\n\n\n\nScikit-learn has a few datasets that are installed alongside the library. To access these datasets, you can rely on load functions like the load_iris function shown in this example. These are small, classic datasets ideal for quick demos and code verification."
  },
  {
    "objectID": "amli/03_00-04-regression.html#fetching",
    "href": "amli/03_00-04-regression.html#fetching",
    "title": "Machine Learning",
    "section": "Fetching",
    "text": "Fetching\n\n\n\n\n\n\n\nSome common datasets aren’t installed alongside scikit-learn, but the library does know how to access them. For these datasets, we use fetch functions, which pull the dataset down from the internet if necessary. This allows access to larger, more realistic datasets relevant to diverse engineering problems."
  },
  {
    "objectID": "amli/03_00-04-regression.html#generating",
    "href": "amli/03_00-04-regression.html#generating",
    "title": "Machine Learning",
    "section": "Generating",
    "text": "Generating\n\n\n\n\n\n\n\nFinally, sometimes it makes more sense to generate a dataset from scratch. This is particularly useful in ECE for simulating system responses, creating test cases for control algorithms, or understanding model behavior under idealized conditions. For this, we can use one of the many generator functions provided by scikit-learn, such as make_regression for linear regression tasks."
  },
  {
    "objectID": "amli/03_00-04-regression.html#bunches",
    "href": "amli/03_00-04-regression.html#bunches",
    "title": "Machine Learning",
    "section": "Bunches",
    "text": "Bunches\n\nBunch objects are scikit-learn objects that are often used to store datasets. If you find yourself using a load or fetch method, you’ll likely encounter a Bunch object. The lab for this lesson provides more details on Bunch objects and explores the data stored within them. You’ll encounter data that is composed of named features, as well as target values paired with sets of features.\nFor the most part, we will convert scikit-learn Bunch objects into Pandas DataFrame objects or TensorFlow dataset objects. The aforementioned objects are more easily integrated with the methods and frameworks we will cover in this course."
  },
  {
    "objectID": "amli/03_00-04-regression.html#estimators",
    "href": "amli/03_00-04-regression.html#estimators",
    "title": "Machine Learning",
    "section": "Estimators",
    "text": "Estimators\n\n\n\n\n\n\n\nMost of the models in scikit-learn are considered estimators. An estimator is expected to implement two methods: fit and predict.\n\nfit is used to train the model. At a minimum, it is passed the feature data used to train the model. In supervised models, it is also passed the target data.\npredict is used to get predictions from the model. This method is passed features and returns target predictions.\n\nThis consistent API design simplifies the process of swapping out different models for a given ECE problem, allowing engineers to quickly experiment with various ML approaches."
  },
  {
    "objectID": "amli/03_00-04-regression.html#transformers",
    "href": "amli/03_00-04-regression.html#transformers",
    "title": "Machine Learning",
    "section": "Transformers",
    "text": "Transformers\n\n\n\n\n\n\n\nIn practice, it is rare that you will get perfectly clean data that is ready to feed into your model for training. Most of the time you will need to perform some type of cleaning or preprocessing on the data first. This is especially true for ECE datasets, which might come from various sensors requiring normalization, filtering, or feature scaling.\nTransformers implement fit and transform methods. The fit method calculates parameters necessary to perform the data transformation (e.g., min/max values for scaling). transform actually applies the transformation. There is a convenience fit_transform method that performs both fitting and transformation in one method call."
  },
  {
    "objectID": "amli/03_00-04-regression.html#pipelines",
    "href": "amli/03_00-04-regression.html#pipelines",
    "title": "Machine Learning",
    "section": "Pipelines",
    "text": "Pipelines\n\n\n\n\n\n\n\nIt isn’t a coincidence that transformers have fit and transform methods and that models have fit methods. The common interface across classes allows scikit-learn to create pipelines for data processing and model building.\nA pipeline is simply a series of transformers, often with an estimator at the end. This allows for a streamlined, organized workflow, ensuring consistent data preprocessing steps are applied before training and prediction, which is critical for reproducible results in ECE experiments."
  },
  {
    "objectID": "amli/03_00-04-regression.html#metrics",
    "href": "amli/03_00-04-regression.html#metrics",
    "title": "Machine Learning",
    "section": "Metrics",
    "text": "Metrics\n\n\n\n\n\n\n\nScikit-learn also comes with many functions for measuring model performance, located in the metrics package.\nIn this case, we are calculating the mean squared error. (In the Introduction to Regression lesson, you saw L1, L2, and MSE). These metrics are crucial for quantifying the success of an ML model in ECE applications, e.g., evaluating the accuracy of a power prediction model or the precision of a control algorithm."
  },
  {
    "objectID": "amli/03_00-04-regression.html#your-turn",
    "href": "amli/03_00-04-regression.html#your-turn",
    "title": "Machine Learning",
    "section": "Your Turn",
    "text": "Your Turn\n\nIt may be helpful to scroll through the lab associated with this unit and point out to the students the key ideas we covered here. Now, let’s apply these scikit-learn concepts in a practical lab."
  },
  {
    "objectID": "amli/03_00-04-regression.html#linear-regression",
    "href": "amli/03_00-04-regression.html#linear-regression",
    "title": "Machine Learning",
    "section": "Linear Regression",
    "text": "Linear Regression\n\nLinear Regression Fit Animation\nRemember that linear regression involves fitting a straight line to a dataset. Most of the time, the line doesn’t fit perfectly for all data points. You can see in this illustration, the blue data points, the regression line, and then the red lines between the data points and the regression line. The red lines indicate the “error.” There are many ways to measure this error that we’ll talk about in detail in a future unit. This GIF helps visualize the goal of minimizing these errors."
  },
  {
    "objectID": "amli/03_00-04-regression.html#scikit-learn-using-linear-algebra",
    "href": "amli/03_00-04-regression.html#scikit-learn-using-linear-algebra",
    "title": "Machine Learning",
    "section": "scikit-learn: Using Linear Algebra",
    "text": "scikit-learn: Using Linear Algebra\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nThis is not a learning algorithm that iteratively optimizes. It’s a direct, closed-form solution.\n\n\n\n\nTo perform linear regression in scikit-learn without iterative learning, we use the LinearRegression class from the linear_model package. As you can see in this example, performing the regression is as simple as instantiating the class and then calling the fit() method. The model then directly calculates the coefficient and intercept for the linear equation using the closed-form solution we discussed earlier. This is efficient for smaller datasets or when GDRegressor convergence is not desired / needed."
  },
  {
    "objectID": "amli/03_00-04-regression.html#optimizers",
    "href": "amli/03_00-04-regression.html#optimizers",
    "title": "Machine Learning",
    "section": "Optimizers",
    "text": "Optimizers\n\n(Batch) Gradient Descent\nStochastic Gradient Descent (SGD)\nMini-Batch Gradient Descent\n\n\nRecall that our overall goal is to learn parameters that minimize a particular cost/loss function. There are many ways to perform this optimization, but gradient descent is a very popular choice. At a high level, we use the gradient (i.e. the derivative/slope) of the cost function to determine the direction to adjust the parameters. In other words, if we want to get to the bottom of the hill, we walk in the direction of the steepest downward slope.\n\nBatch Gradient Descent: The entire dataset is used to calculate the gradient during each iteration of training. This can be computationally expensive for large datasets.\nStochastic Gradient Descent (SGD): We randomly choose one data point from our training set to compute the gradient at each iteration (i.e. we use a batch-size of 1). This introduces more noise but can be much faster per iteration.\nMini-Batch Gradient Descent: A middle ground between batch and stochastic gradient descent, using a fixed number of training samples (greater than 1, but less than the entire dataset) to compute the gradient during each iteration. This combines the speed of SGD with some stability.\n\nThese various methods mirror iterative optimization techniques used in ECE for adaptive systems or circuit design (e.g., tuning filters)."
  },
  {
    "objectID": "amli/03_00-04-regression.html#scikit-learn-stochastic-gradient-descent",
    "href": "amli/03_00-04-regression.html#scikit-learn-stochastic-gradient-descent",
    "title": "Machine Learning",
    "section": "scikit-learn: Stochastic Gradient Descent",
    "text": "scikit-learn: Stochastic Gradient Descent\n\n\n\n\n\n\n\nUsing stochastic gradient descent looks strikingly similar to using LinearRegression. This is no accident. Scikit-learn’s API is very consistent, simplifying learning and application.\nIn this example, we load the data into memory, perform SGD (fit method), and then print out the coefficient and intercept.\nNote that this might not be the absolute optimal coefficient and intercept; it’s the best one that the SGD algorithm found after running through its epochs and iterations, within its convergence criteria. This is a common characteristic of iterative optimization in ECE."
  },
  {
    "objectID": "amli/03_00-04-regression.html#scikit-learn-sgd-hyperparameters",
    "href": "amli/03_00-04-regression.html#scikit-learn-sgd-hyperparameters",
    "title": "Machine Learning",
    "section": "scikit-learn: SGD Hyperparameters",
    "text": "scikit-learn: SGD Hyperparameters\n\n\n\n\n\n\n\nThere aren’t really any hyperparameters to tune for LinearRegression (the closed-form solution). SGDRegressor, however, has many hyperparameters that can be tuned. You can see some of those hyperparameters in use here:\n\nmax_iter: The maximum number of passes over the training data (epochs). Sometimes training more can improve performance.\nn_iter_no_change: Manages “early stopping.” If loss doesn’t meaningfully improve for this many iterations, training stops.\ntol: The tolerance for loss improvement to trigger early stopping.\nlearning_rate: Affects how much the weights are adjusted during each step. ‘adaptive’ means it adjusts dynamically. Different learning rate schedules are crucial in ECE control systems for stability or convergence speed.\n\nThere are many more hyperparameters that can be found in the SGDRegressor documentation, allowing for fine-grained control over the optimization process, similar to tuning intricate analog circuits."
  },
  {
    "objectID": "amli/03_00-04-regression.html#scikit-learn-sgd-partial_fit",
    "href": "amli/03_00-04-regression.html#scikit-learn-sgd-partial_fit",
    "title": "Machine Learning",
    "section": "scikit-learn: SGD partial_fit",
    "text": "scikit-learn: SGD partial_fit\nfrom sklearn.linear_model import SGDRegressor\n\nsgd_reg = SGDRegressor()\nsgd_reg.partial_fit(X_1, y_1)\nsgd_reg.partial_fit(X_2, y_2)\n...\nsgd_reg.partial_fit(X_n, y_n)\nsgd_reg.coef_, sgd_reg.intercept_\n\n\n\n\n\n\n\nAnother capability of the SGDRegressor is the ability to partially train the model. This can be useful if your data doesn’t fit into memory, or if you’re working with streaming data. You can continually call partial_fit with subsets of the full dataset.\nThis is highly relevant in ECE for embedded systems, real-time control, or sensor networks where data arrives continuously and cannot be stored entirely. partial_fit allows the model to learn incrementally."
  },
  {
    "objectID": "amli/03_00-04-regression.html#loss",
    "href": "amli/03_00-04-regression.html#loss",
    "title": "Machine Learning",
    "section": "Loss",
    "text": "Loss\nMean Squared Error\n\\[ MSE = \\frac{1}{n} \\sum_{n=1}^{n}(y_{i} - \\hat{y_{i}})^{2} \\]\n\nWe’ll get into loss and different ways to measure it in later units. For this unit we’ll calculate loss using the mean squared error. The mean squared error is the measure of the values that our model predicts vs. what the values actually are. The differences are calculated, squared to get rid of negatives, and summed so that the average squared error can be found. This measure is crucial for quantifying the performance of ECE systems, from signal reconstruction errors to predictive modeling accuracy."
  },
  {
    "objectID": "amli/03_00-04-regression.html#trainvalidate-test",
    "href": "amli/03_00-04-regression.html#trainvalidate-test",
    "title": "Machine Learning",
    "section": "Train/Validate, Test",
    "text": "Train/Validate, Test\n\nTrain, Validate, Test Split\nThis lab will also be the first time we’ll need to split our data for model training.\nWhen we train a model, we could use all of the data that we have. When we do that, however, we risk overfitting the model to our data, and we lose the ability to test our model on “new” data it hasn’t seen. The model might become really good at making predictions that look like the data that it has already seen, but really bad at generalizing.\nFor this reason we typically hold out some of the data and don’t use it to train the model at all. We keep this “test set” of data and use it only to evaluate the model after training has completed. We pass the trained models the features in the test set, get the predictions from the model, and then calculate the difference between the predictions and the actual values.\nThe concept of a validation set is also important. The validation set is used during training to let the optimizer evaluate the model. The loss calculated with the validation set directly affects decisions the model makes. This practice is akin to rigorous testing of an ECE prototype against a test bench and then against real-world scenarios before deployment."
  },
  {
    "objectID": "amli/03_00-04-regression.html#trainvalidate-test-validate",
    "href": "amli/03_00-04-regression.html#trainvalidate-test-validate",
    "title": "Machine Learning",
    "section": "Train/Validate, Test, Validate",
    "text": "Train/Validate, Test, Validate\n\nDouble Validation Process\nThe holdout data story gets more complicated when hyperparameter tuning is involved. When you tune hyperparameters, you’ll still have the same training and validating data available during model fitting. Then you’ll use your test data to see how well the model generalizes. With that said, if you then change hyperparameters and test again, you risk over-tuning hyperparameters to the test data set.\nIn order to prevent this, many data scientists also keep another holdout dataset called the validation dataset (often called a “holdout validation set” or “dev set” to distinguish from the training-time validation set). This dataset is used for one final check after you have selected hyperparameters and before final deployment. This multi-layered validation ensures the model’s robustness, similar to multiple stages of verification and validation in ECE product lifecycle management."
  },
  {
    "objectID": "amli/03_00-04-regression.html#your-turn-1",
    "href": "amli/03_00-04-regression.html#your-turn-1",
    "title": "Machine Learning",
    "section": "Your Turn",
    "text": "Your Turn\n\nLet’s now build a few different linear regression models using scikit-learn in our lab exercise. You’ll apply these concepts to practical ECE datasets."
  },
  {
    "objectID": "amli/03_00-04-regression.html#coefficient-of-determination-r2",
    "href": "amli/03_00-04-regression.html#coefficient-of-determination-r2",
    "title": "Machine Learning",
    "section": "Coefficient of Determination (\\(R^2\\))",
    "text": "Coefficient of Determination (\\(R^2\\))\n\\[ SS_{res} = \\sum_{i}(y_i - \\hat{y_i})^2 \\] \\[ \\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n}y_{i} \\] \\[ SS_{tot} = \\sum_{i}(y_{i}-\\bar{y})^2 \\] \\[ R^{2} = 1 - \\frac{SS_{res}}{SS_{tot}} \\]\n\nThe coefficient of determination, denoted \\(R^2\\), is one of the most important metrics in regression. It tells us how much of the data is “explained” by the model. This is very useful in ECE to understand how well a model captures the underlying physics or behavior of an electronic component or system.\nBefore we can define the metric itself, we need to define a few other key terms: * Residual sum of squares (\\(SS_{res}\\)): The summation of the square of every difference between the target value \\(y_i\\) and the predicted value \\(\\hat{y_i}\\). * Total sum of squares (\\(SS_{tot}\\)): The sum of the squared differences between each value \\(y_i\\) and their mean \\(\\bar{y}\\).\nGiven these, we can calculate \\(R^2\\). The \\(R^2\\) score measures how well the actual variance from \\(x\\)-values to \\(y\\)-values is represented in the variance between the \\(x\\)-values and the predicted \\(\\hat{y}\\)-values.\nTypically, this score ranges from 0 to 1, where 0 is bad and 1 is a perfect mapping. However, the score can also be negative. This happens if a simple horizontal line through the mean \\(\\bar{y}\\) performs better than your regression, meaning your model is truly terrible and needs serious revision. For values in the range 0-1, interpreting the \\(R^2\\) is more subjective. The closer to 0, the worse your model is at fitting the data. And generally, the closer to 1, the better. But you also don’t want to overfit, which we’ll discuss later."
  },
  {
    "objectID": "amli/03_00-04-regression.html#mean-squared-error-mse",
    "href": "amli/03_00-04-regression.html#mean-squared-error-mse",
    "title": "Machine Learning",
    "section": "Mean Squared Error (MSE)",
    "text": "Mean Squared Error (MSE)\n\\[ MSE = \\frac{1}{n} \\sum_{n=1}^{n}(y_{i} - \\hat{y_{i}})^{2} \\]\n\nThe mean squared error is the measure of the values that our model predicts vs. what the values actually are. The differences are calculated, squared to get rid of negatives, and summed so that the average squared error can be found.\nWhat is a good MSE value? The answer really depends how perfect you want your model to be. The values of MSE are a little difficult to interpret, though. Since they are the square of the error, the units don’t match the units of the target in our model (e.g., if predicting voltage in volts, MSE is in volts-squared). This is fine for machines training the model, but it’s nearly impossible for an engineer to intuitively reason about afterward.\nThere is a solution, though."
  },
  {
    "objectID": "amli/03_00-04-regression.html#root-mean-squared-error-rmse",
    "href": "amli/03_00-04-regression.html#root-mean-squared-error-rmse",
    "title": "Machine Learning",
    "section": "Root Mean Squared Error (RMSE)",
    "text": "Root Mean Squared Error (RMSE)\n\\[ RMSE = \\sqrt{\\frac{1}{n} \\sum_{n=1}^{n}(y_{i} - \\hat{y_{i}})^{2}} \\]\n\n\n\n\n\n\nNote\n\n\nRMSE returns the error in the original units of the target variable for easier interpretation.\n\n\n\n\nThe root mean squared error is simply the square root of the mean squared error. It adjusts the units of the error back to the units of the target, which makes model quality much easier to reason about directly.\nFor instance, if you have a model that predicted the output voltage of a power supply, and it had an RMSE of 0.1V, that would tell an ECE engineer that, on average, the predictions are off by 0.1 volts. If the target voltage was 5V, this error might be acceptable, but if it was 0.5V, it might be too high. This direct interpretability is why RMSE is often preferred when discussing model accuracy in engineering contexts."
  },
  {
    "objectID": "amli/03_00-04-regression.html#mean-absolute-error-mae",
    "href": "amli/03_00-04-regression.html#mean-absolute-error-mae",
    "title": "Machine Learning",
    "section": "Mean Absolute Error (MAE)",
    "text": "Mean Absolute Error (MAE)\n\\[ MAE = \\frac{1}{n} \\sum_{n=1}^{n}(|y_{i} - \\hat{y_{i}}|) \\]\n\nMean absolute error is calculated similarly to mean squared error. Instead of using squaring to remove negative values, the absolute value of the difference in actual and predicted values is taken.\nA benefit of MAE is that the units remain the same as that of the target, similar to RMSE.\nThe primary difference in MAE and MSE/RMSE is that MSE/RMSE squares the error, which gives larger differences in value and much higher error scores, effectively giving extra penalty to really bad predictions (outliers). MAE treats all errors linearly. In ECE, choosing between MAE and RMSE often depends on whether large errors should be heavily penalized (RMSE) or if all errors are considered equally important magnitude-wise (MAE)."
  },
  {
    "objectID": "amli/03_00-04-regression.html#predicted-vs.-actual-plots",
    "href": "amli/03_00-04-regression.html#predicted-vs.-actual-plots",
    "title": "Machine Learning",
    "section": "Predicted vs. Actual Plots",
    "text": "Predicted vs. Actual Plots\n\nGood Predicted vs Actual Plot\nThere are numerous ways to visualize regression predictions, but one of the most basic and intuitive is the “predicted vs. actual” plot. Here, we plot the actual target values on one axis and the model’s predicted values for those targets on the other. A perfect model would have all points lying directly on the y=x line.\nIn this case, the data points scatter pretty evenly around the prediction-to-actual line (i.e., the line y=x, where the actual and prediction are equal). This indicates a good fit without significant bias.\nSo what does a bad plot look like?"
  },
  {
    "objectID": "amli/03_00-04-regression.html#predicted-vs.-actual-plots-positive-bias",
    "href": "amli/03_00-04-regression.html#predicted-vs.-actual-plots-positive-bias",
    "title": "Machine Learning",
    "section": "Predicted vs. Actual Plots (Positive Bias)",
    "text": "Predicted vs. Actual Plots (Positive Bias)\n\nPredicted vs Actual Plot with Positive Bias\nNow we have a situation where there is an obvious bias. All predictions are consistently higher than the actual values (lying below the y=x line, meaning Predicted &gt; Actual). This suggests the model needs to be adjusted to make smaller predictions across the board. Such biases are critical to identify in ECE, as they could indicate systematic errors in sensor calibration or system modeling."
  },
  {
    "objectID": "amli/03_00-04-regression.html#residual-plots",
    "href": "amli/03_00-04-regression.html#residual-plots",
    "title": "Machine Learning",
    "section": "Residual Plots",
    "text": "Residual Plots\n\nGood Residual Plot\nAnother helpful visualization tool is plotting the regression residuals. As a reminder, residuals are the difference between the actual values and the predicted values (y - y_pred).\nWe plot residuals on the y-axis against the predicted values on the x-axis and draw a horizontal line through y=0. Ideally, residuals should be randomly scattered around zero, indicating no systematic pattern in the errors, and that the model has captured the underlying relationship well."
  },
  {
    "objectID": "amli/03_00-04-regression.html#residual-plots-bias-example",
    "href": "amli/03_00-04-regression.html#residual-plots-bias-example",
    "title": "Machine Learning",
    "section": "Residual Plots (Bias Example)",
    "text": "Residual Plots (Bias Example)\n\nResidual Plot with Bias\nCases where our predictions were too low appear above the zero line (positive residuals). Cases where our predictions were too high appear below the zero line (negative residuals).\nIn the “predicted vs. actual” section above, we plotted a case where there was a large positive bias in our predictions (model consistently overpredicts). Plotting the same biased data on a residual plot shows all of the residuals falling below the zero line. This clear pattern in residuals indicates a systemic issue with the model, which an ECE engineer would seek to diagnose and correct."
  },
  {
    "objectID": "amli/03_00-04-regression.html#your-turn-2",
    "href": "amli/03_00-04-regression.html#your-turn-2",
    "title": "Machine Learning",
    "section": "Your Turn",
    "text": "Your Turn\n\nLet’s now move on to the lab portion of the unit. In this lab, you’ll create and interpret various measures and visualizations of regression model quality. This is a practical skill for any ECE professional working with data-driven systems."
  },
  {
    "objectID": "amli/03_00-04-regression.html#outline",
    "href": "amli/03_00-04-regression.html#outline",
    "title": "Machine Learning",
    "section": "Outline",
    "text": "Outline\n\nRecall Linear Regression\nPolynomial Regression: What is it and how is it different (or not so different)?\nCaution! Dangers of polynomial regression!\n\n\n\n\n\n\n\nTip\n\n\nUnderstanding when and how to use polynomial regression is key to modeling complex system behaviors in ECE."
  },
  {
    "objectID": "amli/03_00-04-regression.html#polynomial-equations",
    "href": "amli/03_00-04-regression.html#polynomial-equations",
    "title": "Machine Learning",
    "section": "Polynomial Equations",
    "text": "Polynomial Equations\n\nExamples of Polynomial Equations\nHere are a few examples of polynomial equations. The topmost is the linear equation we are used to (degree 1). The next is commonly called a quadratic equation (degree 2). The third is a cubic equation (degree 3). The number of factors (or the ‘degree’ of the polynomial) you can add to the equation is theoretically unbounded, though you’ll pay a computational expense for polynomials of higher degree and also increase the risk of overfitting, which we’ll discuss soon."
  },
  {
    "objectID": "amli/03_00-04-regression.html#polynomial-regression-linear-regression",
    "href": "amli/03_00-04-regression.html#polynomial-regression-linear-regression",
    "title": "Machine Learning",
    "section": "Polynomial Regression = Linear Regression",
    "text": "Polynomial Regression = Linear Regression\nTurn the original polynomial regression problem into a polynomial regression problem with multiple features.\n\n\n\n\n\n\n\nG\n\n\n\nInput_x\n\nOriginal Feature (x)\n\n\n\nTransformation\n\nPolynomial Feature\nTransformation\n\n\n\nInput_x-&gt;Transformation\n\n\nApplies powers\n\n\n\nFeatures_X_prime\n\n\nTransformed Features\n([1, x, x^2, x^3, ...])\n\n\n\nTransformation-&gt;Features_X_prime\n\n\nNew Features (X')\n\n\n\nLinear_Regression_Model\n\nLinear Regression Model\n(w_0, w_1, w_2, w_3, ...)\n\n\n\nFeatures_X_prime-&gt;Linear_Regression_Model\n\n\nInput for fitting\n\n\n\nOutput_y_hat\n\nPredicted Target (y_hat)\n\n\n\nLinear_Regression_Model-&gt;Output_y_hat\n\n\nPrediction\n\n\n\n\n\n\n\n\n\nTo find the weights and biases for a polynomial regression model, we recast the problem as a multivariate linear regression problem. This is a key insight: We are not changing the linear regression algorithm itself. Instead, we are changing the input features.\nFor example, if we want a order-2 polynomial \\(y = w_0 + w_1 x + w_2 x^2\\), we take our original feature x and create new features: x_1 = x and x_2 = x^2. Then, the problem becomes a linear regression y = w_0 + w_1 x_1 + w_2 x_2. The machine learning algorithm still learns linear weights for these new, transformed features. This technique of feature engineering is very important in ECE for transforming raw sensor data into more meaningful inputs for ML models."
  },
  {
    "objectID": "amli/03_00-04-regression.html#overfitting",
    "href": "amli/03_00-04-regression.html#overfitting",
    "title": "Machine Learning",
    "section": "Overfitting",
    "text": "Overfitting\n\nWe will now explore the potential dangers of using higher-order polynomial fits. While they can capture non-linear relationships, they pose a significant risk of ‘overfitting’ the data."
  },
  {
    "objectID": "amli/03_00-04-regression.html#overfitting-analogy-clothing-fit",
    "href": "amli/03_00-04-regression.html#overfitting-analogy-clothing-fit",
    "title": "Machine Learning",
    "section": "Overfitting Analogy: Clothing Fit",
    "text": "Overfitting Analogy: Clothing Fit\n\nWell-fitting shirt\nLet’s think of overfitting by looking into clothing. Here, we have a person wearing a reasonably well-fitting shirt. It’s comfortable, covers well, and fits a typical body shape, allowing for some variation without being loose. This is like a well-generalized model."
  },
  {
    "objectID": "amli/03_00-04-regression.html#how-do-we-avoid-this",
    "href": "amli/03_00-04-regression.html#how-do-we-avoid-this",
    "title": "Machine Learning",
    "section": "How Do We Avoid This?",
    "text": "How Do We Avoid This?\n\nGiven the problem of a polynomial fitting data too closely (overfitting), how would you avoid it? Give students some time to throw out some ideas. This is a crucial design challenge in ECE when trying to build robust and generalizable ML systems for signal processing, control, or embedded intelligence."
  },
  {
    "objectID": "amli/03_00-04-regression.html#avoiding-overfitting",
    "href": "amli/03_00-04-regression.html#avoiding-overfitting",
    "title": "Machine Learning",
    "section": "Avoiding Overfitting",
    "text": "Avoiding Overfitting\n\nSimpler polynomial\nMore training data\nDropping out some training data (e.g., regularization)\nOverfitting penalties (regularization)\n\n\n\n\n\n\n\nImportant\n\n\nRegularization is a key technique to manage overfitting by adding penalties to model complexity.\n\n\n\n\nHere are some of the most common ways to avoid overfitting:\n\nUsing a polynomial function with fewer degrees: If your model is introducing enough curvature to cross most training data points, then use fewer degrees in your polynomial. This reduces model complexity.\nMore training data: As your dataset grows in size, it will likely also grow in diversity and create a model that is less overfitted because it sees more variations. This can be challenging for ECE systems where data collection is expensive.\nDropping out some training data (or features): Sometimes removing less informative features or artificially simplifying the input can help.\nOverfitting penalties (regularization): There are strategies for adding penalties to the model that make even a high-degree polynomial less likely to overfit. Some common strategies are called Lasso, Ridge, and ElasticNet. We’ll look at each of these more closely, and you’ll experiment with them in your lab exercise. Regularization can be seen as introducing a “cost” for excessive model complexity."
  },
  {
    "objectID": "amli/03_00-04-regression.html#regularization",
    "href": "amli/03_00-04-regression.html#regularization",
    "title": "Machine Learning",
    "section": "Regularization",
    "text": "Regularization\n\nRegularization is a method of “shrinking” the coefficients (weights) in the learned equation. This process discourages overly complex models that fit the noise in the training data rather than the underlying signal. There are many types of regularizers, but we will look at the most common ones here: Lasso, Ridge, and ElasticNet. These methods are indispensable in ECE for developing robust models, especially in areas like predictive maintenance or system fault diagnosis where generalization is critical."
  },
  {
    "objectID": "amli/03_00-04-regression.html#recall-mean-squared-error",
    "href": "amli/03_00-04-regression.html#recall-mean-squared-error",
    "title": "Machine Learning",
    "section": "Recall: Mean Squared Error",
    "text": "Recall: Mean Squared Error\n\nMean Squared Error Formula Breakdown\nAs a reminder, this is the equation of a common loss function, the mean squared error. Let’s break down its components in the context of our linear algebra notation:\n\nLine 1: (y_true - y_pred) is the error between the true target and the predicted target from the model.\nLine 2: Recall that y_pred came from a linear regression equation, which can be written in matrix notation as X * theta.\nLine 3: Completing the matrix multiplication and writing the multivariate regression formula using detailed notation:\n\nn = number of rows in the training data\np = number of coefficients in the equation (also number of features + bias term)\ny_true = true target value\ntheta_0 = intercept (bias)\ntheta_j = coefficients (weights) of the polynomial equation\nx_i = feature values\n\n\nThis foundation helps us understand how regularization will modify this loss function."
  },
  {
    "objectID": "amli/03_00-04-regression.html#lasso-l1-regularization",
    "href": "amli/03_00-04-regression.html#lasso-l1-regularization",
    "title": "Machine Learning",
    "section": "Lasso (L1) Regularization",
    "text": "Lasso (L1) Regularization\n\nLasso (L1) Regularization Formula\nWhat does it mean to shrink coefficients? It effectively means to increase the value of the loss function as the coefficients get larger.\nLasso is L1 regression. This means that it adds the sum of the absolute values of the coefficients (multiplied by a regularization parameter \\(\\lambda\\)) to the original MSE loss function. We can see that by adding lambda * |theta_j| (a positive number), the cost function is always slightly larger than the regular MSE loss function for any non-zero theta_j. This regularization term forces the model to make theta_j values smaller.\nSmaller coefficients make the model “more linear” or less sensitive to specific features. For example, in a high-degree polynomial, if theta_2 and theta_3 become very small, their terms have less impact on the curve.\nLAGSO is an acronym for “Least Absolute Shrinkage and Selection Operator.”\nDue to the absolute value function, L1 regularization has a unique property: it can drive some coefficients exactly to zero. This means L1 regularization can perform feature selection, effectively identifying and ignoring less important features. This is highly useful in ECE for reducing model complexity and identifying critical system parameters."
  },
  {
    "objectID": "amli/03_00-04-regression.html#ridge-l2-regularization",
    "href": "amli/03_00-04-regression.html#ridge-l2-regularization",
    "title": "Machine Learning",
    "section": "Ridge (L2) Regularization",
    "text": "Ridge (L2) Regularization\n\nRidge (L2) Regularization Formula\nRidge regularization looks similar to Lasso, but instead of appending the sum of absolute values of coefficients to the loss function, it appends the sum of their squares. This is also multiplied by a regularization parameter \\(\\lambda\\).\nRidge regularization also shrinks coefficients towards zero, but it tends to shrink them proportionally. Unlike Lasso, L2 regularization rarely drives coefficients exactly to zero; it prefers to reduce their magnitude without fully eliminating them.\nSince the L2 norm (sum of squares) is differentiable, problems using this method can be solved efficiently by gradient descent, making it computationally attractive. In ECE, Ridge regression helps stabilize models in the presence of multicollinearity (highly correlated features), which is common in sensor data fusion."
  },
  {
    "objectID": "amli/03_00-04-regression.html#elasticnet-l1-l2",
    "href": "amli/03_00-04-regression.html#elasticnet-l1-l2",
    "title": "Machine Learning",
    "section": "ElasticNet (L1 + L2)",
    "text": "ElasticNet (L1 + L2)\n\nElasticNet is a regularization technique that combines both L1 (Lasso) and L2 (Ridge) penalties. It includes both the sum of the absolute values of coefficients and the sum of their squares in the loss function.\nThis combination allows ElasticNet to benefit from both methods: it can perform feature selection (like Lasso) by shrinking some coefficients to zero, while also handling groups of correlated features gracefully (like Ridge). This makes ElasticNet a robust choice in many real-world ECE applications where datasets might have many features, some of which are correlated, and model sparsity is desired."
  },
  {
    "objectID": "amli/03_00-04-regression.html#which-regularization-is-best",
    "href": "amli/03_00-04-regression.html#which-regularization-is-best",
    "title": "Machine Learning",
    "section": "Which Regularization Is Best?",
    "text": "Which Regularization Is Best?\n\n\n\n\n\n\nCaution\n\n\nThe choice of regularization often depends on the specific dataset and problem. Experimentation is key!\n\n\n\n\nIt depends on the specific characteristics of your data and your modeling goals:\n\nL1 regularization (Lasso):\n\nCan drive coefficients to zero, and it tends to produce a sparse model (i.e., many coefficients are zero).\nIts unique ability to eliminate irrelevant features makes it useful for feature selection.\n\nL2 regularization (Ridge):\n\nIs less likely to drive coefficients exactly to zero; it shrinks them proportionally.\nInstead, it tends to produce a more dense model (most coefficients are small but non-zero).\nEffective at handling multicollinearity (highly correlated features).\n\nElasticNet:\n\nAs a compromise between L1 and L2, it often works well in situations where there are multiple correlated features or when feature selection is important.\n\n\nIt is probably worth experimenting with each method to see which works best for your particular model, considering performance, interpretability, and computational resources, especially in diverse ECE problem domains."
  },
  {
    "objectID": "amli/03_00-04-regression.html#your-turn-3",
    "href": "amli/03_00-04-regression.html#your-turn-3",
    "title": "Machine Learning",
    "section": "Your Turn",
    "text": "Your Turn\n\nNow that we’ve covered polynomial regression and regularization techniques, it’s time to apply these concepts in a hands-on lab. You’ll experiment with fitting complex curves and battling overfitting, essential skills for robust system modeling in ECE."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is Signals and Systems Course Notes."
  },
  {
    "objectID": "amli/03_05-09-regression.html#what-is-tensorflow-good-for",
    "href": "amli/03_05-09-regression.html#what-is-tensorflow-good-for",
    "title": "Machine Learning",
    "section": "What Is TensorFlow Good For?",
    "text": "What Is TensorFlow Good For?\n\nNeural Networks: Advanced architectures, key for modern ML breakthroughs.\nDistributed Computing: Handles massive datasets across multiple machines.\nGPU and TPU Support: Specialized hardware acceleration for faster training.\n\n\nWe’ve been humming along pretty nicely performing machine learning tasks with NumPy, Pandas, and scikit-learn. Is TensorFlow really necessary?\nWe have been able to do quite a bit with the tools that we’ve seen so far. What TensorFlow adds to the equation is better support for neural networks. Neural networks are the technology behind many of the breakthroughs in machine learning we’ve seen in recent years. We’ll learn more about neural networks soon.\nTensorFlow also provides support for distributed computing. Machine learning algorithms thrive with big data. TensorFlow helps you process massive amounts of data, across many machines if necessary.\nTensorFlow also provides support for graphical processing units (GPUs) and tensor processing units (TPUs). These are specialized microprocessors that can really accelerate machine learning.\nThat being said, TensorFlow isn’t the only toolkit that fills this space. Other options like Torch and Microsoft Cognitive Toolkit (CNTK), as well as many others, provide powerful machine learning capabilities."
  },
  {
    "objectID": "amli/03_05-09-regression.html#tensor",
    "href": "amli/03_05-09-regression.html#tensor",
    "title": "Machine Learning",
    "section": "Tensor",
    "text": "Tensor\nAn N-dimensional array of data\n\nTensor\nSo where does the name TensorFlow come from?\nIn math, a simple number like 3 or 5 is called a scalar.\nA vector is a one-dimensional array of numbers. In physics, a vector is something with magnitude and direction. In computer science, you use vector to mean 1D arrays.\nA two-dimensional array is a matrix.\nA three-dimensional array? These can be called cubes.\nAnd four-dimensional? That is typically just called a 4d or Rank-4 tensor.\nBut it doesn’t have to stop there. You can create tensors with an arbitrarily high number of dimensions.\nSo we now understand why the “tensor” part of the name exists, but what about “flow?”\nTypically a sequence of operations is performed on tensors in a model. These tensors “flow” through the graph that constitutes the model, hence “TensorFlow.”"
  },
  {
    "objectID": "amli/03_05-09-regression.html#tensorflow-graphs",
    "href": "amli/03_05-09-regression.html#tensorflow-graphs",
    "title": "Machine Learning",
    "section": "TensorFlow: Graphs",
    "text": "TensorFlow: Graphs\n\nGraphs\nTensorFlow internally constructs a graph of operations that it uses to perform machine learning tasks."
  },
  {
    "objectID": "amli/03_05-09-regression.html#tensorflow-graphs-1",
    "href": "amli/03_05-09-regression.html#tensorflow-graphs-1",
    "title": "Machine Learning",
    "section": "TensorFlow: Graphs",
    "text": "TensorFlow: Graphs\n\nGraphs\nThe edges of the graph represent tensors of data flowing through the graph."
  },
  {
    "objectID": "amli/03_05-09-regression.html#tensorflow-graphs-2",
    "href": "amli/03_05-09-regression.html#tensorflow-graphs-2",
    "title": "Machine Learning",
    "section": "TensorFlow: Graphs",
    "text": "TensorFlow: Graphs\n\nGraphs\nThese graphs pass through data in order to learn weights and biases."
  },
  {
    "objectID": "amli/03_05-09-regression.html#tensorflow-versions",
    "href": "amli/03_05-09-regression.html#tensorflow-versions",
    "title": "Machine Learning",
    "section": "TensorFlow: Versions",
    "text": "TensorFlow: Versions\n\n\nTensorFlow 1\n\nLazy execution by default\nAwkward programming model\n\n\nTensorFlow 2\n\nEager execution by default\nKeras programming model\n\n\n\nVersion 1 of TensorFlow really emphasized the concept of graphs. It used a “lazy” execution model where you build a graph completely before anything is run. This graph was then put into a session where data was passed through the model.\nThis programming model worked, but it was a little clunky. Luckily, a library called Keras showed that machine learning models could be built and trained using a more natural eager execution model.\nTensorFlow 2 was officially released in late 2019. TensorFlow 2 still supports much of the older programming model through a compatibility layer, but, if possible, new programs should be written in TensorFlow 2’s Keras API style.\nTensorFlow 1 placed more of an emphasis on the concept of estimators (similar to scikit-learn). They are still supported in TensorFlow 2 and will continue to be for the indefinite future."
  },
  {
    "objectID": "amli/03_05-09-regression.html#tensorflow-is-separated-into-abstraction-layers",
    "href": "amli/03_05-09-regression.html#tensorflow-is-separated-into-abstraction-layers",
    "title": "Machine Learning",
    "section": "TensorFlow Is Separated Into Abstraction Layers",
    "text": "TensorFlow Is Separated Into Abstraction Layers\n\nTensorFlow Abstraction\nTensorFlow is actually not written in Python, but is instead a C++ library. The Python library we use is a wrapper over the C++ with even more abstraction layers added on top of it. For this class we’ll be using the “Core TensorFlow (Python)” layer and above."
  },
  {
    "objectID": "amli/03_05-09-regression.html#your-turn",
    "href": "amli/03_05-09-regression.html#your-turn",
    "title": "Machine Learning",
    "section": "Your Turn!",
    "text": "Your Turn!\n\n\n\n\n\n\nNote\n\n\nExercise: Explore basic tensor operations in TensorFlow.\n\n\n\n\nIn this lab you’ll get a brief introduction to tensors and operators. The goal is to get you familiar working with the core objects of TensorFlow. Soon we will be using higher-level APIs. The Tensor objects themselves are sometimes exposed in these higher-level APIs, though, so it is a good idea to at least be familiar with them."
  },
  {
    "objectID": "amli/03_05-09-regression.html#but-why",
    "href": "amli/03_05-09-regression.html#but-why",
    "title": "Machine Learning",
    "section": "But Why?",
    "text": "But Why?\n\nScalability: Handling huge datasets and distributed training.\nUnified Ecosystem: Prepares for advanced deep learning tasks.\nLearning Tool: Practice with familiar concepts in a new framework.\n\n\nWhy would we want to build a linear regression using TensorFlow?\nIt’s true that scikit-learn is perfectly good at linear regression most of the time. However, TensorFlow has some features like distributed model training that can help you build models when you have huge amounts of data. It is also useful to learn a new tool by practicing on content that you are familiar with."
  },
  {
    "objectID": "amli/03_05-09-regression.html#linearregressor",
    "href": "amli/03_05-09-regression.html#linearregressor",
    "title": "Machine Learning",
    "section": "LinearRegressor",
    "text": "LinearRegressor\nAn implementation of Estimator\n\nIn this lab we’ll be using the LinearRegressor class. LinearRegressor is an Estimator. Estimator is an API and programming model that was introduced in TensorFlow version 1. It is a little more difficult to use than modern Keras-style TensorFlow, but you will still see it used in practice, and support for it will continue in TensorFlow 2 because the Estimator-style of programming works better for some specific machine learning applications."
  },
  {
    "objectID": "amli/03_05-09-regression.html#linearregressor-1",
    "href": "amli/03_05-09-regression.html#linearregressor-1",
    "title": "Machine Learning",
    "section": "LinearRegressor",
    "text": "LinearRegressor\nimport tensorflow as tf\n\n# Define feature columns (e.g., numeric_column, categorical_column_with_vocabulary_list)\nfeature_columns = [\n    tf.feature_column.numeric_column(\"feature1\"),\n    tf.feature_column.numeric_column(\"feature2\")\n]\n\nlr = tf.estimator.LinearRegressor(\n    feature_columns=feature_columns\n)\n\n# Dummy input functions for demonstration\ndef training_input():\n    features = {\"feature1\": [1.0, 2.0], \"feature2\": [10.0, 20.0]}\n    labels = [30.0, 40.0]\n    return tf.data.Dataset.from_tensor_slices((features, labels)).batch(1)\n\ndef testing_input():\n    features = {\"feature1\": [3.0, 4.0], \"feature2\": [30.0, 40.0]}\n    return tf.data.Dataset.from_tensor_slices(features).batch(1)\n\nlr.train(input_fn=training_input, steps=1) # Train for a single step for demo\n\np = lr.predict(input_fn=testing_input)\n# print(list(p)) # Uncomment to see predictions\n\nHere you can see the main programming flow of the LinearRegressor.\nWe: 1. Import TensorFlow. 2. Create an estimator class, defining the feature columns. 3. Train the estimator by passing it a function that provides data. 4. Use the model by passing it a function that provides data for prediction.\nThis pyodide block provides a runnable example of this basic flow. You can modify feature columns or input data to see how it might work practically."
  },
  {
    "objectID": "amli/03_05-09-regression.html#linearregressor-training-function-details",
    "href": "amli/03_05-09-regression.html#linearregressor-training-function-details",
    "title": "Machine Learning",
    "section": "LinearRegressor: Training Function Details",
    "text": "LinearRegressor: Training Function Details\nimport tensorflow as tf\nimport pandas as pd\n\n# Dummy DataFrame for demonstration\ntraining_df = pd.DataFrame({\n    \"MedInc\": [1.0, 2.0, 3.0, 4.0, 5.0],\n    \"HouseAge\": [10.0, 20.0, 30.0, 40.0, 50.0],\n    \"target_charges\": [100.0, 150.0, 200.0, 250.0, 300.0]\n})\nfeature_columns = [\"MedInc\", \"HouseAge\"]\ntarget_column = \"target_charges\"\n\ndef training_input():\n  ds = tf.data.Dataset.from_tensor_slices((\n    {c: training_df[c].values for c in feature_columns},  # feature map\n    training_df[target_column].values                     # labels\n  ))\n  ds = ds.repeat(100)           # Repeat data 100 times\n  ds = ds.shuffle(buffer_size=10000) # Shuffle data for better training\n  ds = ds.batch(100)            # Process in mini-batches of 100\n  return ds\n\n# Example usage (not run, just definition)\n# input_dataset = training_input()\n# for element in input_dataset.take(1):\n#    print(element)\n\nHere you can see what an input function might look like. The function:\n\nCreates a Dataset object. This particular Dataset is just wrapping a bunch of Pandas Series objects, but Dataset can represent other data acquisition and storage strategies.\nSets the number of times to pass the data to the model. Remember that our models will be using an optimizer to try to find good weights. In order to do this, it helps to pass the data to the model a few times.\nShuffles the data between repeats.\nDefines the mini-batch size. This is the number of data points that will be passed to the model in each training step.\n\nNote that repetition and batch are hyperparameters that you can change in the model. You might find that you don’t need to repeat the data as much or that you need to repeat it more. You might find that smaller batches work better than big batches."
  },
  {
    "objectID": "amli/03_05-09-regression.html#linearregressor-optimizer",
    "href": "amli/03_05-09-regression.html#linearregressor-optimizer",
    "title": "Machine Learning",
    "section": "LinearRegressor: Optimizer",
    "text": "LinearRegressor: Optimizer\nimport tensorflow as tf\n\n# Example feature columns\nfeature_columns = [tf.feature_column.numeric_column(\"x\")]\n\n# Create an Adam optimizer with a specific learning rate\nadam_optimizer = tf.keras.optimizers.Adam(\n  learning_rate=0.001,\n  epsilon=1e-08 # Added for Keras compatibility\n)\n\n# Instantiate LinearRegressor with the custom optimizer\nlinear_regressor = tf.estimator.LinearRegressor(\n    feature_columns=feature_columns,\n    optimizer=adam_optimizer,\n)\n\n# You would then call .train() and .predict() on linear_regressor\n# print(linear_regressor) # Uncomment to inspect the estimator\n\nAnother interesting hyperparameter is the optimizer. By default LinearRegressor uses the Ftrl optimizer; however, there are many more options. In this example we use the Adam optimizer. In this case, we also manually set the learning rate. Each optimizer has settings like this that you can change to help your model train faster and better."
  },
  {
    "objectID": "amli/03_05-09-regression.html#linearregressor-distribution",
    "href": "amli/03_05-09-regression.html#linearregressor-distribution",
    "title": "Machine Learning",
    "section": "LinearRegressor: Distribution",
    "text": "LinearRegressor: Distribution\n# Dummy for conceptual demonstration - actual distribution\n# requires a multi-device setup not available in pyodide.\nimport tensorflow as tf\n\n# Example feature columns\nfeature_columns = [tf.feature_column.numeric_column(\"x\")]\n\n# Define a distributed strategy (conceptually)\n# This part won't execute effectively in pyodide, but shows the API.\ntry:\n    mirrored_strategy = tf.distribute.MirroredStrategy()\n    config = tf.estimator.RunConfig(\n        train_distribute=mirrored_strategy,\n        eval_distribute=mirrored_strategy,\n    )\nexcept RuntimeError as e:\n    print(f\"Distribution Strategy initialization skipped in Pyodide: {e}\")\n    config = None # Fallback if strategy cannot be initialized\n\nlinear_regressor = tf.estimator.LinearRegressor(\n    feature_columns=feature_columns,\n    config=config,\n)\n\n# print(linear_regressor) # Uncomment to inspect\n\nIn order to distribute training and evaluation across workers, you can optionally pass the LinearRegressor a distribution method via config. We’ll show how to do this in the lab, though it doesn’t help much on the small virtual machines that we’ll be working with.\nNote: The distribution strategy code above is primarily for demonstration of the API. tf.distribute.MirroredStrategy typically requires a CUDA-enabled GPU and a multi-device setup, which isn’t available in the browser-based Pyodide environment. Thus, the try-except block is included to prevent errors when running this in the presentation."
  },
  {
    "objectID": "amli/03_05-09-regression.html#your-turn-predicting-housing-prices",
    "href": "amli/03_05-09-regression.html#your-turn-predicting-housing-prices",
    "title": "Machine Learning",
    "section": "Your Turn! Predicting Housing Prices",
    "text": "Your Turn! Predicting Housing Prices\n\n\n\n\n\n\nImportant\n\n\nLab: Apply LinearRegressor to predict housing prices using the California census data.\n\n\n\n\nIn the lab we will use United States census data to try to predict housing prices in California. We’ll examine the data, manipulate the data, and then build and adjust a model."
  },
  {
    "objectID": "amli/03_05-09-regression.html#neural-networks-good",
    "href": "amli/03_05-09-regression.html#neural-networks-good",
    "title": "Machine Learning",
    "section": "Neural Networks: Good?",
    "text": "Neural Networks: Good?\n\nSelf-driving Car\nDeep learning is a giant leap forward for humanity. We can now program machines to excel at tasks that we once thought only humans could master. Computers can drive cars, interpret medical imaging, create art, and play complex games at a human expert-level or better."
  },
  {
    "objectID": "amli/03_05-09-regression.html#neural-networks-bad",
    "href": "amli/03_05-09-regression.html#neural-networks-bad",
    "title": "Machine Learning",
    "section": "Neural Networks: Bad?",
    "text": "Neural Networks: Bad?\n\nDecepticons\nThere is also the fear that deep learning will have huge negative impacts on society. The images of a terminator are likely overblown, but there is real concern that advanced deep learning algorithms will have negative effects on some people.\nDisruptive technologies like self-driving cars will displace millions of workers.\nSocietal bias, conscious or not, can become encoded in deep learning algorithms, multiplying and normalizing the negative effects that have existed for decades.\nWhen using deep learning, great care must be taken to remove bias and to understand the implications of mass application of the algorithms."
  },
  {
    "objectID": "amli/03_05-09-regression.html#neural-networks-hype",
    "href": "amli/03_05-09-regression.html#neural-networks-hype",
    "title": "Machine Learning",
    "section": "Neural Networks: Hype?",
    "text": "Neural Networks: Hype?\n\nHype\nAnd finally, there are those who think deep learning and neural networks are just hype. For every person who thinks a technological revolution is around the corner, there is another pointing out how specialized and controlled the environment has to be for machine learning algorithms to perform well.\nDeep learning doesn’t progress at an even pace. We are currently in a deep learning boom, but this has happened before. There have been a few “AI winters” where researchers thought that we were on the cusp of a revolution, only to have research in neural networks go dormant for a while.\nWe’d like to think that this time might be different. Computation is finally fast enough and has enough scale that algorithms designed decades ago can finally be implemented and trained in an effective manner.\nOnly time will tell if deep learning can live up to expectations. What we can do now is learn about it, be thoughtful about how we train and use it, and continue to innovate cautiously."
  },
  {
    "objectID": "amli/03_05-09-regression.html#history-motivation",
    "href": "amli/03_05-09-regression.html#history-motivation",
    "title": "Machine Learning",
    "section": "History & Motivation",
    "text": "History & Motivation\n\nLet’s first look at some history and motivation for neural networks."
  },
  {
    "objectID": "amli/03_05-09-regression.html#neural-networks-inspired-by-nature",
    "href": "amli/03_05-09-regression.html#neural-networks-inspired-by-nature",
    "title": "Machine Learning",
    "section": "Neural Networks: Inspired by Nature",
    "text": "Neural Networks: Inspired by Nature\n\nInspired by Nature\nWe’ve talked about what people think neural networks can and cannot do, but we really haven’t talked about what neural networks are. And why are they even called neural networks?\nNature can be a source of inspiration. Birds inspired man to fly. The burdock plant was the inspiration for velcro. Even in the computer science realm we hear references to trees, forests, and other things that occur in nature."
  },
  {
    "objectID": "amli/03_05-09-regression.html#neural-networks-inspired-by-nature-1",
    "href": "amli/03_05-09-regression.html#neural-networks-inspired-by-nature-1",
    "title": "Machine Learning",
    "section": "Neural Networks: Inspired by Nature",
    "text": "Neural Networks: Inspired by Nature\n\nNeuron in our Body\nSimilar to the examples in the last slide, neural networks are inspired by nature. The brain contains a massive network of neurons that send electrical signals that activate other neurons. Through this network we are able to think.\nThis is the building block of the brain: a neuron.\nA neuron is just a cell with a nucleus and cell body like any other cell. One of the distinguishing features of the neuron is the ‘axon,’ which is the long tail of the neuron. The tip of the axon has synaptic terminals that attach to other neuron bodies. A neuron body receives signals from the synapse of neurons before it. When those signals reach a critical point within a fixed period of time, the receiving neuron fires, sending a signal to later neurons.\nNeural networks were inspired by neurons and connections between neurons in the brain, hence the name."
  },
  {
    "objectID": "amli/03_05-09-regression.html#neural-networks-inspired-by-nature-2",
    "href": "amli/03_05-09-regression.html#neural-networks-inspired-by-nature-2",
    "title": "Machine Learning",
    "section": "Neural Networks: Inspired by Nature",
    "text": "Neural Networks: Inspired by Nature\n\nWeb of neurons (neural networks)\nThis builds a web of neurons called a “neural network.”\nThis simplification of the brain signaling pathway led to research into “artificial neural networks” with different types of neurons.\nBeyond this network effect, the concept of neural networks tends to break away from biology. Similarly, birds inspired flight, but modern airplanes don’t flap their wings.\nWe find inspiration in nature. We don’t have to copy it."
  },
  {
    "objectID": "amli/03_05-09-regression.html#neural-networks-cutting-edge",
    "href": "amli/03_05-09-regression.html#neural-networks-cutting-edge",
    "title": "Machine Learning",
    "section": "Neural Networks: Cutting Edge?",
    "text": "Neural Networks: Cutting Edge?\n\nEinstein?\nWhen did neural networks originate? The 1940s.\n1940s! I thought neural networks were cutting edge?\nMany of the fundamental algorithms we use today are rooted in thought experiments from the 1940s, but it has been a long journey from then to where we are today.\nThe computing power and data storage that we have today is nearly unimaginable compared to what was available even in the recent past. Also, many of the early ideas were foundational, but they have been improved upon over time.\nThe idea of deep learning is not new. There were even a few “AI winters” over the last 80 years that stalled development and research in deep learning. It feels like we might finally be at a point where the theoretical ideas of the past can be fulfilled with the technologies of today."
  },
  {
    "objectID": "amli/03_05-09-regression.html#artificial-neural-networks-ann",
    "href": "amli/03_05-09-regression.html#artificial-neural-networks-ann",
    "title": "Machine Learning",
    "section": "Artificial Neural Networks (ANN)",
    "text": "Artificial Neural Networks (ANN)\n\nComputational networks inspired by biological systems.\nFeed-forward networks: Information flows in one direction.\nBackpropagation: Algorithm for training ANNs by adjusting weights.\nSpecific types: Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN).\n\n\nToday we will talk about artificial neural networks. These are computational networks inspired by biological systems.\nANN is a big umbrella. There are “feed-forward” networks. There is a concept of “backpropagation.” And there are specific types of networks such as convolutional neural networks (CNN) and recurrent neural networks (RNN) that we will look at in more detail in future units."
  },
  {
    "objectID": "amli/03_05-09-regression.html#artificial-neural-networks-ann-1",
    "href": "amli/03_05-09-regression.html#artificial-neural-networks-ann-1",
    "title": "Machine Learning",
    "section": "Artificial Neural Networks (ANN)",
    "text": "Artificial Neural Networks (ANN)\n\nANN architecture\nThese are the typical diagrams you see to depict an artificial neural network. On the left we have our “input layer.” This is where we feed our feature data into the model. In these two diagrams, there are three features (depicted by the two blue dots on the far left of the schematic).\nThe feature information then flows into “hidden layers.” In these hidden layers, mathematical operations are performed to extract patterns from the feature data. We’ll talk more about this math on future slides.\nFinally, the transformed feature data flows to the output layer, which returns our predicted target values.\nThe main idea is that if neurons in one layer “fire.” Then, using the connections to the next layer, we can determine which neurons in the next layer will fire. For now, it is useful to think of a neuron firing as a 1 and not firing as a 0. It is true that more sophisticated neural networks take into account the intensity of a “fire” (i.e., fired at 50% vs fired at 100%), but for the sake of discussion, let’s stick with the 1 or 0 model."
  },
  {
    "objectID": "amli/03_05-09-regression.html#perceptron",
    "href": "amli/03_05-09-regression.html#perceptron",
    "title": "Machine Learning",
    "section": "Perceptron",
    "text": "Perceptron\n\nSimplest neural network: perceptron\nIn 1958, an American psychologist named Frank Rosenblatt attempted to build a machine called a perceptron.\nWe can think of the perceptron as the building block of neural networks. The perceptron has no hidden layers. We feed our features into the left side, do computation, and receive a predicted target.\nThis looks strikingly similar to the models we’ve been building in this course. And that’s no accident! We can think of a linear regression model as a perceptron.\nBut what are those mystery computations that take place on the black lines? There are weights, \\(w_{1}\\), …, \\(w_{m}\\), that are used in these computations. How does that work? Let’s look closer at what’s happening behind the scenes along those black lines."
  },
  {
    "objectID": "amli/03_05-09-regression.html#perceptron-the-math",
    "href": "amli/03_05-09-regression.html#perceptron-the-math",
    "title": "Machine Learning",
    "section": "Perceptron: The Math",
    "text": "Perceptron: The Math\n\nPerceptron mathThe core computation: \\[ \\text{sum} = \\sum_{i=1}^{m} w_i x_i + b = W^T X + b \\] The result sum then goes through an activation function \\(f(\\text{sum})\\) to produce the output."
  },
  {
    "objectID": "amli/03_05-09-regression.html#perceptron-the-math-1",
    "href": "amli/03_05-09-regression.html#perceptron-the-math-1",
    "title": "Machine Learning",
    "section": "Perceptron: The Math",
    "text": "Perceptron: The Math\nInteractive Perceptron Demo\nAdjust inputs and weights to see the output.\n\nviewof x1 = Inputs.range([0, 1], {step: 1, label: \"Input x1\"});\nviewof x2 = Inputs.range([0, 1], {step: 1, label: \"Input x2\"});\nviewof w1 = Inputs.range([-2, 2], {value: 1, step: 0.1, label: \"Weight w1\"});\nviewof w2 = Inputs.range([-2, 2], {value: 1, step: 0.1, label: \"Weight w2\"});\nviewof bias = Inputs.range([-2, 2], {value: -0.5, step: 0.1, label: \"Bias b\"});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe green and blue compartments show the computations taking place in the connections between the input layer and output layer of a perceptron.\nThe features are denoted by \\(x_{i}\\). The weights \\(w_{i}\\) are playing the same role as the weights in our linear regression model. If we build a weight vector \\(W = [w_{1}, w_{2}, ..., w_{m}]\\) and a feature vector \\(X = [x_{1}, x_{2}, ..., x_{m}]\\), then the green computation is simply \\(W^{T}X + b\\) (which is exactly the same as the target in a regression model: bias + \\(w_{1}x_{1}\\) + \\(w_{2}x_{2}\\) + … + \\(w_{m}x_{m}\\)).\nThis information is then sent to an “activation function,” which uses the information from the green computation to determine whether or not the next neuron should fire. In a linear regression example, the activation function might be \\(f(x) = x\\). In other words, the activation function plays no role. But let’s look at a slightly more interesting example and walk through these details in a little more depth.\nThe interactive demo on the right allows you to play with the inputs, weights, and bias to see how the neuron’s output changes based on the calculated weighted sum and a simple step function. This demonstrates the fundamental logic of a perceptron."
  },
  {
    "objectID": "amli/03_05-09-regression.html#perceptron-example-predicting-ml-study",
    "href": "amli/03_05-09-regression.html#perceptron-example-predicting-ml-study",
    "title": "Machine Learning",
    "section": "Perceptron Example: Predicting ML Study",
    "text": "Perceptron Example: Predicting ML Study\n\nPerceptron example"
  },
  {
    "objectID": "amli/03_05-09-regression.html#perceptron-example-predicting-ml-study-1",
    "href": "amli/03_05-09-regression.html#perceptron-example-predicting-ml-study-1",
    "title": "Machine Learning",
    "section": "Perceptron Example: Predicting ML Study",
    "text": "Perceptron Example: Predicting ML Study\n\n\\(x_1\\): Will make more money? (1=Yes, 0=No)\n\\(x_2\\): Loves programming/math? (1=Yes, 0=No)\n\\(x_3\\): Has project benefiting from ML? (1=Yes, 0=No)\n\n\\[\\sum_{i=1}^{3} w_i x_i - \\text{threshold} \\geq 0 \\implies \\text{Studies ML (1)}\\] \\[\\sum_{i=1}^{3} w_i x_i - \\text{threshold} &lt; 0 \\implies \\text{Does Not Study ML (0)}\\]\n\nSuppose we want to predict whether an individual will start studying machine learning. Our features are given by: \\(x_{1}\\) = will the person make more money? \\(x_{2}\\) = does the person love programming and mathematics? \\(x_{3}\\) = does the person have a project that would benefit from ML?\nWe compute \\(W^{T}X = w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} + bias\\).\nNow assume that we will say “yes”: the person will study machine learning if the result is \\(\\geq 0\\) and “no”: the person will not study machine learning if the result is \\(&lt; 0\\).\nIt might be helpful to flip back to the previous slide and explain that the specific activation function we’re working with in this example is \\(f(x) = 1\\) if \\(W^{T}X + b \\geq 0\\) and \\(f(x) = 0\\) if \\(W^{T}X + b &lt; 0\\). Also, for notational convenience, we flip the sign of b and write \\(w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} - b\\) going forward. If we use this model, then the algorithm will learn a negated form of b.\nThat is, we ask is \\(w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} - bias \\geq 0\\)? Which is the same as asking is \\(w_{1}x_{1} + w_{2}x_{2} + w_{3}x_{3} \\geq b\\). For convenience, we have relabeled b as -b."
  },
  {
    "objectID": "amli/03_05-09-regression.html#machine-learning-process-review",
    "href": "amli/03_05-09-regression.html#machine-learning-process-review",
    "title": "Machine Learning",
    "section": "Machine Learning Process (Review)",
    "text": "Machine Learning Process (Review)\n\nInfer/Predict/Forecast: Use the model to make predictions.\nCalculate Error/Loss/Cost: Quantify prediction inaccuracy.\nTrain/Learn: Adjust model parameters (weights, biases) to minimize error.\nIterate: Repeat until a stopping condition is met.\n\n\nLet’s recall the general machine learning process. This is the same process that we use for all ML models."
  },
  {
    "objectID": "amli/03_05-09-regression.html#perceptron-example-weights-bias",
    "href": "amli/03_05-09-regression.html#perceptron-example-weights-bias",
    "title": "Machine Learning",
    "section": "Perceptron Example: Weights & Bias",
    "text": "Perceptron Example: Weights & Bias\n\nPerceptron example: weights and bias"
  },
  {
    "objectID": "amli/03_05-09-regression.html#perceptron-example-weights-bias-1",
    "href": "amli/03_05-09-regression.html#perceptron-example-weights-bias-1",
    "title": "Machine Learning",
    "section": "Perceptron Example: Weights & Bias",
    "text": "Perceptron Example: Weights & Bias\n\n\\(w_1 = 2\\), \\(w_2 = 2\\), \\(w_3 = 6\\)\nThreshold = 5\n\n\\[\\text{Predict } 1 \\text{ if } 2x_1 + 2x_2 + 6x_3 \\geq 5\\] \\[\\text{Predict } 0 \\text{ if } 2x_1 + 2x_2 + 6x_3 &lt; 5\\]\n\nLet’s assume we already have our weights and bias. We say that \\(x_{1}\\) and \\(x_{2}\\) have an equal impact on a person’s decision to study ML, and they both have weight 2. Assume that \\(x_{3}\\) is three times as important in a person’s decision to study ML, so its weight is 6. Now let’s assume the bias is 5. In other words, we are thresholding at 5, and we say if \\(W^{T}X \\geq 5\\), then the person will study machine learning. If \\(W^{T}X &lt; 5\\), then the person will not study machine learning.\nLet’s take a second to think about these numbers critically and see what they really mean."
  },
  {
    "objectID": "amli/03_05-09-regression.html#perceptron-example-kellys-input",
    "href": "amli/03_05-09-regression.html#perceptron-example-kellys-input",
    "title": "Machine Learning",
    "section": "Perceptron Example: Kelly’s Input",
    "text": "Perceptron Example: Kelly’s Input\n\nPerceptron example: input"
  },
  {
    "objectID": "amli/03_05-09-regression.html#perceptron-example-kellys-input-1",
    "href": "amli/03_05-09-regression.html#perceptron-example-kellys-input-1",
    "title": "Machine Learning",
    "section": "Perceptron Example: Kelly’s Input",
    "text": "Perceptron Example: Kelly’s Input\n\n\\(x_1 = 0\\) (Won’t make more money)\n\\(x_2 = 0\\) (Doesn’t love programming/math)\n\\(x_3 = 1\\) (Has a project benefiting from ML)\n\n\nLet’s assume a particular person, Kelly, does not stand to make more money by studying ML and she does not like programming and math (\\(x_{1} = x_{2} = 0\\)). But assume that Kelly does have a project that would benefit from ML (\\(x_{3} = 1\\))."
  },
  {
    "objectID": "amli/03_05-09-regression.html#perceptron-example-kellys-prediction",
    "href": "amli/03_05-09-regression.html#perceptron-example-kellys-prediction",
    "title": "Machine Learning",
    "section": "Perceptron Example: Kelly’s Prediction",
    "text": "Perceptron Example: Kelly’s Prediction\n\nPerceptron example: prediction"
  },
  {
    "objectID": "amli/03_05-09-regression.html#perceptron-example-kellys-prediction-1",
    "href": "amli/03_05-09-regression.html#perceptron-example-kellys-prediction-1",
    "title": "Machine Learning",
    "section": "Perceptron Example: Kelly’s Prediction",
    "text": "Perceptron Example: Kelly’s Prediction\n\\[2(0) + 2(0) + 6(1) = 6\\]\nSince \\(6 \\geq 5\\), the model predicts: YES, Kelly will study ML!\n\nComputing \\(W^{T}X\\) we get 6.\nWe check that 6 is \\(\\geq 5\\), so we say “yes”: Kelly will study machine learning."
  },
  {
    "objectID": "amli/03_05-09-regression.html#perceptron-example-rileys-input",
    "href": "amli/03_05-09-regression.html#perceptron-example-rileys-input",
    "title": "Machine Learning",
    "section": "Perceptron Example: Riley’s Input",
    "text": "Perceptron Example: Riley’s Input\n\nPerceptron example: input"
  },
  {
    "objectID": "amli/03_05-09-regression.html#perceptron-example-rileys-input-1",
    "href": "amli/03_05-09-regression.html#perceptron-example-rileys-input-1",
    "title": "Machine Learning",
    "section": "Perceptron Example: Riley’s Input",
    "text": "Perceptron Example: Riley’s Input\n\n\\(x_1 = 1\\) (Will make more money)\n\\(x_2 = 1\\) (Loves programming/math)\n\\(x_3 = 0\\) (No project benefiting from ML)\n\n\nNow let’s assume we have another person, Riley, who will make more money in her job by learning ML and she does like programming and math (\\(x_{1} = x_{2} = 1\\)), but she does not have a project that would benefit from ML (\\(x_{3}=0\\))."
  },
  {
    "objectID": "amli/03_05-09-regression.html#perceptron-example-rileys-prediction",
    "href": "amli/03_05-09-regression.html#perceptron-example-rileys-prediction",
    "title": "Machine Learning",
    "section": "Perceptron Example: Riley’s Prediction",
    "text": "Perceptron Example: Riley’s Prediction\n\nPerceptron example: prediction"
  },
  {
    "objectID": "amli/03_05-09-regression.html#perceptron-example-rileys-prediction-1",
    "href": "amli/03_05-09-regression.html#perceptron-example-rileys-prediction-1",
    "title": "Machine Learning",
    "section": "Perceptron Example: Riley’s Prediction",
    "text": "Perceptron Example: Riley’s Prediction\n\\[2(1) + 2(1) + 6(0) = 4\\]\nSince \\(4 &lt; 5\\), the model predicts: NO, Riley will not study ML.\n\nComputing \\(W^{T}X\\) we get 4.\nWe check that \\(4 &lt; 5\\), so the model predicts “no”: Riley will not study ML.\nIn general, this is how we feed input data into our model. If the model had already finished learning the weights and bias, then this is how we would generate our predicted targets."
  },
  {
    "objectID": "amli/03_05-09-regression.html#perceptron-example-learning-process",
    "href": "amli/03_05-09-regression.html#perceptron-example-learning-process",
    "title": "Machine Learning",
    "section": "Perceptron Example: Learning Process",
    "text": "Perceptron Example: Learning Process\n\nPerceptron example: learning process"
  },
  {
    "objectID": "amli/03_05-09-regression.html#perceptron-example-learning-process-1",
    "href": "amli/03_05-09-regression.html#perceptron-example-learning-process-1",
    "title": "Machine Learning",
    "section": "Perceptron Example: Learning Process",
    "text": "Perceptron Example: Learning Process\n\nKelly: Prediction = 1 (Correct, actual = 1)\nRiley: Prediction = 0 (Incorrect, actual = 1)\n\nThe model needs to adjust weights and bias to correctly predict for Riley. This involves optimization (e.g., gradient descent) and backpropagation (applying the chain rule to update weights across layers).\n\nBut how does the model actually update the weights and bias during the learning process?\nLet’s look back at our example. Note that both of these samples were technically training data. From our dataset, we know that both Kelly and Riley did study ML (y=1), but for Kelly we predicted \\(\\hat{y} = 1\\), and for Riley we predicted \\(\\hat{y} = 0\\). So Kelly’s prediction was correct, while Riley’s was not correct.\nNow the model needs to adjust the weights. It seems like if a person stands to make more money from studying ML AND they love programming and math, then the model should predict a 1 (whether or not they have a current project that would benefit from ML).\nSo the model needs to update the weights and bias via some optimization algorithm like gradient descent. In order to compute the derivative (gradient) to discern the direction of steepest descent, we will need to unravel the many compositions of matrix multiplication. If you remember your calculus, how do we take the derivative of a composition? The chain rule! That is effectively what backpropagation does. It is a way to compute the gradient when many chain rules are involved through each layer of the network."
  },
  {
    "objectID": "amli/03_05-09-regression.html#machine-learning-process-neural-networks",
    "href": "amli/03_05-09-regression.html#machine-learning-process-neural-networks",
    "title": "Machine Learning",
    "section": "Machine Learning Process (Neural Networks)",
    "text": "Machine Learning Process (Neural Networks)\n\nInfer/Predict/Forecast: Compute \\(f(X, W, B)\\), involving compositions of activation functions and many matrix multiplications across layers.\nCalculate Error/Loss/Cost: Use metrics like MSE, MAE to quantify discrepancy between predicted and actual values.\nTrain/Learn (Optimization):\n\nAdjust \\(W\\) and \\(B\\) in the direction that minimizes cost.\nThis direction is typically found via gradient descent.\nGradients for complex networks are computed efficiently using the chain rule, implemented through backpropagation.\n\nIterate: Repeat steps 1-3 until the model converges or a stopping condition (e.g., max epochs) is met.\n\n\nLet’s put everything together and summarize how a neural network will learn in general. It shouldn’t surprise you that it’s the same machine learning process that we’ve been working with for all our models. Now we’ve just filled it with some high-level details of each step for neural networks."
  },
  {
    "objectID": "amli/03_05-09-regression.html#issues-with-this-plan",
    "href": "amli/03_05-09-regression.html#issues-with-this-plan",
    "title": "Machine Learning",
    "section": "Issues with this plan?",
    "text": "Issues with this plan?\n\n\nThe simple step function:\n\\[\nf(x) =\n  \\begin{cases}\n    1 & \\text{if } x \\geq 0 \\\\\n    0 & \\text{if } x &lt; 0\n  \\end{cases}\n\\]\n\nDrawbacks:\n\nNot differentiable at 0: Problematic for gradient descent.\nZero gradient elsewhere: \\(f'(x) = 0\\) for \\(x \\neq 0\\), hindering learning.\nBinary output only: No confidence scores or continuous values.\n\n\n\nThere are many possible activation functions, and some work better than others in certain situations.\nLet’s take a closer look at the activation function we used in our simple example. This function is called a step-function.\nThere are a few drawbacks to using the step-function. * \\(f\\) is not differentiable at 0. This could create problems for gradient descent when we need to take a derivative. * \\(f'(x)\\) is 0 whenever \\(x\\) is not 0. This could also create problems for gradient descent. If we ever multiply by \\(f'(x)\\), the entire function will go to 0, which means no slope. So it can be hard to determine the direction of steepest descent. * \\(f\\) only returns a no or a yes. It would be preferable for \\(f\\) to return a continuous value between 0 and 1. For example, if \\(f\\) returned .9, then we would say that we’re 90% confident the answer is “yes, this person will study ML.” That is far more powerful than just returning a “yes” or “no.” We will discuss this further in the section on classification."
  },
  {
    "objectID": "amli/03_05-09-regression.html#sigmoid-activation",
    "href": "amli/03_05-09-regression.html#sigmoid-activation",
    "title": "Machine Learning",
    "section": "Sigmoid Activation",
    "text": "Sigmoid Activation\n\nSigmoid\nA differentiable function that “squashes” values between 0 and 1.\nAddresses limitations of the step function.\n\n\nThe sigmoid function is a far more popular activation function, as it addresses the issues we just discussed with the step-function. Again, we will talk more about this when we get to classification."
  },
  {
    "objectID": "amli/03_05-09-regression.html#activation-functions",
    "href": "amli/03_05-09-regression.html#activation-functions",
    "title": "Machine Learning",
    "section": "Activation Functions",
    "text": "Activation Functions\n\nList of Activation Functions\nCrucial for introducing non-linearity to the network.\nEnables learning complex patterns.\nMany types: ReLU (Rectified Linear Unit), Tanh, Leaky ReLU, etc.\n\n\nThe choice of activation function is important. RELU makes differentiation difficult, but it actually works really well in practice. The other functions are also very useful.\nIt is important to note that why certain activation functions behave in certain ways is an active area of research. People are testing new ones every day. Sometimes there is good theoretical justification for using a particular activation function, and sometimes we use a particular activation function simply because it trained quickly and gave us good results in practice."
  },
  {
    "objectID": "amli/03_05-09-regression.html#keras",
    "href": "amli/03_05-09-regression.html#keras",
    "title": "Machine Learning",
    "section": "Keras",
    "text": "Keras\nThe Python Deep Learning Library\n\nHigh-level API for quickly building and training ML models.\nIntegrates seamlessly with TensorFlow 2.\nSimplifies complex deep learning model design.\n\n\nTo build our deep neural network, we will be using Keras, a high-level Python API that can be used within TensorFlow.\nDon’t be put off by the term “deep neural network.” Though the math and the theory are complex, the actual code you need to write to create one is as easy as creating a simple linear regression."
  },
  {
    "objectID": "amli/03_05-09-regression.html#keras-sequential-models",
    "href": "amli/03_05-09-regression.html#keras-sequential-models",
    "title": "Machine Learning",
    "section": "Keras: Sequential Models",
    "text": "Keras: Sequential Models\nfrom tensorflow import keras\n\n# An empty sequential model\nmodel = keras.Sequential()\n\n# model.add(some_layer) # Layers can be added later\n# print(model) # Uncomment to see model summary\n\nLinear stack of layers: Each layer feeds directly into the next.\nIdeal for simple feed-forward networks where data flows in one direction.\nAlternative: Functional API for more complex, graph-like architectures.\n\n\nWe will build our model using the Sequential class. Sequential simply means that the model will consist of a sequence of layers, one after the other. Each layer feeds the next in the sequence.\nIn Keras, the alternative to a sequential model is a functional model. Functional models allow layers to interconnect in more complex ways. Layers can branch and merge through different paths. The resultant model might look more like a graph with multiple inputs and outputs. This is different from the sequential model, which looks much more like a funnel."
  },
  {
    "objectID": "amli/03_05-09-regression.html#keras-layers",
    "href": "amli/03_05-09-regression.html#keras-layers",
    "title": "Machine Learning",
    "section": "Keras: Layers",
    "text": "Keras: Layers\nfrom tensorflow.keras import layers\n\n# Input layer (implicitly created) and 1st hidden layer with 32 nodes\nlayer_1 = layers.Dense(32, input_shape=[8]) \n\n# 2nd hidden layer with 16 nodes and ReLU activation\nlayer_2 = layers.Dense(16, activation='relu')\n\n# Output layer with 1 node for regression\nlayer_3 = layers.Dense(1)\n\n# These layers would typically be combined in a Sequential model\n# e.g., model = keras.Sequential([layer_1, layer_2, layer_3])\n\nDense layer: Every node connects to every node in the previous/next layer.\ninput_shape: Defines the number of features in the input.\nFirst argument: Number of nodes (\\(\\textit{units}\\)) in the layer.\nactivation: Specifies the activation function (e.g., 'relu', 'sigmoid').\n\n\nA model consists of layers of nodes. In the lab we are about to do, those layers are Dense layers. A dense layer in a neural network is a layer where every node is connected to every node in the next layer.\nIn the example we have on this slide, we create three Dense layer classes. This actually creates a neural network that is four layers deep, though.\nWhen we make the first layer, we pass in an input shape. This is the shape of the features you’ll be feeding into the model. In this case we chose an input shape of 8. That indicates we’ll be providing 8 features to the model. The input layer is the first layer.\nBut you should also notice that we passed the number 32 to the Dense constructor. This creates our first hidden layer with 32 nodes.\nIn review, this first line of code creates two layers. One layer is an input layer that accepts 8 features. That layer is densely connected to the next layer, which has 32 nodes. This means there are 8x32 connections between the layers.\nThe next line of code creates another dense layer. This layer is 16 nodes wide. Notice that we pass an activation function to this layer. The activation we chose is the relu activation. By default the activation for a dense layer in TensorFlow Keras is \\(f(x) = x\\). We can adjust the activation function layer by layer.\nThere are many activation functions available in the tensorflow.keras.activations namespace. Many of these can be referenced by name, as shown in this example. There are more activation functions available in tf.nn. For these functions you’ll need to pass in the class - like tf.nn.leaky_relu - instead of just the name.\nThe final layer that we create is our output layer. Since we have been doing single output regressions, this output layer has only one node. That node will be our predicted regression value for a given set of input features.\nYou aren’t limited to one output though. As we move into classification, we’ll see examples with more than one output node."
  },
  {
    "objectID": "amli/03_05-09-regression.html#keras-dense-neural-network-architecture",
    "href": "amli/03_05-09-regression.html#keras-dense-neural-network-architecture",
    "title": "Machine Learning",
    "section": "Keras: Dense Neural Network Architecture",
    "text": "Keras: Dense Neural Network Architecture\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nmodel = keras.Sequential([\n  layers.Dense(64, input_shape=[8], activation='relu', name='hidden_layer_1'),\n  layers.Dense(64, activation='relu', name='hidden_layer_2'),\n  layers.Dense(1, name='output_layer')\n])\nmodel.summary()\nModel Visualization\n\n\n\n\n\n\n\nG\n\n\n\nInput\n\nInput Layer\n(8 Features)\n\n\n\nHidden1\n\nDense (64 units)\n(ReLU)\n\n\n\nInput-&gt;Hidden1\n\n\n8x64 connections\n\n\n\nHidden2\n\nDense (64 units)\n(ReLU)\n\n\n\nHidden1-&gt;Hidden2\n\n\n64x64 connections\n\n\n\nOutput\n\nDense (1 unit)\n(Output)\n\n\n\nHidden2-&gt;Output\n\n\n64x1 connection\n\n\n\n\n\n\n\n\n\nIn our previous slide, we created layers, but we didn’t connect them. In this slide we’ll create the layers inside a sequential model. Now the layers are densely connected in sequence.\nQuestions to ask the class: How many layers are there in this model? Answer: 4 (Input, Hidden1, Hidden2, Output)\nHow many nodes are in the first (input) layer? Answer: 8 (implicitly from input_shape)\nHow many nodes are in the second (hidden_layer_1) and third (hidden_layer_2) layers? Answer: 64\nHow many nodes are in the final (output) layer? Answer: 1\nHow many connections are there between layer 1 (input) and layer 2 (hidden_layer_1)? Answer: 8x64 = 512 connections.\nIt may be helpful to draw a schematic of the model on the board while asking students the questions if the Graphviz diagram isn’t clear enough immediately.\nThe model.summary() command (if run in a Python environment) prints a table showing the layers, their output shapes, and the number of parameters. This helps verify the architecture."
  },
  {
    "objectID": "amli/03_05-09-regression.html#keras-other-layer-types",
    "href": "amli/03_05-09-regression.html#keras-other-layer-types",
    "title": "Machine Learning",
    "section": "Keras: Other Layer Types",
    "text": "Keras: Other Layer Types\nfrom tensorflow.keras.layers import (\n    AveragePooling1D,\n    Conv3D,\n    GRU,\n    RNN,\n    ZeroPadding3D,\n    LSTM,\n    BatchNormalization,\n    Dropout,\n    Reshape\n)\n\n# Not an exhaustive list, just examples for different ML tasks.\n# Each serves a specific purpose in processing different data types.\n\n# These are imported for conceptual understanding, not direct execution.\n# Actual usage involves constructing models from these layers.\n\nDense is just one type; Keras offers many specialized layers:\n\nConvolutional layers (Conv2D, Conv3D): For spatial data (images, videos).\nRecurrent layers (LSTM, GRU): For sequential data (time series, text).\nPooling layers (MaxPooling1D, AveragePooling2D): For downsampling.\nNormalization layers (BatchNormalization): For stabilizing training.\nRegularization layers (Dropout): For preventing overfitting.\n\n\n\nDense isn’t the only type of layer. There are dozens of layers that can be found in the tensorflow.keras.layers namespace. Here is a sample. We will discuss some of these layers later in the course. They are all different, and some work very well for certain types of data and use cases."
  },
  {
    "objectID": "amli/03_05-09-regression.html#keras-model-compilation",
    "href": "amli/03_05-09-regression.html#keras-model-compilation",
    "title": "Machine Learning",
    "section": "Keras: Model Compilation",
    "text": "Keras: Model Compilation\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nmodel = keras.Sequential([\n  layers.Dense(64, input_shape=[8], activation='relu'),\n  layers.Dense(1)\n])\n\nmodel.compile(\n  loss='mse',           # Mean Squared Error\n  optimizer='Adam',     # Adaptive Moment Estimation optimizer\n  metrics=['mae', 'mse'], # Track Mean Absolute Error and Mean Squared Error\n)\n\n# print(model.optimizer) # Uncomment to inspect optimizer\n\nConfigures the model for training.\nloss function: Measures how well the model performs.\noptimizer: Algorithm to adjust weights and minimize the loss.\nmetrics: Evaluation criteria, displayed during training.\n\n\nAfter we have defined the structure of the model, we need to tell TensorFlow what to optimize for. To do that, we compile the model.\nIn this example we use the Adam optimizer to optimize for mean squared error, while also tracking mean absolute error and mean squared error. The tracked values will be reported after training."
  },
  {
    "objectID": "amli/03_05-09-regression.html#keras-model-training",
    "href": "amli/03_05-09-regression.html#keras-model-training",
    "title": "Machine Learning",
    "section": "Keras: Model Training",
    "text": "Keras: Model Training\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Dummy data for demonstration\ntraining_df = {\n    \"feature1\": np.random.rand(100, 8),\n    \"target_column\": np.random.rand(100)\n}\nfeature_columns = [\"feature1\"]\ntarget_column = \"target_column\"\n\nmodel = keras.Sequential([layers.Dense(1, input_shape=[8])])\nmodel.compile(loss='mse', optimizer='Adam', metrics=['mae'])\n\nEPOCHS = 5\n\nhistory = model.fit(\n  training_df[\"feature1\"],\n  training_df[target_column],\n  epochs=EPOCHS,\n  validation_split=0.2, # Use 20% of training data for validation\n  verbose=0 # Suppress output for concise presentation\n)\n\nprint(history.history) # Display training history\n\nmodel.fit(): Method to train the model.\nepochs: Number of times the entire dataset is passed forward and backward through the neural network.\nvalidation_split: Fraction of data to use for validation during training.\nReturns a History object containing loss and metric values per epoch.\n\n\nOnce you have defined your model and set up optimization parameters, it is time to train your model. Training is done with the fit() method, which needs to know the feature and target data.\nFit also needs to know how many times to repeat the data. Each repetition is called an epoch. In this case, we asked for 50 epochs. In the history that is returned, we will get measurements for the mean absolute error, mean squared error, and loss at each epoch.\nThe final argument that we pass to fit() is how much of the data to hold out as a validation set during training. This allows the model to track how it progresses over epochs using data that it isn’t training on."
  },
  {
    "objectID": "amli/03_05-09-regression.html#keras-making-predictions",
    "href": "amli/03_05-09-regression.html#keras-making-predictions",
    "title": "Machine Learning",
    "section": "Keras: Making Predictions",
    "text": "Keras: Making Predictions\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n# Assume 'model' is already trained (from previous slide)\n# Dummy testing data for demonstration\ntesting_df = {\n    \"feature1\": np.random.rand(10, 8)\n}\nfeature_columns = [\"feature1\"]\n\n# Generate predictions\npredictions = model.predict(testing_df[\"feature1\"])\n\nprint(\"First 5 predictions:\")\nprint(predictions[:5])\n\nmodel.predict(): Generates output predictions for new input data.\nReturns an array of predictions, matching the output layer’s shape.\n\n\nThe whole point of building a model is to make predictions. You can use the predict method to do that."
  },
  {
    "objectID": "amli/03_05-09-regression.html#your-turn-regression-with-tensorflow",
    "href": "amli/03_05-09-regression.html#your-turn-regression-with-tensorflow",
    "title": "Machine Learning",
    "section": "Your Turn! Regression with TensorFlow",
    "text": "Your Turn! Regression with TensorFlow\n\n\n\n\n\n\nTip\n\n\nLab: Build a deep neural network using Keras to predict California housing prices.\n\n\n\n\nFor our hands on exercise, we will revisit the California housing prices dataset from an earlier lab. We’ll use a sequential model with dense layers to create predictions that outperform the linear regression model we created earlier."
  },
  {
    "objectID": "amli/03_05-09-regression.html#predicting-insurance-charges",
    "href": "amli/03_05-09-regression.html#predicting-insurance-charges",
    "title": "Machine Learning",
    "section": "Predicting Insurance Charges",
    "text": "Predicting Insurance Charges\n\nWe have learned so much about regression over the past few labs. We have learned about linear regression and polynomial regression. We have learned how to calculate regression quality. We have built regression models using both scikit-learn and TensorFlow, where we have created traditional regression models and neural networks.\nHowever, most of the work we have done with regression has been very guided. In this project you’ll be given a dataset, and you will explore it on your own. You will then train and evaluate your own model. The model will be based on a dataset found on Kaggle that contains information about insurance charges."
  },
  {
    "objectID": "amli/03_05-09-regression.html#review-what-regression-models-have-we-learned-about",
    "href": "amli/03_05-09-regression.html#review-what-regression-models-have-we-learned-about",
    "title": "Machine Learning",
    "section": "Review: What regression models have we learned about?",
    "text": "Review: What regression models have we learned about?\n\nBefore diving in, let’s review a bit. What models have we learned so far?\n@Exercise(5 minutes) { Have students list the models they have learned so far. Get them to explain each of the models they mention. If they need prompting, remind them about linear regression, polynomial regression, and neural networks. }"
  },
  {
    "objectID": "amli/03_05-09-regression.html#review-what-tools-have-we-learned-about",
    "href": "amli/03_05-09-regression.html#review-what-tools-have-we-learned-about",
    "title": "Machine Learning",
    "section": "Review: What tools have we learned about?",
    "text": "Review: What tools have we learned about?\n\nWe have learned many different tools for performing regression. What are some of those tools?\n@Exercise(5 minutes) { Have students talk about the tools they have learned about. Get them to explain a bit about each of the tools. If they need prompting, remind them about scikit-learn’s LinearRegression and PolynomialFeatures. Remind them about TensorFlow and the Keras API. }"
  },
  {
    "objectID": "amli/03_05-09-regression.html#review-what-data-analysis-and-preparation-techniques-have-we-learned-about",
    "href": "amli/03_05-09-regression.html#review-what-data-analysis-and-preparation-techniques-have-we-learned-about",
    "title": "Machine Learning",
    "section": "Review: What data analysis and preparation techniques have we learned about?",
    "text": "Review: What data analysis and preparation techniques have we learned about?\n\nWe have also done quite a bit of data analysis and manipulation. What are some techniques and tools we have learned?\n@Exercise(5 minutes) { Have students talk about the tools and techniques they have learned about. If they need prompting, remind them about standardization and normalization. Remind them about detecting missing data and how to fix the data points that are missing. Remind them about basic sanity checking. Remind them about finding bias in the data. }"
  },
  {
    "objectID": "amli/03_05-09-regression.html#review-how-do-we-measure-the-quality-of-a-model",
    "href": "amli/03_05-09-regression.html#review-how-do-we-measure-the-quality-of-a-model",
    "title": "Machine Learning",
    "section": "Review: How do we measure the quality of a model?",
    "text": "Review: How do we measure the quality of a model?\n\nOnce we build a model, how do we know if it is any good? What are some ways for us to test model quality?\n@Exercise(5 minutes) { Have students talk about testing and model quality. If they need prompting, remind the students about having a final validation holdout. Remind them we can measure attributes such as root mean squared error and mean absolute error. Remind them we also validate internally in the model as we perform optimization. Be sure that ‘generalization’ is brought up. We don’t want a model that just scores well while being trained. We want a model that generalizes well to data it has never seen. Remind them we test this by utilizing training, testing, and validation sets. }"
  },
  {
    "objectID": "amli/03_05-09-regression.html#regression-project-the-data",
    "href": "amli/03_05-09-regression.html#regression-project-the-data",
    "title": "Machine Learning",
    "section": "Regression Project: The Data",
    "text": "Regression Project: The Data\n\n\n\nColumn\nType\nDescription\n\n\n\n\nage\nnumber\nage of primary beneficiary\n\n\nsex\nstring\ngender of the primary beneficiary\n\n\nbmi\nnumber\nbody mass index of the primary beneficiary\n\n\nchildren\nnumber\nnumber of children covered by the plan\n\n\nsmoker\nstring\nis the primary beneficiary a smoker\n\n\nregion\nstring\ngeographic region of the beneficiaries\n\n\ncharges\nnumber\ncosts to the insurance company (target)\n\n\n\n\nHere are the columns of data you’ll be working with. As you can see, we have both numbers and strings. The target column is ‘charges’, and it is a continuously varying number."
  },
  {
    "objectID": "amli/03_05-09-regression.html#regression-project-your-turn",
    "href": "amli/03_05-09-regression.html#regression-project-your-turn",
    "title": "Machine Learning",
    "section": "Regression Project: Your Turn",
    "text": "Regression Project: Your Turn\n\nProblem Framing: Understand the context, potential biases, and impact.\nExploratory Data Analysis (EDA): Acquire, clean, and visualize the data.\nModel Building: Choose, train, and evaluate a regression model.\n\n\nIt is now your turn to perform a regression from end-to-end.\nThe lab you are about to be given is divided into three primary parts, shown on this slide.\nIn the “Problem Framing” section, you’ll be given the context for your insurance charges model and asked questions about how machine learning might or might not be the best tool for the job, how the data might be biased, and how the model fits in the overall solution. This section exists to remind you that we create these models to help drive decisions, and those decisions have impact. There aren’t necessarily right or wrong answers here. We are interested in you thinking through the issues and coming up with your own opinion.\nIn the next section, you’ll acquire and explore the data. In this section we expect you to write code and prose about the data. Does the data have obvious problems? Do any model-independent changes need to be made to the data? EDA is the place to reason about and perform these tasks.\nThe final section is the modeling section. In this section we expect you to build and train a model to perform regression. Then measure the quality of that model using, at minimum, a final root mean squared error. It doesn’t matter if you perform a linear regression or build a neural network. We just want to see a model built and trained. It would be good if your final RMSE was near or better than the benchmark mentioned in the lab, but that isn’t a strict requirement.\nFeel free to use any of the tools that we have covered in this course so far.\nTake your time. Experiment. Don’t be afraid to throw away some work along the way."
  },
  {
    "objectID": "amli/04_05-09-classification.html#the-nature-of-image-features",
    "href": "amli/04_05-09-classification.html#the-nature-of-image-features",
    "title": "Machine Learning",
    "section": "The Nature of Image Features",
    "text": "The Nature of Image Features\nWhat makes image classification unique? Each pixel is a feature, represented by numerical values.\n\nPixel Grid Representation\nWhat makes image classification different from other forms of classification? One major difference is the features. When classifying an image, each pixel is a feature. How are these pixels represented? Understanding this representation is fundamental for ECE students to grasp data acquisition and processing."
  },
  {
    "objectID": "amli/04_05-09-classification.html#rgb-pixel-values",
    "href": "amli/04_05-09-classification.html#rgb-pixel-values",
    "title": "Machine Learning",
    "section": "RGB Pixel Values",
    "text": "RGB Pixel Values\nPixels are often encoded using Red, Green, and Blue (RGB) values. Each color component typically ranges from 0 to 255.\n\nRGB Color Model\nOften pixels are represented as RGB values. These are three numbers that indicate the amount of red, green, and blue in an image. These numbers often range from 0 to 255. This multi-channel representation is key for color images, but it significantly increases feature dimensionality."
  },
  {
    "objectID": "amli/04_05-09-classification.html#feature-dimensions-a-challenge",
    "href": "amli/04_05-09-classification.html#feature-dimensions-a-challenge",
    "title": "Machine Learning",
    "section": "Feature Dimensions: A Challenge",
    "text": "Feature Dimensions: A Challenge\nConsider a 1920 × 1920 image. How many features if represented by RGB values?\n\nLet’s take a moment to think about the number of features we are dealing with there. Say we have a 1920 by 1920 pixel image. How many features would we have? This calculation highlights the computational burden of raw pixel data."
  },
  {
    "objectID": "amli/04_05-09-classification.html#feature-dimensions-the-calculation",
    "href": "amli/04_05-09-classification.html#feature-dimensions-the-calculation",
    "title": "Machine Learning",
    "section": "Feature Dimensions: The Calculation",
    "text": "Feature Dimensions: The Calculation\n\\[ 1920 \\times 1920 \\times 3 = 11,059,200 \\]\nThat’s over 11 million input features! Data can be viewed as a 3D tensor: Width × Height × Channels.\n\nThat’s over 11 million input features! This is an enormous number for a standard machine learning model to handle directly. We can think of the data as a 3-d matrix (or a tensor) with dimensions 1920 x 1920 x 3."
  },
  {
    "objectID": "amli/04_05-09-classification.html#interactive-feature-calculator",
    "href": "amli/04_05-09-classification.html#interactive-feature-calculator",
    "title": "Machine Learning",
    "section": "Interactive Feature Calculator",
    "text": "Interactive Feature Calculator\nExplore how image dimensions and color channels impact the total number of features.\n\nviewof image_width = Inputs.range([10, 2000], {value: 1920, step: 10, label: \"Image Width (pixels):\"});\nviewof image_height = Inputs.range([10, 2000], {value: 1920, step: 10, label: \"Image Height (pixels):\"});\nviewof color_channels = Inputs.select([\"1 (Grayscale)\", \"3 (RGB/BGR)\", \"4 (RGBA/BGRA)\"], {value: \"3 (RGB/BGR)\", label: \"Color Channels:\"});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nAdjust the sliders and dropdown to see the feature count change dynamically!\n\n\n\n\n\n\n\n\n\n:::\n\nThis interactive calculator helps visualize the scale of image data. Students can play with different resolutions and channel counts to directly observe the explosion of features. This ties into computational complexity and hardware considerations in ECE."
  },
  {
    "objectID": "amli/04_05-09-classification.html#even-more-features",
    "href": "amli/04_05-09-classification.html#even-more-features",
    "title": "Machine Learning",
    "section": "Even More Features",
    "text": "Even More Features\nHow many features would a 12 megapixel image (common for phone cameras) have if stored in RGB?\n\nLet’s try another one. How many features would we have for a a 12 megapixel image stored in RGB? This resolution (or greater) is common for mobile phones these days. This is a practical example of real-world image sizes."
  },
  {
    "objectID": "amli/04_05-09-classification.html#megapixel-feature-count",
    "href": "amli/04_05-09-classification.html#megapixel-feature-count",
    "title": "Machine Learning",
    "section": "Megapixel Feature Count",
    "text": "Megapixel Feature Count\n\\[ 12,000,000 \\times 3 = 36,000,000 \\]\nAn extremely large number of features! This makes training traditional models difficult. Lower resolution images are often used for initial training.\n\nThis is an insanely huge number of features. It is extremely difficult for a model to perform well with such a huge number of features directly. That is why you’ll notice that the images we use in this lab are very low resolution. This also motivates the need for specialized architectures like Convolutional Neural Networks (CNNs) that can handle such high dimensionality efficiently."
  },
  {
    "objectID": "amli/04_05-09-classification.html#grayscale-reducing-complexity",
    "href": "amli/04_05-09-classification.html#grayscale-reducing-complexity",
    "title": "Machine Learning",
    "section": "Grayscale: Reducing Complexity",
    "text": "Grayscale: Reducing Complexity\nGrayscale images use a single number (e.g., 0-255 or 0.0-1.0) to represent pixel intensity. This effectively reduces the feature count by a factor of three.\n\nGrayscale Image\nAnother way to reduce the number of features is to convert them to grayscale. Grayscale uses a single number to represent the intensity of color in a pixel, but it doesn’t specify the color. The range of values that you’ll find vary. In this lab we work with one dataset that has a grayscale range of 0 through 255 and another that goes from 0 through 16. Grayscale values might even be in the range from 0.0 through 1.0. For neural networks this smaller range is easier to train on and aids in faster convergence."
  },
  {
    "objectID": "amli/04_05-09-classification.html#other-image-formats",
    "href": "amli/04_05-09-classification.html#other-image-formats",
    "title": "Machine Learning",
    "section": "Other Image Formats",
    "text": "Other Image Formats\nBeyond RGB and Grayscale, various formats exist, each with specific applications:\n\nHSV: Hue, Saturation, Value (perceptually organized)\nHSL: Hue, Saturation, Light (perceptually organized)\nCMYK: Cyan, Magenta, Yellow, Black (for printing)\nBGR: Blue, Green, Red (common in some computer vision libraries)\n\n\nThere are more color models than RGB and grayscale. A few alternatives are listed in this slide. You’ll notice that some, like CMYK, have more values than RGB. BGR, on the other hand, is just RGB in a different order. Understanding these alternatives is important for ECE students who might work with cameras, displays, or different image processing pipelines."
  },
  {
    "objectID": "amli/04_05-09-classification.html#real-world-image-challenges",
    "href": "amli/04_05-09-classification.html#real-world-image-challenges",
    "title": "Machine Learning",
    "section": "Real-World Image Challenges",
    "text": "Real-World Image Challenges\nImages encountered in real-world scenarios are rarely simple. They often contain multiple objects and background clutter.\n\nBusy Street Scene\nAnother interesting aspect of image classification is that images rarely contain just a single item. Take this image, for instance. It contains buildings, cars, people, and more. With an image like this, it can be hard for the model to identify the important features. Sometimes this requires the researcher to pre-process and clean the images. Sometimes it requires additional model tuning. This is where ECE expertise in signal processing and intelligent systems becomes critical."
  },
  {
    "objectID": "amli/04_05-09-classification.html#lab-exercise-fashion-mnist",
    "href": "amli/04_05-09-classification.html#lab-exercise-fashion-mnist",
    "title": "Machine Learning",
    "section": "Lab Exercise: Fashion-MNIST",
    "text": "Lab Exercise: Fashion-MNIST\nWe’ll start with controlled datasets, like Fashion-MNIST: 70,000 grayscale, 28x28 pixel images of single clothing items.\n\nAnkle Boot Example\nIn the lab for this unit, we’ll work with some very curated datasets. The first dataset we’ll work with is the Fashion-MNIST dataset. The dataset contains 70,000 images of different clothing items. Each image is a grayscale image, only contains one item, and is only 28x28 pixels. This low-resolution and curated nature allows us to focus on the classification task without overwhelming computational resources."
  },
  {
    "objectID": "amli/04_05-09-classification.html#fashion-mnist-class-labels",
    "href": "amli/04_05-09-classification.html#fashion-mnist-class-labels",
    "title": "Machine Learning",
    "section": "Fashion-MNIST Class Labels",
    "text": "Fashion-MNIST Class Labels\n\n\n\nLabel\nClass\n\n\n\n\n0\nT-shirt/top\n\n\n1\nTrouser\n\n\n2\nPullover\n\n\n3\nDress\n\n\n4\nCoat\n\n\n5\nSandal\n\n\n6\nShirt\n\n\n7\nSneaker\n\n\n8\nBag\n\n\n9\nAnkle boot\n\n\n\n\nThe images in the Fashion-MNIST dataset are labeled with one of the shown classes. The numeric label is the target of the model. This is a multi-class classification problem."
  },
  {
    "objectID": "amli/04_05-09-classification.html#lab-exercise-mnist-digits",
    "href": "amli/04_05-09-classification.html#lab-exercise-mnist-digits",
    "title": "Machine Learning",
    "section": "Lab Exercise: MNIST Digits",
    "text": "Lab Exercise: MNIST Digits\nAnother clean dataset: handwritten digits for classification (0-9). Similar 28x28 grayscale format, one digit per image.\n\nHandwritten Digits\nWe’ll also work with the MNIST digits dataset. This dataset contains handwritten digits that we’ll classify as 0 through 9. This is also a very clean dataset with one digit per image. Both Fashion-MNIST and MNIST are benchmarks in machine learning for image classification, ideal for introductory labs."
  },
  {
    "objectID": "amli/04_05-09-classification.html#your-turn",
    "href": "amli/04_05-09-classification.html#your-turn",
    "title": "Machine Learning",
    "section": "Your Turn!",
    "text": "Your Turn!\nGet hands-on experience with image classification datasets."
  },
  {
    "objectID": "amli/04_05-09-classification.html#what-is-an-image-really",
    "href": "amli/04_05-09-classification.html#what-is-an-image-really",
    "title": "Machine Learning",
    "section": "What is an Image, Really?",
    "text": "What is an Image, Really?\nAt its core, an image is a grid of pixels. Each pixel is a sampled data point representing color at a specific location.\n\nLet’s think for a second. What is an image actually? You likely know that an image is a grid of pixels. And each pixel represents a single color point in the image. But how is that pixel encoded? From an ECE perspective, this means understanding analog-to-digital conversion and spatial sampling."
  },
  {
    "objectID": "amli/04_05-09-classification.html#image-encodings",
    "href": "amli/04_05-09-classification.html#image-encodings",
    "title": "Machine Learning",
    "section": "Image Encodings",
    "text": "Image Encodings\nNot all pixels are encoded in the same way. Various encoding schemes exist, influencing data representation and processing.\n\nNot all pixels are encoded in the same way. There are actually quite a few different encodings for images. Choosing the right encoding can significantly impact memory usage, processing speed, and model performance."
  },
  {
    "objectID": "amli/04_05-09-classification.html#grayscale-vs.-color-images",
    "href": "amli/04_05-09-classification.html#grayscale-vs.-color-images",
    "title": "Machine Learning",
    "section": "Grayscale vs. Color Images",
    "text": "Grayscale vs. Color Images\nA primary distinction: single-channel grayscale or multi-channel color. This choice affects feature count and information richness.\n\nColor vs Grayscale Car\nOne of the first distinctions to be made is if the image is made up pixels on a “gray scale” or if the image is made from a larger spectrum of colors. In this example you can see that the image on the left has many colors, including some reds while the image on the right is limited to black, white, and the grays in between. What does this mean for the encoding? This decision impacts the computational load and the type of features a model can extract."
  },
  {
    "objectID": "amli/04_05-09-classification.html#grayscale-pixel-ranges",
    "href": "amli/04_05-09-classification.html#grayscale-pixel-ranges",
    "title": "Machine Learning",
    "section": "Grayscale Pixel Ranges",
    "text": "Grayscale Pixel Ranges\nGrayscale values can range from: - Integers: [0, 255] (8-bit unsigned integer) - Floats: [0.0, 1.0] (normalized for neural networks)\n\nGrayscale Car\nWe’ll start with the simplest format, grayscale. Grayscale images have a single numeric value representing each pixel in the image. But what are those numbers? Typically they range from 0 to 255 if they are integers or 0.0 to 1.0 if they are floating point values. Even with grayscale images, it is important to know the range of values for the input pixels. If the pixels range from 0.0 to 1.0 then many models will be able to more easily train on the images due to better gradient flow properties. If the values are integers between 0 and 255, then it is typically a good idea to divide the values by 255.0 in order to bring them into the 0.0 to 1.0 range that neural networks prefer to help models learn more quickly. This normalization is a common pre-processing step in ECE ML applications."
  },
  {
    "objectID": "amli/04_05-09-classification.html#interactive-pixel-normalizer",
    "href": "amli/04_05-09-classification.html#interactive-pixel-normalizer",
    "title": "Machine Learning",
    "section": "Interactive Pixel Normalizer",
    "text": "Interactive Pixel Normalizer\nNormalize a pixel value from [0, 255] to [0.0, 1.0] or vice versa.\n\nviewof pixel_value_0_255 = Inputs.range([0, 255], {value: 128, step: 1, label: \"Input Pixel Value (0-255):\"});\nviewof normalization_type = Inputs.select([\"Normalize to [0.0, 1.0]\", \"Scale to [0, 255] (from [0.0, 1.0])\"], {value: \"Normalize to [0.0, 1.0]\", label: \"Operation:\"});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n:::\n\nDemonstrating pixel normalization is vital for ECE students. It shows how raw sensor data (e.g., 0-255 from an ADC) is often transformed into a range amenable to neural network training, which is typically floating-point values between 0 and 1. This interactive element allows them to see the direct mapping."
  },
  {
    "objectID": "amli/04_05-09-classification.html#color-image-encodings-a-spectrum",
    "href": "amli/04_05-09-classification.html#color-image-encodings-a-spectrum",
    "title": "Machine Learning",
    "section": "Color Image Encodings: A Spectrum",
    "text": "Color Image Encodings: A Spectrum\nFrom RGB to CMYK, many color spaces exist. Each offers a different way to represent color, impacting applications from display technology to printing.\n\nColor Car\nGrayscale images typically are one of the two encodings that we mentioned. It is of course important to know which encoding your images are in since a model expects inputs to be on the same scale. However, converting between [0.0, 1.0] and [0, 255] is fairly trivial. Color images introduce an entirely new level of encoding complexity. There are scores of encodings for color images. One of the more common ones that you might have seen is RGB. RGB stands for “red”, “green”, “blue”. With these three colors you can make scores of other colors. With RGB encoding a value, typically between 0 and 255 (though sometimes between 0.0 and 1.0), you can combine the colors to create a rainbow of possibility. With RGB you have three numeric values for each pixel. This triples the size of your inputs! But that is not all. There is RGBA, which takes our red, green, and blue and adds an “alpha” channel which represents the opacity of the pixel. Opacity? Typically when we think of an image, we think about only seeing that image. But what if we put an image under the image we were looking at? If there were no opacity, then we’d only see the topmost image. If there is opacity (think transparency) then we would see a little bit of the underlying image too. The alpha channel, also typically between 0 and 255 or 0.0 and 1.0, manages how “see-through” our pixel is. But why RGB? Why not BRG or GBR or any other ordering? It turns out that there are other orderings, one of the more common being BGR. This was a common encoding in early digital cameras for hardware reasons that aren’t relevant to our topic. Just know that color order can change, and you need to make sure that your inputs for training and predicting have the same encodings. Of course, this begs the question. Are reds, greens, blues, and maybe alphas the only way to encode color? Of course not! There are other schemes such as CMYK, which stands for cyan, magenta, yellow, and black. Encodings aren’t complicated individually, but the number and variety of image encodings can be difficult to work with. Know your inputs!"
  },
  {
    "objectID": "amli/04_05-09-classification.html#modifying-images-encoding-transformations",
    "href": "amli/04_05-09-classification.html#modifying-images-encoding-transformations",
    "title": "Machine Learning",
    "section": "Modifying Images: Encoding Transformations",
    "text": "Modifying Images: Encoding Transformations\nPython libraries like OpenCV (cv) and NumPy (for array operations) facilitate these transformations.\nimport cv2\n\n# Convert from BGR encoding (common in OpenCV) to RGB \nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n# Normalize pixel values from [0, 255] to [0.0, 1.0]\nimage = image / 255.0\n\n# Scale pixel values from [0.0, 1.0] back to [0, 255]\nimage = (image * 255).astype(int) \n\nWe talked about image encodings and how it is important to feed your model images encoded in the same way. In order to do this you have a few options. If you are converting encodings, you can use the OpenCV cvtColor function to do the conversion for you. If you are scaling the encodings you can use simple Python expressions with NumPy arrays. These are standard operations in many ECE signal processing pipelines."
  },
  {
    "objectID": "amli/04_05-09-classification.html#modifying-images-resizing",
    "href": "amli/04_05-09-classification.html#modifying-images-resizing",
    "title": "Machine Learning",
    "section": "Modifying Images: Resizing",
    "text": "Modifying Images: Resizing\nResizing images is often necessary to match model input requirements. Care must be taken to avoid distortion.\n\nResized Running Shoe\nBut what about scaling/resizing an image? Some models have a scaling layer as an early step, but not all do. Also, you may want more control of your image when you scale it. In the example in this slide we simply scaled the image down to a size that presumptively the model expects. We could have also padded it into a proportional square or rectangle before resizing. Resizing algorithms can involve various interpolation methods (e.g., nearest-neighbor, bilinear, bicubic), which are key considerations in image processing."
  },
  {
    "objectID": "amli/04_05-09-classification.html#modifying-images-padding",
    "href": "amli/04_05-09-classification.html#modifying-images-padding",
    "title": "Machine Learning",
    "section": "Modifying Images: Padding",
    "text": "Modifying Images: Padding\nPadding helps maintain aspect ratio and prevents image distortion during resizing. Useful for ensuring all images conform to a fixed input size.\n\nPadded Running Shoe\nBut you don’t always just want to blindly resize an image. That might distort it. In some cases you’ll want to pad an image with whatever the background color is and then resize it in order to avoid distorting the image. To do this, you must find the number of pixels to add to the height of the image and divide those pixels across the top and bottom of the image. You must do the same for the left and right of the image. This is a common pre-processing technique, especially in image recognition with CNNs."
  },
  {
    "objectID": "amli/04_05-09-classification.html#modifying-images-centering",
    "href": "amli/04_05-09-classification.html#modifying-images-centering",
    "title": "Machine Learning",
    "section": "Modifying Images: Centering",
    "text": "Modifying Images: Centering\nAdvanced techniques can find and center the focal object. Algorithms like Canny edge detection help pinpoint important features.\n\nCar with Edge Detection Lines\nIf we have images with a predictable solid background, we can actually perform more complex processing and try to find the center of the focal object. Using algorithms like the Canny algorithm, we can find the key strokes and make our image, hone in on them, and find the center of our image. We can then pad around that. This involves control systems and image analysis, direct applications for ECE students."
  },
  {
    "objectID": "amli/04_05-09-classification.html#modifying-images-rotation",
    "href": "amli/04_05-09-classification.html#modifying-images-rotation",
    "title": "Machine Learning",
    "section": "Modifying Images: Rotation",
    "text": "Modifying Images: Rotation\nImage augmentation often involves various transformations, including rotation, to increase data diversity and model robustness.\n\nRotated Color Car\nOther image manipulation tricks involve rotations. You can augment an image by spinning it around. Data augmentation like rotation helps improve model generalization by exposing it to varied orientations of objects without needing more real-world data."
  },
  {
    "objectID": "amli/04_05-09-classification.html#other-image-augmentations",
    "href": "amli/04_05-09-classification.html#other-image-augmentations",
    "title": "Machine Learning",
    "section": "Other Image Augmentations",
    "text": "Other Image Augmentations\nWhat other image augmentations can you imagine?\n\nCutting/Mixup: Splicing parts of images to create new training examples.\nDropout: Randomly removing portions of an image during training.\nGenerative Models: Creating synthetic data to augment existing datasets.\nColor Jittering: Randomly adjusting brightness, contrast, saturation.\n\n\nWhat are some other image augmentations that you can think of? Some others include: ‘cutting’: where images of the same class are spliced together to increase the size of the training data set. ‘drop out’: where portions of training images are removed during training. Generating fake data based from a model that is then used to train another model. There are many more strategies and none are right for every model. You have to experiment. Data augmentation is a powerful technique to prevent overfitting and improve model performance in data-scarce scenarios, a critical aspect of practical ML deployment in ECE systems."
  },
  {
    "objectID": "amli/04_05-09-classification.html#understanding-video-data",
    "href": "amli/04_05-09-classification.html#understanding-video-data",
    "title": "Machine Learning",
    "section": "Understanding Video Data",
    "text": "Understanding Video Data\nFor our purposes, video is simply a sequence of images (frames).\nConsider:\n\nFrame Rate (FPS): Number of images per second (e.g., 30 fps, 60 fps).\nChange between frames: Varies greatly based on content.\n\n\nThis section also talks about video. We are going to greatly simplify video. If you think about a video feed, it has images, it has sound, it might have captions and other optional features. For our case in this course, video will simply be a series of images and we will treat it as such. Much of the video we watch is 30 “frames per second” (fps) or 60 fps. Think of each of these frames as a still image. Now think about how much changes between frames in 1/30th of a second? Well, it depends on what type of video you are processing. Are you watching the spray from a sneeze? Are you watching ice melt? Video might simply be a “series of images” for our purposes, but you still need to consider what you are modelling. This understanding is key for ECE applications in real-time video processing, such as autonomous vehicles or surveillance."
  },
  {
    "objectID": "amli/04_05-09-classification.html#your-turn-1",
    "href": "amli/04_05-09-classification.html#your-turn-1",
    "title": "Machine Learning",
    "section": "Your Turn",
    "text": "Your Turn\nIt’s time to practice working with images and video.\nThis involves multiple labs:\n\nImage processing with PIL (Pillow).\nImage processing with OpenCV.\nVideo processing (extracting frames from video).\n\nThese labs build towards a project on classifying items in a video. Have fun!"
  },
  {
    "objectID": "amli/04_05-09-classification.html#pickling-scikit-learn-models",
    "href": "amli/04_05-09-classification.html#pickling-scikit-learn-models",
    "title": "Machine Learning",
    "section": "Pickling scikit-learn Models",
    "text": "Pickling scikit-learn Models\nStandard Python’s pickle module can serialize (save) and deserialize (load) scikit-learn models.\n\n\nSaving a model\nimport pickle\nfrom sklearn.linear_model import LogisticRegression\n# Assume 'model' is a trained scikit-learn model\nmodel = LogisticRegression() # Placeholder for a real trained model\n# ... train model ...\n\nmodel_file = 'my_model.pkl'\n\nwith open(model_file, 'wb') as output:\n    pickle.dump(model, output, pickle.HIGHEST_PROTOCOL)\n\nLoading and using a model\nimport pickle\nmodel_file = 'my_model.pkl'\n\nwith open(model_file, 'rb') as input:\n    model_restored = pickle.load(input)\n\n# Example: make a prediction (dummy input)\nprint(model_restored.predict([[45, 34, 2]])) # Placeholder\n\n\nFor models created using scikit-learn, we can use standard Python pickling to persist and reload the model. pickle.HIGHEST_PROTOCOL ensures compatibility and efficiency. This method is straightforward for simpler models, but attention to library versions is important for compatibility."
  },
  {
    "objectID": "amli/04_05-09-classification.html#saving-and-loading-keras-models",
    "href": "amli/04_05-09-classification.html#saving-and-loading-keras-models",
    "title": "Machine Learning",
    "section": "Saving and Loading Keras Models",
    "text": "Saving and Loading Keras Models\nKeras (built on TensorFlow) provides native functions for saving and loading models in its own format or H5.\n\n\nSaving a Keras model\nimport tensorflow as tf\nfrom tensorflow import keras\n# Assume 'model' is a trained Keras model\nmodel = keras.Sequential([keras.layers.Dense(1, input_shape=(3,))]) # Placeholder\n\ntf.keras.models.save_model(\n    model, 'my_model.tf'\n)\n\nLoading a Keras model\nimport tensorflow as tf\n\nloaded_model = tf.keras.models.load_model(\n    'my_model.tf'\n)\n# Example: Summarize the loaded model\nloaded_model.summary()\n\n\nKeras-based models can be saved and loaded using the save_model and load_model functions. By default the models are in a TensorFlow-specific format, which is optimized for TensorFlow’s execution graphs. However, the models can also be saved as H5, which is another popular file format for storing models, often more portable. This is particularly relevant for ECE engineers deploying Keras models on various hardware accelerators."
  },
  {
    "objectID": "amli/04_05-09-classification.html#loading-frozen-graphs-historical-context",
    "href": "amli/04_05-09-classification.html#loading-frozen-graphs-historical-context",
    "title": "Machine Learning",
    "section": "Loading Frozen Graphs: Historical Context",
    "text": "Loading Frozen Graphs: Historical Context\n“Frozen graphs” refer to TensorFlow 1.x models saved as a single .pb file. They represent a static computation graph with embedded weights.\n\n\nLoading the Graph Definition\nimport tensorflow as tf\nimport os\n\nfrozen_graph_path = os.path.join(\"path\", 'frozen_inference_graph.pb')\n\nwith tf.io.gfile.GFile(frozen_graph_path, \"rb\") as f:\n    graph_def = tf.compat.v1.GraphDef()\n    loaded = graph_def.ParseFromString(f.read())\n\n\n\n\n\n\n\nNote\n\n\nThis process uses tf.compat.v1, indicating compatibility for older TensorFlow 1.x models within a TensorFlow 2.x environment.\n\n\n\n\n\nThere is also the concept of freezing graphs. Some models, such as the one we’re going to use in this lab and in our next project, are distributed in this manner. In order to “unfreeze” a graph, you must first load the graph into a GraphDef object. Notice that this is using a TensorFlow version 1 compatibility layer object. This process is useful for loading models built in TensorFlow version 1, which many legacy systems in ECE might still use."
  },
  {
    "objectID": "amli/04_05-09-classification.html#loading-frozen-graphs-wrapping-for-tf2",
    "href": "amli/04_05-09-classification.html#loading-frozen-graphs-wrapping-for-tf2",
    "title": "Machine Learning",
    "section": "Loading Frozen Graphs: Wrapping for TF2",
    "text": "Loading Frozen Graphs: Wrapping for TF2\nTensorFlow 1.x used lazy execution; TensorFlow 2.x uses eager execution. tf.compat.v1.wrap_function bridges this gap for seamless integration.\ndef wrap_graph(graph_def, inputs, outputs, print_graph=False):\n    wrapped = tf.compat.v1.wrap_function(\n        lambda: tf.compat.v1.import_graph_def(graph_def, name=\"\"), [])\n\n    # Prune the graph to only include specified inputs and outputs\n    return wrapped.prune(\n        tf.nest.map_structure(wrapped.graph.as_graph_element, inputs),\n        tf.nest.map_structure(wrapped.graph.as_graph_element, outputs))\n  \n# Example usage:\nmodel = wrap_graph(graph_def=graph_def,\n                   inputs=[\"image_tensor:0\"], # Name of the input tensor\n                   outputs=[\"detection_boxes:0\", \"detection_scores:0\"]) # Example output tensors\n\nThe programming models of TensorFlow 1 and 2 are quite a bit different. TensorFlow 1 used lazy execution (defining the graph first, executing later) while TensorFlow 2 uses eager execution (operations execute immediately). In order to bridge the gap in these execution models, we need to wrap our TensorFlow version 1 graph. This wrapping makes the TF1 graph behave like a TF2 callable function, simplifying its use in modern workflows. This is a common challenge for ECE engineers maintaining or upgrading ML infrastructure."
  },
  {
    "objectID": "amli/04_05-09-classification.html#loading-frozen-graphs-using-the-wrapped-model",
    "href": "amli/04_05-09-classification.html#loading-frozen-graphs-using-the-wrapped-model",
    "title": "Machine Learning",
    "section": "Loading Frozen Graphs: Using the Wrapped Model",
    "text": "Loading Frozen Graphs: Using the Wrapped Model\nOnce wrapped, the frozen graph can be used like any other TensorFlow 2.x callable.\n# Assuming 'tensor' is a pre-processed image tensor\npredictions = model(tensor) \n\n# 'predictions' would contain the outputs defined earlier, e.g.,\n# predictions[\"detection_boxes:0\"], predictions[\"detection_scores:0\"]\n\nAnd now we can use the model as a function. We pass it in tensor objects and get predictions back. This demonstrates how backward compatibility is handled, enabling ECE professionals to leverage older, pre-trained models."
  },
  {
    "objectID": "amli/04_05-09-classification.html#your-turn-2",
    "href": "amli/04_05-09-classification.html#your-turn-2",
    "title": "Machine Learning",
    "section": "Your Turn",
    "text": "Your Turn\nPractice saving and loading models using different frameworks to understand their practical deployment."
  },
  {
    "objectID": "amli/04_05-09-classification.html#review-image-data-representation",
    "href": "amli/04_05-09-classification.html#review-image-data-representation",
    "title": "Machine Learning",
    "section": "Review: Image Data Representation",
    "text": "Review: Image Data Representation\nHow is image data typically represented and stored? What are the features?\n\nExercise (5 minutes) Have students discuss the fact that images are simply pixels. There are different ways to represent pixels, but it’s common to use RGB values that each range from 0 to 255. Each pixel is a feature. Remind them that image data can be challenging to work with because it is often very large. For example, a 12 megapixel image has 36,000,000 features. You may mention that grayscale is one way to cut down on the number of features. This review reinforces the foundational concepts before tackling the project."
  },
  {
    "objectID": "amli/04_05-09-classification.html#review-python-libraries-for-imagevideo",
    "href": "amli/04_05-09-classification.html#review-python-libraries-for-imagevideo",
    "title": "Machine Learning",
    "section": "Review: Python Libraries for Image/Video",
    "text": "Review: Python Libraries for Image/Video\nWhat Python libraries have we used for image and video manipulation?\n\nExercise (5 minutes) Have students discuss the labs they completed using PIL (Pillow) and OpenCV. These are industry-standard libraries, and knowing their application is crucial for ECE students in computer vision."
  },
  {
    "objectID": "amli/04_05-09-classification.html#review-classification-with-image-data",
    "href": "amli/04_05-09-classification.html#review-classification-with-image-data",
    "title": "Machine Learning",
    "section": "Review: Classification with Image Data",
    "text": "Review: Classification with Image Data\nHow have you performed classification tasks with image data?\n\nExercise (5 minutes) Have students discuss the fact that they used TensorFlow to train a simple classification model for the Fashion MNIST dataset. This was a prefabricated dataset that was relatively small, so it was possible to train a simple model locally and in a reasonable amount of time. For larger classification tasks, we discussed using pre-built models (specifically those stored in the TensorFlow detection model zoo). This connects past labs to the current project and future complex applications."
  },
  {
    "objectID": "amli/04_05-09-classification.html#video-processing-project-overview",
    "href": "amli/04_05-09-classification.html#video-processing-project-overview",
    "title": "Machine Learning",
    "section": "Video Processing Project Overview",
    "text": "Video Processing Project Overview\nProcess video frame-by-frame, applying a pre-trained object detection model. Visualize detections by drawing bounding boxes around identified objects.\n\nVideo Frame with Bounding Boxes\nNow let’s talk about the project for today! Here you can see a single frame of a video showing a road with a bunch of cars. A machine learning model, like the one you will use, has identified many of the cars in the image and labeled them as “car.” One was strangely labeled as a cell phone. Clearly models are not perfect. In this project we will process a video frame-by-frame and create bounding boxes around items found in those images by the third-party model. This real-world scenario demonstrates the power and limitations of current ML models."
  },
  {
    "objectID": "amli/04_05-09-classification.html#your-turn-3",
    "href": "amli/04_05-09-classification.html#your-turn-3",
    "title": "Machine Learning",
    "section": "Your Turn",
    "text": "Your Turn\nThis lab will exercise many of your Python and modeling skills. Let’s get started!"
  },
  {
    "objectID": "amli/04_05-09-classification.html#what-do-you-see-first",
    "href": "amli/04_05-09-classification.html#what-do-you-see-first",
    "title": "Machine Learning",
    "section": "What Do You See First?",
    "text": "What Do You See First?\nPerception can be ambiguous. Similarly, ML models can misinterpret data, leading to serious issues.\n\nDuck-Rabbit Ambiguous Illusion\nWhen you look at this, what do you see first? Raise your hand if it’s a duck you see first. Raise your hand if it’s a rabbit you see first. You’ve likely seen similar ambiguous images, images where one thing jumps out at you at first, and it takes a little longer to see something else. This phenomenon is likely based on humans and their individual schemas. But models can make the same kinds of errors, which can lead to some serious issues. Today we’ll discuss three separate scenarios of classifications that did not go as planned and the impact they caused."
  },
  {
    "objectID": "amli/04_05-09-classification.html#framing-harmful-classifications",
    "href": "amli/04_05-09-classification.html#framing-harmful-classifications",
    "title": "Machine Learning",
    "section": "Framing Harmful Classifications",
    "text": "Framing Harmful Classifications\n\nOften, bias is unintentional, not malicious.\nHowever, errors can be difficult to fix once deployed.\nMistakes can have long-lasting, negative repercussions on individuals or groups.\n\n\nMost people don’t set out to make a harmful or biased system; they set out to create a model that does one thing, but it ends up having other effects that could be unintended. This happens frequently. You can search for many, many examples of machine learning projects gone awry, some more serious than others. When these mistakes occur, they’re often very difficult to remedy because they require collecting new data, retraining a model, etc. If your dataset was biased to begin with, then focusing your data collection on only one type of data to remedy your initial issue may lead to another type of bias. These mistakes can have a negative and far-reaching impact on people or entire groups. Understanding the societal impact of ML is an ethical imperative for ECE professionals."
  },
  {
    "objectID": "amli/04_05-09-classification.html#group-activity",
    "href": "amli/04_05-09-classification.html#group-activity",
    "title": "Machine Learning",
    "section": "Group Activity",
    "text": "Group Activity\nDivide into groups (1, 2, 3) and each read a corresponding article. Be prepared to discuss the implications of “classification gone wrong.”\n\nGroup Collaboration Image\nLet’s break into groups by counting off 1, 2, and 3. Group 1, you will read the corresponding article. The same goes for groups 2 and 3."
  },
  {
    "objectID": "amli/04_05-09-classification.html#group-discussion-prompts",
    "href": "amli/04_05-09-classification.html#group-discussion-prompts",
    "title": "Machine Learning",
    "section": "Group Discussion Prompts",
    "text": "Group Discussion Prompts\n\nRead the article as a group (10 minutes).\nDiscuss the following questions (15 minutes):\n\nWhat was the original intent of this model/system?\nDescribe the bias with the model that led to this problem.\nWhat was the cause of this problem?\nAre there other mistakes that this model/system could make with this same root problem?\nWhat are the short-term and long-term impacts of this?\n\nEach group will present to the class (5 minutes/group).\n\n\nEach group will read their article and discuss these questions. After reading and your group discussion, each group will present to the class. You may have one member of your group present or several. When planning this 5-minute presentation, please allow one minute for questions. Give students a 5-minute warning to begin building a short presentation for the rest of the class. You can give students easel boards or posters to use as an aid to present or have them just use notes to verbally present. This encourages critical thinking and ethical analysis, vital skills for ECE graduates."
  },
  {
    "objectID": "amli/04_05-09-classification.html#class-discussion",
    "href": "amli/04_05-09-classification.html#class-discussion",
    "title": "Machine Learning",
    "section": "Class Discussion",
    "text": "Class Discussion\n\nWhat was most surprising or alarming about these examples of bias?\nHow can situations like this be prevented in future ML system designs?\nWhat is the real-world impact of these mistakes?\nWhat does this mean regarding your responsibility as professionals in ECE ML?\n\n\nNote: If time permits, open up the discussion to the entire class after each group has presented. Encourage more follow-up questions and/or reflections of the questions listed on the slide. This final discussion brings together the ethical and technical aspects of ML, preparing ECE students for real-world challenges."
  },
  {
    "objectID": "cs231n/neural-network-1.html#sources",
    "href": "cs231n/neural-network-1.html#sources",
    "title": "Machine Learning",
    "section": "Sources",
    "text": "Sources\nStanford University CS231n: Deep Learning for Computer Vision\nCS231n Deep Learning for Computer Vision"
  },
  {
    "objectID": "cs231n/neural-network-1.html#table-of-contents",
    "href": "cs231n/neural-network-1.html#table-of-contents",
    "title": "Machine Learning",
    "section": "Table of Contents",
    "text": "Table of Contents\n\nQuick Intro: Linear vs NN\nModeling One Neuron\n\nBiological Motivation\nSingle Neuron as Linear Classifier\nActivation Functions\n\nNeural Network Architectures\n\nLayer-wise Organization\nFeed-Forward Computation\nRepresentational Power\nSetting Layers & Sizes\n\nSummary\nAdditional References"
  },
  {
    "objectID": "cs231n/neural-network-1.html#quick-intro-beyond-linear-models",
    "href": "cs231n/neural-network-1.html#quick-intro-beyond-linear-models",
    "title": "Machine Learning",
    "section": "1. Quick Intro: Beyond Linear Models",
    "text": "1. Quick Intro: Beyond Linear Models\n\n\nLinear Classification:\n\nScores obtained directly from weighted input sum.\nExample: \\( s = W x \\)\n\n\\(x\\): input vector (e.g., image pixels).\n\\(W\\): weight matrix.\n\\(s\\): class scores.\n\n\n\n\n\n\n\n\nNote\n\n\nIssue: Limited to linear decision boundaries.\n\n\n\n\nNeural Network Approach (2-layer):\n\nIntroduces a non-linear transformation.\nExample: \\( s = W_2 (0, W_1 x) \\)\n\n\\(W_1\\): First layer weights.\n\\((0, )\\): Element-wise non-linearity (ReLU).\n\\(W_2\\): Second layer weights.\n\n\n\n\n\n\n\n\nImportant\n\n\nThe non-linearity is crucial for modeling complex relationships and introducing the “wiggle”.\n\n\n\n\n\nIn traditional linear classification, like SVMs or Softmax, we directly compute scores as a linear combination of inputs and weights. For example, for an image classification task, say CIFAR-10, an input image x (3072 pixels) is multiplied by a weight matrix W (10x3072) to produce 10 class scores. This approach is simple and interpretable but inherently limited to “linear” decision boundaries.\nNeural networks overcome this by introducing non-linear activation functions between layers. A simple two-layer network, as shown in the example s = W2 max(0, W1 x), first transforms the input x using W1, then applies a non-linear function (here, max(0,.) which is ReLU), and finally transforms it again with W2 to get the scores. This non-linearity is the key component; without it, multiple linear layers would collapse into a single linear operation, offering no additional power beyond a simple linear classifier. This “wiggle” allows neural networks to learn intricate, non-linear patterns in data."
  },
  {
    "objectID": "cs231n/neural-network-1.html#quick-intro-visualizing-the-flow",
    "href": "cs231n/neural-network-1.html#quick-intro-visualizing-the-flow",
    "title": "Machine Learning",
    "section": "Quick Intro: Visualizing the Flow",
    "text": "Quick Intro: Visualizing the Flow\n\n\n\n\n\ngraph LR\n    Input[\"Input Image (x)\"] --&gt; W1_Layer(\"Layer 1 - W1\")\n    W1_Layer --&gt; Nonlinearity[\"Non-Linear Activation (max(0, .))\"]\n    Nonlinearity --&gt; W2_Layer(\"Layer 2 - W2\")\n    W2_Layer --&gt; Scores[\"Output Scores (s)\"]\n\n    style Input fill:#f9f,stroke:#333,stroke-width:2px;\n    style Scores fill:#bbf,stroke:#333,stroke-width:2px;\n\n\n\n\n\n\n\nDeeper Networks:\n\nA three-layer network: \\( s = W_3 (0, W_2 (0, W_1 x)) \\)\nAdds more non-linear transformations.\nParameters \\(W_i\\) are learned via stochastic gradient descent and backpropagation.\n\n\n\nThis flowchart illustrates the forward pass of the two-layer neural network we just discussed. The input image x first goes through a linear transformation by W1. The result then undergoes a non-linear activation, which introduces the capacity to learn complex, non-linear relationships. Finally, another linear transformation by W2 produces the output class scores s.\nFor deeper networks, this process simply stacks more such layers, each with its own weights and non-linear activation. The key takeaway is that each layer adds a level of abstraction and complexity, allowing the network to learn rich representations of the input data. The learning process involves adjusting all these weight matrices, W1, W2, W3, based on the error in the output, using algorithms like backpropagation."
  },
  {
    "objectID": "cs231n/neural-network-1.html#modeling-one-neuron-biological-motivation",
    "href": "cs231n/neural-network-1.html#modeling-one-neuron-biological-motivation",
    "title": "Machine Learning",
    "section": "2. Modeling One Neuron: Biological Motivation",
    "text": "2. Modeling One Neuron: Biological Motivation\n\n\nBiological Neuron (Left):\n\nDendrites: Receive input signals.\nCell Body: Integrates signals.\nAxon: Transmits output signals.\nSynapses: Connections to other neurons, with variable strengths.\n\n\n\n\nA cartoon drawing of a biological neuron.\n\n\n\nComputational Model (Right):\n\nInputs (\\(x_i\\)) correspond to signals from other neurons.\nWeights (\\(w_i\\)) represent synaptic strengths (learnable).\nSummation: \\(_i w_i x_i + b\\) (cell body processing).\nActivation function (\\(f\\)): Simulates firing rate.\n\n\n\n\nMathematical model of a neuron.\n\n\n\n\nThe concept of a neural network is loosely inspired by biological neurons. On the left, you see a simplified diagram of a biological neuron. It receives signals through dendrites, processes them in the cell body, and sends out signals through its axon, which connects to other neurons via synapses.\nOn the right, we have the mathematical model. Each input x_i is multiplied by a corresponding weight w_i, mimicking synaptic strength. These weighted inputs are summed, along with a bias term b, representing the cell body’s integration. Finally, an activation function f (like sigmoid here) is applied to this sum. This function models the neuron’s “firing rate,” squashing the output to a specific range (e.g., 0 to 1). The weights w_i and bias b are the learnable parameters in this computational model.\nIt’s important to remember that this is a highly simplified model. Biological neurons are far more complex, with dynamic, non-linear dendritic computations and precise spike timing. We abstract away much of this complexity for computational tractability and effective machine learning."
  },
  {
    "objectID": "cs231n/neural-network-1.html#modeling-one-neuron-interactive-forward-pass",
    "href": "cs231n/neural-network-1.html#modeling-one-neuron-interactive-forward-pass",
    "title": "Machine Learning",
    "section": "Modeling One Neuron: Interactive Forward Pass",
    "text": "Modeling One Neuron: Interactive Forward Pass\nLet’s simulate a single neuron’s forward computation. You can modify inputs, weights, and bias to observe the firing_rate.\n\n\n\n\n\n\n\nThis interactive code block demonstrates the forward pass of our single neuron model. The sigmoid function is defined as our activation function. You are encouraged to change the values of inputs, weights, and bias within the designated section.\nObserve how changes to these parameters affect the cell_body_sum and subsequently the final firing_rate. For instance, try making the weights larger, smaller, or even negative, and see how the neuron’s output responds to different input patterns. This helps build an intuition for how the neuron “reacts” to its inputs based on its learned parameters."
  },
  {
    "objectID": "cs231n/neural-network-1.html#single-neuron-as-a-linear-classifier",
    "href": "cs231n/neural-network-1.html#single-neuron-as-a-linear-classifier",
    "title": "Machine Learning",
    "section": "Single Neuron as a Linear Classifier",
    "text": "Single Neuron as a Linear Classifier\nA single neuron’s output \\((_i w_i x_i + b)\\) can be interpreted as a probability.\n\nBinary Softmax Classifier (Logistic Regression)\n\n\\(P(y=1 x; w) = (_i w_i x_i + b)\\)\n\\(P(y=0 x; w) = 1 - P(y=1 x; w)\\)\nOptimized with cross-entropy loss.\n\nBinary SVM Classifier\n\nThe neuron’s output can be combined with a max-margin hinge loss.\nThe neuron effectively “fires” if the input falls into one class, and not for the other.\n\n\n\n\n\n\n\n\nTip\n\n\nRegularization: In this context, regularization loss (e.g., L2) can be seen as “gradual forgetting” of synaptic weights.\n\n\n\n\n\n\n\n\n\nNote\n\n\nA single neuron can be used to implement a binary classifier (e.g., binary Softmax or binary SVM classifiers).\n\n\n\n\nThis slide highlights the classification capabilities of a single neuron. When combined with a sigmoid activation function, the neuron’s output, ranging from 0 to 1, can be directly interpreted as the probability of an input belonging to one of two classes. This forms the basis of a Binary Softmax classifier, often referred to as logistic regression. The model is trained by minimizing the cross-entropy loss, which measures the difference between predicted and true probabilities.\nAlternatively, by attaching a max-margin hinge loss to the neuron’s output, it can be trained to function as a binary Support Vector Machine. In this case, the neuron aims to correctly classify inputs with a maximum margin between the classes.\nThe beauty of this is that the regularization terms used in these classifiers, like L2 regularization, can be seen from a biological perspective as a mechanism for “gradual forgetting,” naturally driving less important synaptic weights towards zero. This ensures that the model doesn’t become overly reliant on any single input feature, contributing to better generalization."
  },
  {
    "objectID": "cs231n/neural-network-1.html#commonly-used-activation-functions",
    "href": "cs231n/neural-network-1.html#commonly-used-activation-functions",
    "title": "Machine Learning",
    "section": "3. Commonly Used Activation Functions",
    "text": "3. Commonly Used Activation Functions\nAn activation function (or non-linearity) takes a single number and performs a fixed mathematical operation.\n\n\nSigmoid Function \\((x) = 1 / (1 + e^{-x})\\)\n\nSquashes real numbers to range [0, 1].\nHistorically popular for “firing rate” interpretation.\n\n\n\n\nSigmoid non-linearity.\n\n\n\n\n\n\n\n\nWarning\n\n\nDrawbacks:\n\nSaturates and kills gradients: At tails (0 or 1), gradient is near zero, hindering learning.\nNon-zero-centered output: Can lead to zig-zagging gradient updates.\n\n\n\n\n\nTanh Function \\((x) = 2 (2x) -1\\) * Squashes real numbers to range [-1, 1]. * Zero-centered output - an improvement over sigmoid.\n\n\n\nTanh non-linearity.\n\n\n\n\n\n\n\n\nNote\n\n\nPreferred over Sigmoid: Due to its zero-centered output, it generally performs better than sigmoid. Still suffers from saturation.\n\n\n\n\n\nActivation functions are crucial for introducing non-linearity into neural networks, allowing complex patterns to be learned. Without them, stacking multiple layers would simply result in another linear function, negating the benefits of depth.\nThe Sigmoid function, while historically significant, has severe limitations. Its “S” shape means that for very large positive or negative inputs, the output saturates quickly, causing its derivative (gradient) to become extremely small. During backpropagation, this small gradient effectively “kills” the learning signal for upstream layers, a problem known as the vanishing gradient problem. Additionally, its output is always positive, which can lead to inefficient “zig-zagging” in gradient descent as weight updates might always be in the same direction.\nThe Tanh function offers an improvement by being zero-centered, addressing one of sigmoid’s issues. However, it still suffers from the saturation problem, meaning large inputs will still lead to small gradients and hinder learning in those regions. Despite this, Tanh is generally preferred over Sigmoid when choosing classic activation functions."
  },
  {
    "objectID": "cs231n/neural-network-1.html#activation-functions-relu-and-variants",
    "href": "cs231n/neural-network-1.html#activation-functions-relu-and-variants",
    "title": "Machine Learning",
    "section": "Activation Functions: ReLU and Variants",
    "text": "Activation Functions: ReLU and Variants\n\n\nRectified Linear Unit (ReLU) \\(f(x) = (0, x)\\)\n\nOutput is 0 for negative input, \\(x\\) for positive input.\nPros:\n\nAccelerates convergence significantly.\nComputationally efficient (simple thresholding).\nDoes not saturate in the positive region.\n\n\n\n\n\nReLU activation function.\n\n\n\nReLU Cons & Variants:\n\n“Dying ReLU” problem: Neurons can become inactive (output 0) for all future inputs if gradients are too large.\nLeaky ReLU: \\(f(x) = (x &lt; 0) (x) + (x ) (x)\\)\n\nIntroduces a small positive slope \\(\\) for negative inputs (e.g., 0.01).\nAims to prevent dying ReLUs.\n\nMaxout: \\((w_1^Tx+b_1, w_2^Tx + b_2)\\)\n\nGeneralizes ReLU and its leaky version.\nNo saturation, no dying problem.\nDrawback: Doubles the number of parameters per neuron.\n\n\n\n\n\n\n\n\nWarning\n\n\nFor ReLU, monitor “dead” units. High learning rates can exacerbate the dying ReLU problem.\n\n\n\n\n\nReLU has become the most popular activation function in deep learning. Its simple form, max(0, x), offers significant advantages: it’s computationally very cheap and, crucially, it doesn’t suffer from saturation in the positive region, which greatly accelerates training compared to sigmoid or tanh.\nHowever, ReLU has its own Achilles’ heel: the “dying ReLU” problem. If a neuron’s weights are updated in such a way that its output is always negative for all training examples, the ReLU function will consistently output zero. This means its gradient will also be zero, and the neuron will stop learning completely—it essentially “dies.”\nTo address this, variants like Leaky ReLU introduce a small, non-zero slope for negative inputs, ensuring that there’s always a gradient flowing through the neuron, even if it’s small. Maxout further generalizes this, offering even better properties but at the cost of increasing the number of parameters, which can make models more prone to overfitting if not properly regularized.\nThe TLDR for activation functions: Start with ReLU. Be mindful of its potential pitfalls and consider Leaky ReLU or Maxout if you encounter issues like dying neurons or want to push performance further. Avoid sigmoid in hidden layers. Tanh is an option, but generally, ReLU-based activations are preferred."
  },
  {
    "objectID": "cs231n/neural-network-1.html#interactive-activation-functions",
    "href": "cs231n/neural-network-1.html#interactive-activation-functions",
    "title": "Machine Learning",
    "section": "Interactive Activation Functions",
    "text": "Interactive Activation Functions\nExplore how Sigmoid, Tanh, and ReLU functions respond to different input values. Adjust the Input X Value slider to see the corresponding output for each function.\n\nviewof x_input = Inputs.range([-5, 5], {value: 0, step: 0.1, label: \"Input X Value\"});\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis interactive plot allows you to visually compare the behavior of the three main activation functions: Sigmoid, Tanh, and ReLU. Observe how the output f(x) changes as you move the Input X Value slider.\n\nSigmoid (Blue): Notice how it flattens out (saturates) at extreme positive and negative values, leading to very small slopes. Its output is always between 0 and 1.\nTanh (Red): Similar to Sigmoid, it also saturates, but its output is centered around 0, ranging from -1 to 1.\nReLU (Green): For positive inputs, it behaves linearly, maintaining a constant slope (gradient of 1). For negative inputs, it’s strictly zero. This linear behavior in the positive region is why it helps accelerate training.\n\nPay close attention to the gradients (slopes) at different points. The flat regions for Sigmoid and Tanh demonstrate the “vanishing gradient” problem, which ReLU largely avoids in its positive region."
  },
  {
    "objectID": "cs231n/neural-network-1.html#neural-network-architectures",
    "href": "cs231n/neural-network-1.html#neural-network-architectures",
    "title": "Machine Learning",
    "section": "4. Neural Network Architectures",
    "text": "4. Neural Network Architectures\nLayer-wise Organization\nNeural Networks are collections of neurons connected in an acyclic graph. Most common organizations are into distinct layers.\n\n\nFully-Connected Layer:\n\nNeurons between adjacent layers are fully pairwise connected.\nNeurons within a single layer share no connections.\n\n\n\n\nTwo-layer Neural Network topology.\n\n\n\nExample - 3-Layer Network:\n\nThree inputs.\nTwo hidden layers, each with 4 neurons.\nOne output layer.\n\n\n\n\nThree-layer Neural Network topology.\n\n\n\n\nNeural networks are structured as layers of interconnected neurons. The key rule is that connections are acyclic, meaning there are no feedback loops that would cause infinite computation in a feedforward network.\nThe most common layer type in a basic neural network is the “fully-connected” layer. In such a layer, every neuron in one layer sends its output to every neuron in the next layer. However, crucially, neurons within the same layer do not connect to each other. This clear, layered structure makes computation highly efficient, primarily through matrix operations.\nThe images show classic examples: a 2-layer network with one hidden layer and an output layer, and a 3-layer network with two hidden layers. Notice how each layer builds upon the outputs of the previous one, creating a hierarchical representation of the data."
  },
  {
    "objectID": "cs231n/neural-network-1.html#neural-network-architecture-a-deeper-look",
    "href": "cs231n/neural-network-1.html#neural-network-architecture-a-deeper-look",
    "title": "Machine Learning",
    "section": "Neural Network Architecture: A Deeper Look",
    "text": "Neural Network Architecture: A Deeper Look\nLet’s visualize the connections in a 3-layer neural network with 3 inputs, two hidden layers of 4 neurons, and 1 output.\n\n\n\n\n\n\n\nG\n\n\ncluster_2\n\nHidden Layer 2\n\n\ncluster_1\n\nHidden Layer 1\n\n\ncluster_3\n\nOutput Layer\n\n\ncluster_0\n\nInput Layer\n\n\n\ninput_node\n\n\n\n x0 \n\n x1 \n\n x2 \n\n\n\nH1_0\n\nH1_0\n\n\n\ninput_node:x0-&gt;H1_0\n\n\n\n\n\ninput_node:x1-&gt;H1_0\n\n\n\n\n\ninput_node:x2-&gt;H1_0\n\n\n\n\n\nH1_1\n\nH1_1\n\n\n\ninput_node:x0-&gt;H1_1\n\n\n\n\n\ninput_node:x1-&gt;H1_1\n\n\n\n\n\ninput_node:x2-&gt;H1_1\n\n\n\n\n\nH1_2\n\nH1_2\n\n\n\ninput_node:x0-&gt;H1_2\n\n\n\n\n\ninput_node:x1-&gt;H1_2\n\n\n\n\n\ninput_node:x2-&gt;H1_2\n\n\n\n\n\nH1_3\n\nH1_3\n\n\n\ninput_node:x0-&gt;H1_3\n\n\n\n\n\ninput_node:x1-&gt;H1_3\n\n\n\n\n\ninput_node:x2-&gt;H1_3\n\n\n\n\n\nH2_0\n\nH2_0\n\n\n\nH1_0-&gt;H2_0\n\n\n\n\n\nH2_1\n\nH2_1\n\n\n\nH1_0-&gt;H2_1\n\n\n\n\n\nH2_2\n\nH2_2\n\n\n\nH1_0-&gt;H2_2\n\n\n\n\n\nH2_3\n\nH2_3\n\n\n\nH1_0-&gt;H2_3\n\n\n\n\n\nH1_1-&gt;H2_0\n\n\n\n\n\nH1_1-&gt;H2_1\n\n\n\n\n\nH1_1-&gt;H2_2\n\n\n\n\n\nH1_1-&gt;H2_3\n\n\n\n\n\nH1_2-&gt;H2_0\n\n\n\n\n\nH1_2-&gt;H2_1\n\n\n\n\n\nH1_2-&gt;H2_2\n\n\n\n\n\nH1_2-&gt;H2_3\n\n\n\n\n\nH1_3-&gt;H2_0\n\n\n\n\n\nH1_3-&gt;H2_1\n\n\n\n\n\nH1_3-&gt;H2_2\n\n\n\n\n\nH1_3-&gt;H2_3\n\n\n\n\n\nO0\n\nO0\n\n\n\nH2_0-&gt;O0\n\n\n\n\n\nH2_1-&gt;O0\n\n\n\n\n\nH2_2-&gt;O0\n\n\n\n\n\nH2_3-&gt;O0\n\n\n\n\n\n\n\n\n\n\n\nThis Graphviz diagram provides a more explicit visualization of the connections within a 3-layer fully-connected neural network. You can clearly see the distinct input, hidden (two layers), and output layers.\nEach input x0, x1, x2 connected to all neurons in the first hidden layer. Similarly, all neurons in Hidden Layer 1 connect to all neurons in Hidden Layer 2, and all neurons in Hidden Layer 2 connect to the single output neuron. This “all-to-all” connectivity between layers defines a fully-connected architecture. Notice the absence of connections within any given layer, confirming the layered structure. This diagram helps solidify the concept of how information flows through the network."
  },
  {
    "objectID": "cs231n/neural-network-1.html#naming-conventions-sizing-neural-networks",
    "href": "cs231n/neural-network-1.html#naming-conventions-sizing-neural-networks",
    "title": "Machine Learning",
    "section": "Naming Conventions & Sizing Neural Networks",
    "text": "Naming Conventions & Sizing Neural Networks\n\nN-layer network: Number of hidden layers + output layer (input layer is not usually counted).\n\nSingle-layer network: No hidden layers (e.g., Logistic Regression).\nArtificial Neural Networks (ANN) or Multi-Layer Perceptrons (MLP) are common synonyms.\n“Units” is a more general term than “neurons”.\n\nOutput Layer: Typically has no activation function (or linear identity) for class scores or regression targets.\n\n\n\nSizing Metrics:\n\nNumber of neurons (excluding input).\nNumber of parameters (weights + biases) - more common.\n\nExample 1 (2-layer NN):\n\n4 hidden, 2 output neurons.\nWeights: \\([3 ] + [4 ] = 12 + 8 = 20\\)\nBiases: \\(4 + 2 = 6\\)\nTotal Parameters: \\(20 + 6 = 26\\)\n\n\nExample 2 (3-layer NN):\n\n4 hidden (H1), 4 hidden (H2), 1 output neuron.\nWeights: \\([3 ] + [4 ] + [4 ] = 12 + 16 + 4 = 32\\)\nBiases: \\(4 + 4 + 1 = 9\\)\nTotal Parameters: \\(32 + 9 = 41\\)\n\n\n\n\n\n\n\nTip\n\n\nModern Convolutional Networks can have 10-20 layers and &gt;100 million parameters (“deep learning”).\n\n\n\n\n\nUnderstanding how to talk about and size neural networks is fundamental. When we refer to an “N-layer neural network,” N typically refers to the number of hidden layers plus the output layer, excluding the input layer. So, a network with just an input and output layer (like logistic regression) is often called a one-layer network.\nThe most practical way to measure a network’s size is by its total number of learnable parameters, which include all the weights and biases. I’ve broken down the calculation for the two example networks from previous slides. This kind of calculation is crucial for estimating computational requirements and potential for overfitting.\nNotice that modern deep learning models, especially Convolutional Neural Networks, can be orders of magnitude larger, with many more layers and parameters. This massive scale is what truly enables them to learn incredibly complex patterns, but also necessitates advanced optimization and regularization techniques."
  },
  {
    "objectID": "cs231n/neural-network-1.html#example-feed-forward-computation",
    "href": "cs231n/neural-network-1.html#example-feed-forward-computation",
    "title": "Machine Learning",
    "section": "Example: Feed-Forward Computation",
    "text": "Example: Feed-Forward Computation\nThe layered structure allows for efficient computation using matrix vector operations.\nConsider a 3-layer network:\n\nInput \\(x\\): [3x1] vector.\nFirst hidden layer weights \\(W_1\\): [4x3] matrix, biases \\(b_1\\): [4x1] vector.\nSecond hidden layer weights \\(W_2\\): [4x4] matrix, biases \\(b_2\\): [4x1] vector.\nOutput layer weights \\(W_3\\): [1x4] matrix, biases \\(b_3\\): [1x1] vector.\n\nThe full forward pass:\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\nThe forward pass of a fully-connected layer corresponds to one matrix multiplication followed by a bias offset and an activation function.\n\n\n\n\nThis slide demonstrates the core computational process of a neural network: the forward pass. Thanks to its layered and fully-connected structure, this process can be highly optimized using linear algebra operations, specifically matrix multiplications.\nThe Python code snippet shows precisely how this works. Each layer’s computation involves np.dot(W, input_from_prev_layer) for the weighted sum, + b for the bias, and then applying the non-linear activation function f. This is repeated for each layer until the final output is produced.\nA crucial point for efficiency is that the input x can also be an entire batch of training data (where each example is a column in a matrix). This allows for parallel computation across multiple examples, a technique known as mini-batching, which is fundamental to modern deep learning training. Also, remember the last layer often doesn’t have an activation if it’s producing raw scores or regression values."
  },
  {
    "objectID": "cs231n/neural-network-1.html#representational-power-universal-approximators",
    "href": "cs231n/neural-network-1.html#representational-power-universal-approximators",
    "title": "Machine Learning",
    "section": "Representational Power: Universal Approximators",
    "text": "Representational Power: Universal Approximators\n\n\nAre there functions a Neural Network cannot model?\n\nUniversal Approximation Theorem:\n\nA Neural Network with one hidden layer (and a reasonable non-linearity, e.g., sigmoid) can approximate any continuous function to an arbitrary degree of accuracy.\n\\( f(x), &gt; 0 g(x) f(x) - g(x) &lt; \\)\n\n\n\n\n\n\n\n\nNote\n\n\nMathematically, a single hidden layer is sufficient, but this doesn’t tell us about practical learning or performance.\n\n\n\n\nWhy go deeper then?\n\nThe “universal approximator” statement is theoretically comforting but practically weak.\nDeeper networks (multiple hidden layers) often perform empirically better.\nThey learn more compact, hierarchical, and abstract representations.\nEspecially true for data with inherent hierarchical structure (e.g., images: edges \\(\\rightarrow\\) textures \\(\\rightarrow\\) objects).\n\nCybenko (1989) and Michael Nielsen’s intuitive explanation details this.\n\n\nThe “Universal Approximation Theorem” is a powerful theoretical result that states, in essence, that a neural network with just one hidden layer is capable of approximating any continuous function to any desired degree of accuracy, provided it has enough neurons. This is a profound statement about the expressive power of neural networks.\nHowever, theory often diverges from practice. While a single hidden layer can theoretically approximate any function, the number of neurons required might be astronomically large, making it impractical to train. Furthermore, deep networks (with multiple hidden layers) have been empirically shown to perform significantly better on many complex tasks.\nWhy? Deeper networks are hypothesized to learn more hierarchical and abstract representations of the data. For instance, in image recognition, a first layer might detect simple edges, a second might combine edges into textures, a third might combine textures into parts of objects, and so on. This hierarchical learning is more aligned with how meaningful features are structured in much of the real-world data we encounter, making deep networks not just theoretically capable, but practically powerful and efficient to learn."
  },
  {
    "objectID": "cs231n/neural-network-1.html#setting-number-of-layers-and-their-sizes",
    "href": "cs231n/neural-network-1.html#setting-number-of-layers-and-their-sizes",
    "title": "Machine Learning",
    "section": "Setting Number of Layers and Their Sizes",
    "text": "Setting Number of Layers and Their Sizes\nNetwork Capacity: The ability of a model to approximate complex functions. Increases with more layers and neurons.\n\n\n\nLarger NNs can represent more complicated functions. Circles are data points, colors are classes, decision regions by trained NNs. (ConvNetsJS demo)\n\n\n\nOverfitting: When a high-capacity model learns noise in training data instead of underlying patterns.\n\nLeft: 1 hidden neuron - too low capacity, underfits.\nMiddle: 3 hidden neurons - good balance.\nRight: 20 hidden neurons - very high capacity, potentially overfits by creating complex, disjoint decision regions.\n\n\n\nWhen designing a neural network, a core decision is its architecture: how many layers and how many neurons per layer. This directly impacts the network’s “capacity” – its ability to learn and represent complex functions.\nThe image vividly demonstrates this. A network with too few neurons (1 hidden neuron) has low capacity, and can’t even separate the two classes effectively, leading to underfitting. Conversely, a network with many neurons (20 hidden neurons) has very high capacity. While it can perfectly fit all training data, including noise (like the red points within the green cluster), this can lead to overfitting. The highly complex, jagged decision boundary on the right is a hallmark of overfitting; it may perform poorly on unseen data because it learned the peculiarities of the training set rather than the generalizable patterns. The goal is to find a balance, like the network with 3 hidden neurons, which provides a smoother, more generalizable decision boundary."
  },
  {
    "objectID": "cs231n/neural-network-1.html#controlling-overfitting-prioritizing-regularization",
    "href": "cs231n/neural-network-1.html#controlling-overfitting-prioritizing-regularization",
    "title": "Machine Learning",
    "section": "Controlling Overfitting: Prioritizing Regularization",
    "text": "Controlling Overfitting: Prioritizing Regularization\n\n\nCounterintuitive Advice:\n\nDon’t use smaller networks to prevent overfitting.\nSmaller networks are harder to train effectively with gradient descent; they often converge to “bad” local minima.\nLarger networks have many more local minima, but these tend to be better in terms of actual loss.\n\n\n\n\n\n\n\nNote\n\n\nAlways use as big of a neural network as your computational budget allows!\n\n\n\n\nPreferred Strategy:\n\nUse a large network to ensure high capacity.\nControl overfitting with robust regularization techniques.\n\n\n\n\nEffects of regularization strength (20 hidden neurons each). Stronger regularization yields smoother decision regions. (ConvNetsJS demo)\n\n\n\n\nThis slide presents a crucial, often counterintuitive, piece of advice in neural network design. While small networks seem appealing to prevent overfitting, they are actually harder to train well. Their loss landscapes can be problematic, leading optimizers to get stuck in poor local minima, resulting in suboptimal performance.\nLarger networks, despite their higher capacity, offer a more advantageous training landscape. While they have more local minima, these minima tend to yield much better actual loss values. This means a large network, if properly managed, is more likely to converge to a good solution.\nTherefore, the recommended strategy is to “go big” with your network architecture (within computational limits) and then actively manage overfitting using regularization techniques. The image on the right illustrates how regularization, like increasing L2 weight decay, can smooth out the decision boundaries even for a large network, making it more generalizable to new data. We will explore various regularization methods like L2 regularization and dropout in detail in later modules."
  },
  {
    "objectID": "cs231n/neural-network-1.html#summary",
    "href": "cs231n/neural-network-1.html#summary",
    "title": "Machine Learning",
    "section": "Summary",
    "text": "Summary\n\nIntroduced a coarse model of a biological neuron and its computational counterpart.\nExplored various activation functions (Sigmoid, Tanh, ReLU, Leaky ReLU, Maxout), with ReLU being the most common choice today.\nDefined Neural Networks with Fully-Connected layers, characterized by pairwise connections between adjacent layers.\nUnderstood how this layered architecture allows for efficient feed-forward computation via matrix multiplications.\nDiscussed that Neural Networks are universal function approximators, and why deep layers are still empirically preferred in practice.\nEmphasized using large networks and controlling overfitting with strong regularization rather than limiting network size."
  },
  {
    "objectID": "cs231n/neural-network-1.html#additional-references",
    "href": "cs231n/neural-network-1.html#additional-references",
    "title": "Machine Learning",
    "section": "Additional References",
    "text": "Additional References\n\ndeeplearning.net tutorial with Theano\nConvNetJS demos for intuitions\nMichael Nielsen’s tutorials"
  },
  {
    "objectID": "cs231n/neural-network-3.html#sources",
    "href": "cs231n/neural-network-3.html#sources",
    "title": "Machine Learning",
    "section": "Sources",
    "text": "Sources\nStanford University CS231n: Deep Learning for Computer Vision\nCS231n Deep Learning for Computer Vision"
  },
  {
    "objectID": "cs231n/neural-network-3.html#table-of-contents",
    "href": "cs231n/neural-network-3.html#table-of-contents",
    "title": "Machine Learning",
    "section": "Table of Contents",
    "text": "Table of Contents\n\nQuick Intro: Linear vs NN\nModeling One Neuron\n\nBiological Motivation\nSingle Neuron as Linear Classifier\nActivation Functions\n\nNeural Network Architectures\n\nLayer-wise Organization\nFeed-Forward Computation\nRepresentational Power\nSetting Layers & Sizes\n\nSummary P1"
  },
  {
    "objectID": "cs231n/neural-network-3.html#table-of-contents-part-2",
    "href": "cs231n/neural-network-3.html#table-of-contents-part-2",
    "title": "Machine Learning",
    "section": "Table of Contents (Part 2)",
    "text": "Table of Contents (Part 2)\n\nSetting up the Data and Model\n\nData Preprocessing\nWeight Initialization\nBatch Normalization\nRegularization\n\nLoss Functions\nSummary P2"
  },
  {
    "objectID": "cs231n/neural-network-3.html#table-of-contents-continued",
    "href": "cs231n/neural-network-3.html#table-of-contents-continued",
    "title": "Machine Learning",
    "section": "Table of Contents (Continued)",
    "text": "Table of Contents (Continued)\n\nLearning Process\n\nGradient Checks\nSanity Checks\nBabysitting the Learning Process\n\nParameter Updates\n\nFirst-Order Methods\nLearning Rate Annealing\nAdaptive Learning Rates\n\nHyperparameter Optimization\nEvaluation: Model Ensembles\nSummary P3\nAdditional References"
  },
  {
    "objectID": "cs231n/neural-network-3.html#the-learning-process",
    "href": "cs231n/neural-network-3.html#the-learning-process",
    "title": "Machine Learning",
    "section": "8. The Learning Process",
    "text": "8. The Learning Process\nWe’ve covered the static aspects: network architecture, data setup, and loss functions. Now, we dive into the dynamics: the process of learning the parameters and fine-tuning hyperparameters.\nThis section covers:\n\nGradient Checks: Verifying the correctness of backpropagation.\nSanity Checks: Quick tests before expensive training.\nBabysitting: Monitoring training progress for insights.\n\n\n\n\n\n\n\nNote\n\n\nThe learning process is an iterative optimization endeavor, where parameters are adjusted to minimize the loss function."
  },
  {
    "objectID": "cs231n/neural-network-3.html#gradient-checks-verifying-backpropagation",
    "href": "cs231n/neural-network-3.html#gradient-checks-verifying-backpropagation",
    "title": "Machine Learning",
    "section": "8.1 Gradient Checks: Verifying Backpropagation",
    "text": "8.1 Gradient Checks: Verifying Backpropagation\nEnsuring your analytically derived gradients match numerical approximations.\nCentered Difference Formula\n\nBad (Do not use): \\( = O(h) \\)\nGood (Use instead): \\( = O(h^2) \\)\n\nMore accurate, worth the 2x computational cost.\n\n\nRelative Error for Comparison\n\nCompare numerical gradient (\\(f’_n\\)) and analytic gradient (\\(f’_a\\)) using: \\[ \\frac{\\mid f'_a - f'_n \\mid}{\\max(\\mid f'_a \\mid, \\mid f'_n \\mid)} \\]\nInterpretation:\n\n&gt; 1e-2: Probably wrong.\n1e-2 to 1e-4: Uncomfortable, often indicates a mistake.\n1e-4 to 1e-7: Acceptable, especially with “kinks” or deep networks.\n&lt; 1e-7: Excellent!\n\n\n\nGradient checking is a critical debugging step for neural networks. It verifies that your manually implemented backpropagation algorithm (analytic gradient calculation) is indeed correct by comparing its output to a numerical approximation of the gradient.\nThe centered difference formula is preferred for its significantly higher accuracy. While it requires two evaluations of the loss function instead of one per parameter, its Taylor series expansion reveals an error on the order of h^2, which is much better than the O(h) error of the simpler forward difference formula.\nFor comparing the gradients, direct absolute difference is unreliable. The relative error metric provides a robust way to determine similarity, as it accounts for the magnitude of the gradients themselves. I’ve provided practical thresholds for interpreting the relative error. Remember that for deeper networks, errors can accumulate, so a slightly higher threshold might be acceptable for earlier layers."
  },
  {
    "objectID": "cs231n/neural-network-3.html#gradient-check-practical-considerations",
    "href": "cs231n/neural-network-3.html#gradient-check-practical-considerations",
    "title": "Machine Learning",
    "section": "Gradient Check: Practical Considerations",
    "text": "Gradient Check: Practical Considerations\n\nUse double precision: Often reduces relative error significantly (e.g., from 1e-2 to 1e-8).\nActive range of floating point: Ensure gradients are not extremely small (e.g., ~1e-10). Temporarily scale loss if needed.\nKinks in the objective: Non-differentiable points (e.g., ReLU, SVM loss) can cause discrepancies.\n\nIf \\((f(x+h)\\) and \\(f(x-h))\\) cross a kink (e.g., a ReLU switches from 0 to positive), the numerical gradient will be inaccurate.\n\nUse few data points: Reduces the chance of hitting kinks in loss functions with many elements (e.g., SVM). Faster checks too.\n\nCheck with ~2-3 datapoints for robust results.\n\nCareful with step size h: Not always smaller is better. Too small can lead to numerical precision issues. Try 1e-4 or 1e-6.\n“Characteristic” mode: Perform gradcheck after a short “burn-in” training period. Random initialization might hit pathological edge cases.\nRegularization: Turn off regularization when checking data loss, then check regularization loss independently.\n\nReg loss has simpler gradients; an issue in data loss might be masked.\n\nTurn off non-determinism: Disable dropout, random data augmentations during gradcheck.\nCheck few dimensions: For large parameter vectors, sample dimensions but ensure even coverage across all parameter types (weights, biases for each layer).\n\n\nGradient checking is a powerful tool, but it comes with several caveats. These practical considerations are crucial for successfully debugging your backpropagation implementation:\n\nDouble Precision: Floating point arithmetic subtly affects numerical stability. Using float64 (double precision) provides higher accuracy and can noticeably improve your relative error values.\nFloating-Point Range: Gradients that are extremely small (e.g., 1e-10) can also suffer from precision issues. Temporarily scaling your loss to bring gradients into a more “dense” floating-point range (around 1.0) can help.\nKinks: Functions like ReLU are not differentiable everywhere. If your x+h and x-h evaluations straddle one of these “kinks,” your numerical approximation will be incorrect. Checking with a small number of data points typically mitigates this by reducing the number of kinks.\nStep Size h: There’s an optimal h. Too small, and you hit floating-point precision limits. Too large, and your approximation is poor. Experiment.\n“Characteristic” Mode: Don’t gradcheck at iteration 0 with random weights. Train for a few iterations until the loss starts decreasing, then check. This avoids edge cases of initial randomness that might mask errors.\nRegularization: Check your data loss gradient first with regularization strength set to zero. Then, separately, check the regularization gradient. The simple nature of regularization gradients can mask complex data loss bugs.\nNon-Determinism: Features like Dropout or random data augmentation introduce randomness. Disable them during gradient checks, or ensure you fix the random seed for both f(x+h) and f(x-h) evaluations, as well as for the analytic gradient.\nDimensionality: For networks with millions of parameters, you can’t check every single one. Sample a few, but ensure you test parameters from all parts of your network (e.g., biases, different layers’ weights)."
  },
  {
    "objectID": "cs231n/neural-network-3.html#interactive-gradient-check-example",
    "href": "cs231n/neural-network-3.html#interactive-gradient-check-example",
    "title": "Machine Learning",
    "section": "Interactive Gradient Check Example",
    "text": "Interactive Gradient Check Example\nCompare analytic vs. numerical gradient for \\(f(x) = x^2\\) or \\(f(x) = (0, x)\\). Adjust x_value and h_step_size to see their impact on accuracy.\n\nviewof x_value = Inputs.range([-5, 5], {value: 1.0, step: 0.1, label: \"Input x Value\"});\nviewof h_step_size = Inputs.range([1e-7, 1e-2], {value: 1e-5, step: 1e-7, label: \"h (Step Size)\"});\nviewof function_choice = Inputs.select([\"x_squared\", \"relu\"], {label: \"Function to check\"});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis interactive block demonstrates the gradient checking process for two simple functions: \\(f(x) = x^2\\) (always differentiable) and \\(f(x) = (0, x)\\) (ReLU, with a kink at 0).\n\nInput x Value: The point at which to compute the gradient.\nh (Step Size): The small perturbation used for the numerical approximation.\nFunction to check: Select between x_squared and relu.\n\nExperiment and Observe:\n\nFor x_squared: Change x_value and h_step_size. You should consistently get very small relative errors, demonstrating accurate gradient calculation for a smooth function.\nFor relu:\n\nTry x_value = 1.0 (positive region). The relative error should be small, as the ReLU is differentiable here.\nTry x_value = -1.0 (negative region). The relative error should also be small.\nNow, try x_value = 0.0 (the kink). You’ll likely see the relative error increase significantly. This is because f(x+h) (e.g., f(0+h) = h) and f(x-h) (e.g., f(0-h) = 0 if h positive) cause a discontinuity in the theoretical derivative, and the numerical approximation struggles. This illustrates the “kinks” problem in gradient checking.\nAlso, try playing with h_step_size: Notice how extremely small h can sometimes lead to higher relative errors due to floating-point precision limits.\n\n\nThis direct interaction helps to build intuition about the details and challenges of gradient checking in practice."
  },
  {
    "objectID": "cs231n/neural-network-3.html#sanity-checks-before-expensive-optimization",
    "href": "cs231n/neural-network-3.html#sanity-checks-before-expensive-optimization",
    "title": "Machine Learning",
    "section": "8.2 Sanity Checks: Before Expensive Optimization",
    "text": "8.2 Sanity Checks: Before Expensive Optimization\nRun these quick checks before full training to save time and identify fundamental issues.\n\nCheck for correct loss at chance performance.\n\nSet regularization to zero.\nWith small parameters, verify initial loss matches theoretical chance performance.\nExample (CIFAR-10):\n\nSoftmax (10 classes): Expected initial loss \\( - (0.1) \\).\nSVM (10 classes): Expected initial loss \\( 9 \\) (margin = 1 for 9 wrong classes).\n\nIf loss is far off, check data loading, labels, and initialization.\n\nIncreasing regularization strength should increase the loss.\n\nA simple test: introduce a large L2 regularization, and the total loss should go up. If not, regularization is incorrectly implemented or not applied.\n\nOverfit a tiny subset of data.\n\nSelect a very small portion of your training data (e.g., 5-20 examples).\nSet regularization to zero.\nTrain the network until it achieves zero cost (or near zero, e.g., 100% training accuracy).\nIf you can’t overfit a small dataset, your network (or code) has a fundamental bug. Do not proceed to full dataset training.\n\n\n\n\n\n\n\n\nCaution\n\n\nEven if you overfit a small dataset, ensure your features are not random due to a bug. Random features will overfit but generalize poorly on the full dataset.\n\n\n\n\nThese sanity checks are a lifeline. They are quick, cheap tests that can catch major errors in your model setup before you spend hours or days running expensive training jobs.\n\nChance Loss: This is a surprisingly effective check. If your loss doesn’t start at the expected random baseline, something is fundamentally wrong with how you’re computing loss, loading data, or initializing. For a 10-class problem, a random guess for the correct class is 10%, hence -log(0.1). For SVM, with tiny scores, all incorrect classes will violate the margin, leading to (num_classes - 1) * margin.\nRegularization Impact: This confirms that your regularization term is actually wired into your loss function and that its gradient is being correctly computed (though not as exhaustively as gradient check).\nOverfitting a Small Subset: This is the most crucial test. A correctly implemented neural network, even a complex one, should be able to perfectly memorize a tiny number of examples if given enough capacity. If it cannot, there is almost certainly a bug in your forward pass, backward pass, or optimizer. Only after passing this, should you expand to the full dataset and consider regularization.\n\nThe caution about random features is important: if your data pipeline is subtly broken and feeding random noise as input features, your model might still overfit a small set of that random noise, but it will never learn useful patterns from your real data."
  },
  {
    "objectID": "cs231n/neural-network-3.html#babysitting-the-learning-process",
    "href": "cs231n/neural-network-3.html#babysitting-the-learning-process",
    "title": "Machine Learning",
    "section": "8.3 Babysitting the Learning Process",
    "text": "8.3 Babysitting the Learning Process\nMonitoring key metrics during training provides invaluable insights into hyperparameter tuning. All plots below typically have epochs on the x-axis.\nLoss Function Plot\n\nTrack loss on individual batches.\nWiggle: Related to batch size (smaller batches = more wiggle).\nShape:\n\nLow LR: Linear, slow decay.\nHigh LR: Exponential decay, then plateaus at higher loss (bouncing chaotically).\n\nConsider plotting in log domain to better visualize progress and compare models.\n\n\n \n\n&lt;b&gt;Left:&lt;/b&gt; Effect of different learning rates on loss. High LR plateaus faster at worse loss values due to chaotic bouncing.\n&lt;b&gt;Right:&lt;/b&gt; Typical loss function over time. Some noise suggests a small batch size.\n\n\n\n“Babysitting” the learning process refers to the continuous monitoring of various metrics during training. These plots are your primary diagnostic tools for understanding what your network is doing and how well it’s learning.\nThe loss function plot is typically the first thing you’ll look at.\n\nWiggle: The jaggedness or “wiggle” in the loss curve is directly related to the batch size. Smaller batches lead to noisier gradients and thus more variation in the loss per iteration. A perfectly smooth loss might indicate a very large batch size or a constant loss.\nShape and Learning Rate: This is critical.\n\nIf your learning rate is too low, the loss will decrease very slowly, often in a nearly linear fashion.\nIf your learning rate is too high, the loss might initially drop quickly but then start oscillating wildly or even increase. A very high learning rate can lead to the loss becoming NaN (Not a Number) because updates are too large and explode parameters. The provided cartoon (left image) clearly illustrates these behaviors.\n\nLogarithmic Scale: Plotting the loss on a logarithmic y-axis can reveal details of sustained improvement that are hard to see on a linear scale, especially when the loss has decreased by several orders of magnitude. It also makes comparing the decay rates of different models easier."
  },
  {
    "objectID": "cs231n/neural-network-3.html#interactive-learning-rate-loss-simulation",
    "href": "cs231n/neural-network-3.html#interactive-learning-rate-loss-simulation",
    "title": "Machine Learning",
    "section": "Interactive Learning Rate Loss Simulation",
    "text": "Interactive Learning Rate Loss Simulation\nObserve how different learning rates affect the simulated loss curve. Adjust the learning_rate to see its impact.\n\nviewof learning_rate = Inputs.range([0.0001, 0.1], {value: 0.01, step: 0.0001, label: \"Learning Rate\"});\nviewof noise_level = Inputs.range([0.0, 0.5], {value: 0.1, step: 0.01, label: \"Noise Level (Batch Size proxy)\"});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis interactive plot simulates the training loss over epochs under different learning rates and noise levels (as a proxy for batch size variability).\n\nLearning Rate: Adjust this slider to see how aggressively the loss decreases.\n\nToo Low: The loss will descend slowly and linearly.\nOptimal: The loss decreases relatively fast and smoothly towards a minimum.\nToo High: The loss might oscillate wildly, decrease erratically, or even increase, indicating that the optimization steps are too large and skipping over minima.\n\nNoise Level (Batch Size proxy): This simulates the noisiness of gradients from mini-batches.\n\nLow Noise: Smoother loss curve, typical of larger batch sizes or smoother gradients.\nHigh Noise: More “wiggle” in the loss, characteristic of smaller batch sizes where individual batch gradients vary more.\n\n\nExperimentation: * Start with a learning_rate around 0.01 and noise_level at 0.1. * Increase learning_rate significantly (e.g., 0.05 or higher). Observe the erratic behavior. * Reduce learning_rate significantly (e.g., 0.001). Notice the slow, linear progress. * Increase noise_level while keeping learning_rate moderate. See the increased “wiggle” in the curve.\nThis simulation gives a simplified, yet illustrative, understanding of how these hyperparameter choices manifest in the loss curve, guiding your practical tuning decisions."
  },
  {
    "objectID": "cs231n/neural-network-3.html#babysitting-trainval-accuracy",
    "href": "cs231n/neural-network-3.html#babysitting-trainval-accuracy",
    "title": "Machine Learning",
    "section": "8.3 Babysitting: Train/Val Accuracy",
    "text": "8.3 Babysitting: Train/Val Accuracy\nThe most direct indicator of model performance and overfitting.\n\n\n\nThe gap between training and validation accuracy indicates overfitting.\n&lt;b&gt;Blue (strong overfitting):&lt;/b&gt; Validation accuracy is significantly lower than training accuracy, and may even decrease after a certain point.\n&lt;b&gt;Green (good fit):&lt;/b&gt; Training and validation accuracy are close, with continuous improvement.\n\n\n\nGap between Training and Validation Accuracy:\n\nLarge Gap (Blue): Strong overfitting. Your model is memorizing the training data but not generalizing well.\n\nAction: Increase regularization (L2, dropout), or collect more data.\n\nSmall Gap (Green): Good fit. Model generalizes well.\nBoth Low: Model is underfitting (too simple, or not trained enough).\n\n\n\n\n\n\n\n\nImportant\n\n\nValidation accuracy is your true measure of how well your model will perform on unseen data.\n\n\n\n\nThe comparison between training and validation accuracy is arguably the most important set of plots for diagnosing model behavior. It tells you directly about generalization.\n\nOverfitting (Blue Curve): If your training accuracy is high but validation accuracy is much lower, especially if validation accuracy starts decreasing while training accuracy continues to rise, your model is heavily overfitting. It’s essentially memorizing the training set, including its noise, and failing to learn generalizable patterns. The indicated actions are: increase regularization to reduce the model’s capacity or its reliance on specific training examples, or get more diverse training data if possible.\nGood Fit (Green Curve): This is the ideal scenario. Both training and validation accuracies are high and continue to improve in tandem, with a small, consistent gap. This indicates the model is learning well and generalizing effectively.\nUnderfitting: If both training and validation accuracies are low, your model is likely underfitting. This mean’s its capacity might be too low (not enough layers/neurons), it hasn’t been trained long enough, or the learning rate is too low.\n\nAlways prioritize validation accuracy. It’s what truly matters for real-world application of your model."
  },
  {
    "objectID": "cs231n/neural-network-3.html#babysitting-weightsupdates-ratio-debugging",
    "href": "cs231n/neural-network-3.html#babysitting-weightsupdates-ratio-debugging",
    "title": "Machine Learning",
    "section": "8.3 Babysitting: Weights:Updates Ratio (DEBUGGING)",
    "text": "8.3 Babysitting: Weights:Updates Ratio (DEBUGGING)\nA diagnostic for the health of your updates, especially for debugging.\n\nA good heuristic: The ratio of the magnitude of weight updates to the magnitude of the weights should be around 1e-3.\n\nFor a layer W, calculate std(dW) / std(W).\nIf std(dW) / std(W) is too low (e.g., 1e-6), updates are too small; the network learns slowly. Adjust learning rate up.\nIf std(dW) / std(W) is too high (e.g., 1e-1), updates are too large; parameters are jumping chaotically. Adjust learning rate down.\n\n\nActivation/Gradient Distributions per Layer (DEBUGGING)\n\nFor each layer, plot histograms of activations, weights, and gradients.\nGoal: Maintain healthy distributions (e.g., not all zero, not all saturated).\nProblem: If activations/gradients consistently go to zero or become saturated (e.g., \\(\\) for Tanh), it indicates vanishing/exploding gradient problems.\n\nThis is where Batch Normalization shines, by actively normalizing these distributions.\n\n\n\nThese are more advanced debugging metrics, especially useful when your network isn’t learning well and the loss/accuracy plots aren’t providing enough insight.\n\nWeights:Updates Ratio: This ratio gives you a direct sense of how much your weights are changing relative to their current values. If the changes are too small (e.g., 1e-6), your learning rate is likely too low, or you’re encountering vanishing gradients. If they’re too large (e.g., 1e-1), your learning rate is too high, and your optimizer is likely overshooting or oscillating. The 1e-3 rule of thumb is a good starting point, indicating a healthy rate of change.\nActivation/Gradient Distributions: Visualizing these distributions (e.g., using histograms) for each layer can reveal problems like vanishing or exploding activations/gradients.\n\nIf activations are all clustered around zero, or heavily saturated at the extremes of an activation function (like 0 or 1 for sigmoid, or -1 and 1 for tanh), information flow is hindered.\nSimilarly, if gradients are all zero, upstream layers aren’t getting learning signals. If they’re exploding, updates become unstable. This is precisely the problem that Batch Normalization was designed to address, by maintaining well-behaved (unit Gaussian-like) activation distributions throughout the network, leading to much more stable gradients."
  },
  {
    "objectID": "cs231n/neural-network-3.html#babysitting-visualization",
    "href": "cs231n/neural-network-3.html#babysitting-visualization",
    "title": "Machine Learning",
    "section": "8.3 Babysitting: Visualization",
    "text": "8.3 Babysitting: Visualization\nVisualizing network internal states or learned features.\n\nFirst Layer Weights:\n\nFor CNNs, visualize the weights of the first convolutional layer directly.\nEach filter (weight vector) often resembles learned features like edges, blobs, or color gradients.\n\nActivations:\n\nFor CNNs, plot activations of different filters for a given input image.\nHelps understand what features different parts of the network activate on.\n\nDimensionality Reduction:\n\nUse PCA or t-SNE (t-Distributed Stochastic Neighbor Embedding) to reduce high-dimensional feature vectors (from deeper layers) to 2D/3D.\nPlot these to see if classes cluster well in the feature space.\n\n\n\n\n\n\n\n\nTip\n\n\nVisualization is more art than science; use it to build intuition rather than for concrete debugging.\n\n\n\n\nVisualization is an art form in deep learning, offering qualitative insights into what your network has learned. It’s less about precise debugging and more about building intuition.\n\nFirst-layer weights: Especially in convolutional neural networks, the filters in the first layer often learn interpretable patterns such as edges, textures, or color blobs. Visualizing them can confirm that your network is picking up meaningful low-level features.\nActivations: Looking at the output of different filters throughout the network for a specific input image can show you which parts of the image activate particular neurons. This helps understand the feature hierarchy.\nDimensionality Reduction: Tools like PCA or t-SNE can project the high-dimensional feature vectors from deeper layers into a 2D or 3D space. Plotting these reduced features can reveal if data points belonging to the same class are clustering together, which indicates good feature learning.\n\nWhile not direct debugging tools, these visualizations are invaluable for developing an intuitive understanding of your network’s internal representations and capabilities."
  },
  {
    "objectID": "cs231n/neural-network-3.html#parameter-updates-optimization-algorithms",
    "href": "cs231n/neural-network-3.html#parameter-updates-optimization-algorithms",
    "title": "Machine Learning",
    "section": "9. Parameter Updates (Optimization Algorithms)",
    "text": "9. Parameter Updates (Optimization Algorithms)\nOnce gradients are computed, how do we update the weights?\n9.1 First-Order Methods\n\nStochastic Gradient Descent (SGD):\n\nUpdate rule: \\( W W - _W L \\)\n\\(\\) is the learning rate.\nTakes small steps in the direction opposite to the gradient.\nSuffers from oscillations and slow convergence in ravines.\n\nMomentum:\n\nIntroduces a “velocity” term to accelerate SGD in the right direction and damp oscillations.\nUpdate rule:\n\n\\( v v - _W L \\)\n\\( W W + v \\)\n\n\\(\\) is the momentum coefficient (e.g., 0.9, 0.99).\n\nNesterov Momentum (NAG - Nesterov Accelerated Gradient):\n\n“Look ahead” before making update.\nComputes gradient at a point slightly ahead in the direction of momentum.\nUpdate rule:\n\n\\( v v - _W L(W + v) \\)\n\\( W W + v \\)\n\nOften yields slightly better convergence than regular momentum.\n\n\n\nOptimization algorithms dictate how our network’s parameters are adjusted based on the gradients. First-order methods leverage only the first derivative (gradient) of the loss function.\n\nSGD: This is the baseline. It takes steps directly opposite to the calculated gradient. While effective, it can be slow, especially in “ravines” of the loss landscape, where it oscillates back and forth across the narrow dimension.\nMomentum: Inspired by physics, momentum introduces a “velocity” that accumulates gradients. Instead of only reacting to the current gradient, it also considers past gradients. This helps to overcome small local optima, smooth out oscillations, and accelerate convergence, especially through flatter regions or ravines. The momentum coefficient μ controls how much of the previous velocity is retained.\nNesterov Momentum: A refinement of momentum, Nesterov’s method is a “look-ahead” optimizer. It first makes a jump in the direction of the accumulated momentum, then calculates the gradient at this “looked-ahead” position, and finally applies the update. This allows it to correct its path more quickly and prevent overshooting, often resulting in slightly faster or more stable convergence.\n\nIn practice, momentum-based optimizers (SGD with momentum or Nesterov) are almost always preferred over plain SGD for deep learning."
  },
  {
    "objectID": "cs231n/neural-network-3.html#optimization-paths-visualized",
    "href": "cs231n/neural-network-3.html#optimization-paths-visualized",
    "title": "Machine Learning",
    "section": "Optimization Paths Visualized",
    "text": "Optimization Paths Visualized\n\n\n\n\n\ngraph LR\n    subgraph Initial State\n        P0((Start Point))\n    end\n\n    subgraph SGD Path\n        P0 --&gt; SGD1(SGD Step)\n        SGD1 --&gt; SGD2(SGD Step)\n        SGD2 --&gt; SGD_Oscillate[SGD learns slowly, oscillates]\n        style SGD_Oscillate fill:#fcc,stroke:#333,stroke-width:2px;\n    end\n\n    subgraph Momentum Path\n        P0 --&gt; M1(Momentum Step: Look at current gradient + accumulate velocity)\n        M1 --&gt; M2(Momentum Step)\n        M2 --&gt; M_Accelerate[Momentum accelerates through ravines]\n        style M_Accelerate fill:#cfc,stroke:#333,stroke-width:2px;\n    end\n\n    subgraph Nesterov Momentum Path\n        P0 --&gt; N1(Nesterov: Look ahead based on accumulated velocity)\n        N1 --&gt; N2(Nesterov: Compute gradient at 'look-ahead' point)\n        N2 --&gt; N3(Nesterov: Update based on 'look-ahead' gradient)\n        N3 --&gt; N_Converge[Nesterov converges faster, more direct]\n        style N_Converge fill:#cce,stroke:#333,stroke-width:2px;\n    end\n\n\n\n\n\n\n\nThis Mermaid diagram provides a conceptual visualization of how plain SGD, Momentum, and Nesterov Momentum navigate the optimization landscape from a starting point towards a minimum.\n\nSGD: Typically takes direct steps based on the local gradient. In narrow valleys or “ravines,” it tends to oscillate back and forth, making slow progress toward the minimum.\nMomentum: Introduces a “memory” of past gradients. It accumulates velocity, allowing it to accelerate more smoothly through flat regions and maintain direction through oscillations, thus dampening them and speeding up convergence.\nNesterov Momentum: Takes it a step further by being “aware” of where it’s going. It calculates the gradient not at the current position, but at the position it would be in after applying the current momentum. This “look-ahead” capability allows it to anticipate the curvature of the loss surface and make more informed, direct updates, often leading to faster convergence than classical momentum.\n\nWhile simplified, this diagram helps reinforce the intuitive understanding of these optimizers’ behaviors."
  },
  {
    "objectID": "cs231n/neural-network-3.html#annealing-the-learning-rate",
    "href": "cs231n/neural-network-3.html#annealing-the-learning-rate",
    "title": "Machine Learning",
    "section": "9.2 Annealing the Learning Rate",
    "text": "9.2 Annealing the Learning Rate\nGradually decreasing the learning rate over time.\n\nHigh learning rates initially help rapid progress, but can prevent fine-tuning near the minimum.\nLower learning rates allow for finer adjustments and better convergence.\n\nCommon Strategies:\n\nStep Decay:\n\nReduce learning rate by a fixed factor (e.g., 0.1) at specific epochs or after a fixed number of iterations.\nPros: Simple and widely used.\nCons: Requires careful tuning of decay rate and decay schedule.\n\nExponential Decay:\n\nReduce learning rate exponentially: \\( = _0 e^{-kt} \\)\n\\(_0\\): initial learning rate, \\(k\\): decay rate.\nPros: Smooth decay.\nCons: Can decay too quickly or too slowly for certain phases.\n\nCosine Decay:\n\nLearning rate follows a cosine curve, smoothly decreasing from a maximum to a minimum.\nPros: Modern, effective strategy, often seen in research. Empirically good for deep networks.\n\n\n\nLearning rate annealing, or scheduling, is a crucial technique. Initial large learning rates allow for rapid exploration of the loss landscape, escaping saddle points and quickly getting into a general region of a minimum. However, those large steps can prevent the optimizer from precisely converging to the exact minimum. As training progresses, we want to take smaller and smaller steps to “fine-tune” the parameters and settle into a good minimum.\nWe discussed three common strategies:\n\nStep Decay: The simplest. You train for some epochs, then drop the learning rate, then train more, drop again, etc. It’s like descending stairs. You need to pick when to drop and by how much.\nExponential Decay: A continuous, smooth decrease. The learning rate shrinks by a constant factor every iteration.\nCosine Decay: A more recent and often very effective schedule. The learning rate starts high, decreases following a cosine curve, and then increases slightly or stays low before the next cycle. It’s known for its good performance, often preventing the learning rate from getting stuck too low too early.\n\nThe choice of learning rate schedule is a hyperparameter that requires careful tuning, often with randomized search."
  },
  {
    "objectID": "cs231n/neural-network-3.html#interactive-learning-rate-schedule-visualization",
    "href": "cs231n/neural-network-3.html#interactive-learning-rate-schedule-visualization",
    "title": "Machine Learning",
    "section": "Interactive Learning Rate Schedule Visualization",
    "text": "Interactive Learning Rate Schedule Visualization\nVisualize how different learning rate annealing strategies change over time.\nAdjust parameters for each schedule to see their impact.\n\nviewof initial_lr = Inputs.range([0.001, 1.0], {value: 0.1, step: 0.001, label: \"Initial Learning Rate\"});\nviewof num_epochs_anneal = Inputs.range([50, 200], {value: 100, step: 10, label: \"Total Epochs\"});\n\nviewof decay_factor_step = Inputs.range([0.1, 0.9], {value: 0.5, step: 0.1, label: \"Step Decay Factor\"});\nviewof decay_epochs_step = Inputs.range([5, 50], {value: 20, step: 5, label: \"Step Decay Every N Epochs\"});\n\nviewof decay_rate_exp = Inputs.range([0.01, 0.1], {value: 0.05, step: 0.01, label: \"Exponential Decay Rate (k)\"});\n\nviewof min_lr_cosine = Inputs.range([0.0, 0.01], {value: 0.001, step: 0.001, label: \"Cosine Min LR\"});\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThis interactive plot helps you visualize how the learning rate changes over epochs for three common annealing strategies: Step Decay, Exponential Decay, and Cosine Decay.\n\nInitial Learning Rate: The starting learning rate for all schedules.\nTotal Epochs: The total duration of the training.\n\nFor Step Decay:\n\nDecay Factor: The multiplier for the learning rate (e.g., 0.5 halves it).\nDecay Every N Epochs: How often the learning rate is multiplied by the decay factor.\n\nObserve the “stair-step” pattern. Higher decay factors and shorter intervals lead to a faster drop.\n\n\nFor Exponential Decay:\n\nDecay Rate (k): Controls how quickly the learning rate drops off.\n\nNotice the smooth, continuous decline. A higher k value makes it drop faster.\n\n\nFor Cosine Decay:\n\nMin LR: The minimum learning rate reached during the cycle.\n\nObserve the sinusoidal curve, smoothly moving from initial LR down to Min LR and back (or just down depending on implementation). This smooth, non-linear progression is often very effective.\n\n\nExperimentation:\n\nAdjust the initial LR, then try different combinations of decay parameters for each schedule.\nPay attention to how quickly each method drops the learning rate to very low values. A premature drop can lead to the model getting stuck.\n\nUnderstanding these curves helps you choose and tune an appropriate learning rate schedule for your specific problem."
  },
  {
    "objectID": "cs231n/neural-network-3.html#adaptive-learning-rate-methods",
    "href": "cs231n/neural-network-3.html#adaptive-learning-rate-methods",
    "title": "Machine Learning",
    "section": "9.3 Adaptive Learning Rate Methods",
    "text": "9.3 Adaptive Learning Rate Methods\nGo beyond global learning rates with per-parameter adaptive adjustments.\n\nMotivation: Different parameters (and even dimensions of a single parameter) might benefit from different learning rates.\n\nParameters related to rare features benefit from larger updates.\nParameters related to common features benefit from smaller updates.\n\n\nAdagrad (Adaptive Gradient Algorithm)\n\nAccumulates squared gradients for each parameter.\nAdjusts learning rate inversely proportional to the square root of the sum of squared historical gradients.\nPros: Automatically adapts learning rates to feature frequency.\nCons: Accumulated squared gradients always increase, can lead to learning rate decaying too aggressively and prematurely stopping learning.\n\nRMSProp (Root Mean Square Propagation)\n\nAddresses Adagrad’s aggressive decay.\nUses a moving average of squared gradients instead of a simple sum.\nPros: More robust, better long-term performance than Adagrad.\n\nAdam (Adaptive Moment Estimation)\n\nCombines ideas from RMSProp and Momentum.\nKeeps an exponentially decaying average of past gradients (first moment) and past squared gradients (second moment).\nPros: Empirically very effective, widely used default optimizer.\nCons: Can sometimes generalize worse than SGD with momentum on certain tasks.\n\n\n\n\n\n\n\nImportant\n\n\nAdam is often the recommended default optimizer due to its strong empirical performance and ease of use (less hyperparameter tuning than SGD+Momentum).\n\n\n\n\nWhile SGD with momentum and learning rate schedules are powerful, they apply a single learning rate globally to all parameters. Adaptive learning rate methods take this a step further by tailoring the learning rate for each individual parameter based on its past gradients.\n\nAdagrad: This was one of the first popular adaptive methods. It makes updates smaller for parameters with frequent, large gradients (common features) and larger for parameters with rare, small gradients (rare features). Its main drawback is that the sum of squared gradients continuously grows, causing the learning rate to eventually become tiny and stop learning altogether.\nRMSProp: Developed to mitigate Adagrad’s aggressive decay. Instead of a simple sum, it uses an exponentially decaying moving average of squared gradients. This prevents the learning rate from monotonically decreasing too quickly, allowing the algorithm to continue learning.\nAdam: Currently the most popular adaptive optimizer. It combines the benefits of RMSProp (adaptive learning rates based on second moments) with the concept of momentum (using an exponentially decaying average of past gradients, the “first moment”). It also includes bias correction terms to account for the initialization of these moving averages. Adam generally performs very well across a wide range of tasks and is often the first optimizer to try.\n\nWhile adaptive optimizers like Adam are great for quick prototyping and often achieve good performance, sometimes a well-tuned SGD with momentum and an aggressive learning rate schedule can achieve even better generalization on specific, critical tasks. It’s a trade-off between ease of use and ultimate performance ceiling."
  },
  {
    "objectID": "cs231n/neural-network-3.html#hyperparameter-optimization",
    "href": "cs231n/neural-network-3.html#hyperparameter-optimization",
    "title": "Machine Learning",
    "section": "10. Hyperparameter Optimization",
    "text": "10. Hyperparameter Optimization\nSystematically finding the best set of hyperparameters for your model.\n1. Cross-Validation\n\nDivide training data into training and validation sets.\nHold-out validation is common: 70-90% for training, rest for validation.\nUse validation set to tune hyperparameters (never the test set!).\n\n2. Hyperparameter Search Strategies\n\nGrid Search: Try all combinations of hyperparameters from a predefined grid.\n\nPros: Exhaustive (if grid is dense enough).\nCons: Computationally expensive; easily misses optimal points if grid is coarse.\n\nRandom Search: Sample hyperparameter values randomly from predefined ranges.\n\nPros: More efficient than grid search for the same computational budget, often finds better models. Better at exploring disparate impactful hyperparameters.\nCons: Still heuristic; no guarantee of finding the global optimum.\n\nCoarse-to-Fine Search:\n\nPerform a random search over a wide range.\nIdentify promising regions.\nThen, perform another (random or grid) search within those narrower, promising regions.\n\nBayesian Optimization:\n\nUses a probabilistic model to predict which hyperparameters to try next, aiming to minimize the number of expensive evaluations.\nPros: Can be much more efficient for complex models and large search spaces.\n\n\n\n\n\n\n\n\nNote\n\n\nAlways tune hyperparameters on the validation set, and evaluate final performance only once on the test set.\n\n\n\n\nHyperparameter optimization is the process of selecting the best set of values for the parameters that control the learning process itself (e.g., learning rate, regularization strength, network architecture, etc.). It’s essentially “learning to learn.”\n\nCross-Validation: The foundation of reliable hyperparameter tuning. You split your data and use the validation set as a proxy for unseen data to evaluate different hyperparameter settings. Critically, the test set is reserved only for the final evaluation of the chosen best model to get an unbiased estimate of its true performance.\nSearch Strategies:\n\nGrid Search: Conceptually simple, but inefficient. If one hyperparameter has little impact and another has a huge impact, grid search wastes effort trying many combinations along the ineffective dimension.\nRandom Search: This was shown to be more effective than grid search for the same computational budget. By randomly sampling, it can more efficiently explore the hyperparameter space, especially when some hyperparameters are much more important than others and interactions are complex.\nCoarse-to-Fine: A pragmatic approach combining exploration and exploitation. Find rough promising areas, then refine the search.\nBayesian Optimization: A more sophisticated approach that builds a statistical model (a surrogate model) of the objective function (e.g., validation accuracy) with respect to the hyperparameters. It then uses this model to intelligently choose the next set of hyperparameters to evaluate, balancing exploration (trying new areas) and exploitation (refining known good areas). This is often implemented with libraries like Optuna, Hyperopt, or scikit-optimize."
  },
  {
    "objectID": "cs231n/neural-network-3.html#evaluation-model-ensembles",
    "href": "cs231n/neural-network-3.html#evaluation-model-ensembles",
    "title": "Machine Learning",
    "section": "11. Evaluation: Model Ensembles",
    "text": "11. Evaluation: Model Ensembles\nCombine multiple models to achieve superior performance.\n\nIntuition: Different models make different errors. Combining their predictions can cancel out individual model weaknesses and lead to a more robust, accurate overall prediction.\n\nCommon Ensemble Strategies:\n\nSame Model, Different Initializations:\n\nTrain multiple models with identical architecture and hyperparameters, but with different random initializations.\nAverage their predictions.\nPros: Simple, effective, especially for non-convex loss landscapes.\n\nTop Models from Cross-Validation:\n\nSelect the top few best-performing models from your hyperparameter search.\nCombine their predictions.\nPros: Leverages models that already performed well.\n\nDifferent Checkpoints of a Single Model:\n\nSave model weights at different epochs during a long training run.\nTreat each saved model as a separate ensemble member.\nPros: Very cheap, as only one training run is needed. Effective because a model at epoch 50 might be different from epoch 100.\n\nAveraging Parameters:\n\nInstead of averaging predictions, average the weights of multiple models.\nCan sometimes work well, but requires careful consideration as parameter spaces are non-linear.\n\n\nHow to Combine Predictions (Classification):\n\nAverage Softmax Probabilities: Simplest and most common.\nVote: Each model “votes” for its predicted class.\n\n\n\n\n\n\n\nTip\n\n\nEnsembles consistently deliver 1-2% (or more) performance boosts, often winning competitions. Always consider using an ensemble for production systems if latency/compute budget allows.\n\n\n\n\nModel ensembles are a powerful technique to squeeze out an extra performance boost from your models. The core idea is that if you have several models that are individually good but make different types of errors, then combining their predictions can lead to a more accurate and robust final decision.\nWe discussed several strategies for creating ensembles:\n\nDifferent Initializations: This is surprisingly effective. Because training neural networks involves optimizing a non-convex loss function, different random initializations will lead to different local minima, resulting in models with slightly different strengths and weaknesses. Averaging their predictions helps smooth out these individual biases.\nTop Models from Cross-Validation: If you have run extensive hyperparameter tuning, you likely have several good models. Instead of picking just one, ensemble the best ones.\nDifferent Checkpoints: This is a very cost-effective strategy. A model’s weights at epoch 50 might perform differently than at epoch 100 or epoch 150. Saving and ensembling these different snapshots can be thought of as getting several models for the cost of one training run.\nAveraging Parameters: While sometimes effective, averaging the parameters themselves is trickier because the parameter space is highly non-linear. This works better if the models being averaged are relatively close in parameter space and have similar functionalities.\n\nFor classification, the most common way to combine predictions is to average the Softmax probabilities (which can be interpreted as confidence scores). Alternatively, models can “vote” for a class. Ensembles are a staple in achieving top performance in many machine learning competitions and are often employed in critical production systems where reliability and peak accuracy are paramount."
  },
  {
    "objectID": "cs231n/neural-network-3.html#summary-part-3",
    "href": "cs231n/neural-network-3.html#summary-part-3",
    "title": "Machine Learning",
    "section": "12. Summary (Part 3)",
    "text": "12. Summary (Part 3)\n\nGradient Checks: Crucial for verifying backpropagation correctness. Use the centered formula and relative error. Be mindful of practical issues like kinks, precision, and non-determinism.\nSanity Checks: Essential quick tests before extensive training: check initial loss, regularization impact, and ability to overfit a small dataset.\nBabysitting Training: Monitoring loss and accuracy curves (training vs. validation) is key to diagnosing learning problems (underfitting, overfitting, bad learning rates). Debugging metrics like Weights:Updates ratio and activation/gradient distributions can provide deeper insights.\nParameter Updates (Optimizers):\n\nSGD with Momentum / Nesterov Momentum: Preferred over plain SGD; accelerate convergence.\nLearning Rate Annealing: Gradually decrease learning rate (step, exponential, cosine decay) for better convergence and fine-tuning.\nAdaptive Methods (Adagrad, RMSProp, Adam): Adjust learning rates per-parameter; Adam is a highly recommended default.\n\nHyperparameter Optimization: Use cross-validation with random search (often coarse-to-fine) to find optimal hyperparameters.\nModel Ensembles: Combining predictions from multiple models (different initializations, checkpoints) consistently improves performance and robustness."
  },
  {
    "objectID": "cs231n/neural-network-3.html#additional-references",
    "href": "cs231n/neural-network-3.html#additional-references",
    "title": "Machine Learning",
    "section": "13. Additional References",
    "text": "13. Additional References\n\ndeeplearning.net tutorial with Theano\nConvNetJS demos for intuitions\nMichael Nielsen’s tutorials\nWhat Every Computer Scientist Should Know About Floating-Point Arithmetic\nOptimization Algorithms (CS231n lecture notes)\nAn overview of gradient descent optimization algorithms by Sebastian Ruder\nBayesian Optimization for Hyperparameter Tuning\nRecommended papers on various topics from the lecture notes (e.g., Glorot, He, Srivastava et al., Ioffe and Szegedy)."
  }
]