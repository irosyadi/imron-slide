<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-587c61ba64f3a5504c4d52d930310e48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/quarto-contrib/live-runtime/live-runtime.js" type="module"></script>
<link href="../site_libs/quarto-contrib/live-runtime/live-runtime.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.26">

  <meta name="author" content="Imron Rosyadi">
  <title>Machine Learning</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-b0356e9119c1bdfd0db189d130feb51c.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script type="module" src="../site_libs/quarto-ojs/quarto-ojs-runtime.js"></script>
  <link href="../site_libs/quarto-ojs/quarto-ojs.css" rel="stylesheet">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Machine Learning</h1>
  <p class="subtitle">06 Others: Clustering, K-Means &amp; Embeddings</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Imron Rosyadi 
</div>
</div>
</div>

</section>
<section>
<section id="clustering-embeddings-in-ece-ml" class="title-slide slide level1 center">
<h1>Clustering &amp; Embeddings in ECE ML</h1>
<p><strong>Uncovering Structure &amp; Efficient Representations</strong></p>
<aside class="notes">
<p>Hello everyone and welcome to today’s lecture on Clustering and Embeddings. So far in this course, we’ve primarily dealt with supervised learning, where our models learn from labeled data to make predictions. Today, we’re shifting gears to explore techniques that help us uncover hidden structures in data and represent complex information more efficiently. These methods are crucial in many ECE applications, from signal processing to computer vision.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="what-is-clustering" class="slide level2">
<h2>What is Clustering?</h2>
<p>Clustering is an <strong>unsupervised machine learning</strong> task.</p>
<ul>
<li>It groups a set of objects such that objects in the same group are <strong>more similar</strong> to each other than to those in other groups.</li>
<li>Unlike classification, there are <strong>no predefined labels</strong> or target variables.</li>
<li>The goal is to discover intrinsic groupings within the data.</li>
</ul>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p><strong>Think of it like sorting items without being told what categories exist.</strong></p>
</div>
</div>
</div>
<aside class="notes">
<p>Let’s start with clustering. Simply put, clustering is about finding natural groupings in your data. It’s a cornerstone of unsupervised learning because, unlike regression or classification where we have labeled examples, here we don’t have a “correct” answer for each data point. The algorithm itself finds the patterns. This is incredibly useful when you have a lot of data but don’t know what to look for, or when labeling data is too expensive or impossible. Think about anomalies in sensor data, segmenting customers, or grouping similar images.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="supervised-vs.-unsupervised-learning" class="slide level2">
<h2>Supervised vs.&nbsp;Unsupervised Learning</h2>
<div class="columns">
<div class="column" style="width:48%;">
<h3 id="supervised-learning"><strong>Supervised Learning</strong></h3>
<ul>
<li><strong>Labeled Data:</strong> Each data point has a known output (e.g., house price, image label).</li>
<li><strong>Goal:</strong> Predict an output based on given inputs.</li>
<li><strong>Examples:</strong> Regression, Classification.</li>
<li><strong>Questions:</strong> <em>“Is this a cat or a dog?”</em>, <em>“What is the house price?”</em></li>
</ul>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p><strong>Analogous to learning with a teacher.</strong></p>
</div>
</div>
</div>
</div><div class="column" style="width:4%;">

</div><div class="column" style="width:48%;">
<h3 id="unsupervised-learning-clustering"><strong>Unsupervised Learning (Clustering)</strong></h3>
<ul>
<li><strong>Unlabeled Data:</strong> Data points have no predefined outputs.</li>
<li><strong>Goal:</strong> Discover patterns, structures, or groupings within the data.</li>
<li><strong>Examples:</strong> Clustering, Dimensionality Reduction.</li>
<li><strong>Questions:</strong> <em>“How can these animals be grouped?”</em>, <em>“What are the natural segments in this market?”</em></li>
</ul>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p><strong>Analogous to self-discovery or exploring on your own.</strong></p>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>To solidify our understanding, let’s explicitly compare supervised and unsupervised learning. In supervised learning, our dataset is like a textbook with answers – we have input ‘features’ and corresponding ‘labels’ or ‘targets’. The model learns the mapping from features to labels. In contrast, unsupervised learning is like getting a pile of raw materials and being asked to organize them. There are no given categories; the algorithm must find them. Clustering is a prime example of this, where similarity among data points guides the grouping process.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="hands-on-analogy-fastener-clustering" class="slide level2 scrollable">
<h2>Hands-On Analogy: Fastener Clustering</h2>

<img data-src="06_res/clustering01.jpg" class="r-stretch"><blockquote>
<p>Imagine a pile of assorted fasteners (screws, nuts, bolts, washers).</p>
</blockquote>
<ol type="1">
<li><strong>Task 1:</strong> Divide them into <strong>six</strong> distinct groups.</li>
<li><strong>Task 2:</strong> Now, divide them into <strong>four</strong> distinct groups.</li>
<li><strong>Task 3:</strong> Finally, divide them into just <strong>two</strong> distinct groups.</li>
</ol>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p><strong>What criteria did you use? How much did the grouping change with different numbers of groups?</strong></p>
</div>
</div>
</div>
<aside class="notes">
<p>Let’s make this tangible. Imagine you have a large assortment of fasteners – screws, nuts, bolts, and washers, of various sizes and materials. If I asked you to group them, you’d intuitively start looking for similarities. Perhaps by head type, size, material, or purpose.</p>
<p>This simple exercise perfectly illustrates the core idea behind clustering. You were implicitly deciding on a “distance metric” – what makes two fasteners similar or different – and then grouping them based on that. And importantly, you experienced how changing the target number of groups, typically denoted as ‘k’ in machine learning, significantly affects the way you perceive and form these clusters. Your choices minimized “differences” within each group, much like clustering algorithms do.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="k-means-the-most-common-algorithm" class="slide level2">
<h2>k-means: The Most Common Algorithm</h2>
<p>k-means is an iterative clustering algorithm that aims to partition <code>n</code> data points into <code>k</code> clusters.</p>
<p><strong>Core Idea:</strong> Minimize the <strong>within-cluster sum of squares (WCSS)</strong>. This means making each cluster as <strong>compact</strong> and <strong>homogeneous</strong> as possible.</p>
<p><span class="math display">\[
\arg \min_{S} \sum_{i=1}^{k} \sum_{x \in S_i} \| x - \mu_i \|^2
\]</span></p>
<ul>
<li><span class="math inline">\(S\)</span>: The set of all clusters <span class="math inline">\(\{S_1, S_2, \dots, S_k\}\)</span>.</li>
<li><span class="math inline">\(S_i\)</span>: All data points within cluster <code>i</code>.</li>
<li><span class="math inline">\(x\)</span>: A data point in cluster <code>i</code>.</li>
<li><span class="math inline">\(\mu_i\)</span>: The <strong>mean (centroid)</strong> of the data points in cluster <code>i</code>.</li>
</ul>
<aside class="notes">
<p>Among the many clustering algorithms, k-means stands out as the most widely used. Its popularity stems from its simplicity and efficiency. The “k” in k-means refers to the number of clusters you want to find. The algorithm determines the ‘mean’ or ‘centroid’ of each cluster.</p>
<p>Mathematically, k-means tries to minimize the sum of squared distances between each data point and the centroid of its assigned cluster. This objective function, called the Within-Cluster Sum of Squares or WCSS, effectively pushes the algorithm to create clusters where points within the same cluster are very close to each other.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="k-means-algorithm-step-by-step" class="slide level2">
<h2>k-means Algorithm: Step-by-Step</h2>
<div class="columns">
<div class="column" style="width:45%;">
<h3 id="initialization"><strong>1. Initialization</strong></h3>
<ul>
<li>Select <code>k</code> number of clusters.</li>
<li>Randomly generate <code>k</code> initial centroids.</li>
</ul>
<p><img data-src="06_res/kmeans03.png"></p>
</div><div class="column" style="width:5%;">

</div><div class="column" style="width:45%;">
<h3 id="assignment"><strong>2. Assignment</strong></h3>
<ul>
<li>Assign each data point to its closest centroid.</li>
</ul>
<p><img data-src="06_res/kmeans04.png"></p>
</div></div>
<aside class="notes">
<p>Let’s walk through the k-means algorithm step-by-step. It’s an iterative process.</p>
<p>First, you decide on <code>k</code>, the number of clusters. Then, the algorithm randomly places ‘k’ points, called centroids, in your data space. These are essentially initial guesses for the center of each cluster.</p>
<p>Next, every single data point in your dataset is assigned to the nearest centroid. “Nearest” is determined by a distance metric, usually Euclidean distance. This creates our initial set of ‘k’ clusters based on these random centroids.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="k-means-algorithm-iteration" class="slide level2">
<h2>k-means Algorithm: Iteration</h2>
<div class="columns">
<div class="column" style="width:45%;">
<h3 id="update"><strong>3. Update</strong></h3>
<ul>
<li>Recalculate new centroids as the mean of all points in each cluster.</li>
</ul>
<p><img data-src="06_res/kmeans05.png"></p>
</div><div class="column" style="width:5%;">

</div><div class="column" style="width:45%;">
<h3 id="reassignment"><strong>4. Reassignment</strong></h3>
<ul>
<li>Reassign data points to their <strong>newest</strong> closest centroids.</li>
</ul>
<p><img data-src="06_res/kmeans07.png"></p>
</div></div>
<aside class="notes">
<p>After the initial assignment, the algorithm refines the clusters. The third step involves updating the centroids. For each cluster, the new centroid is calculated as the average position (arithmetic mean) of all the data points currently assigned to that cluster. This moves the centroids towards the true ‘center of gravity’ of their respective clusters.</p>
<p>With the new centroid positions, all data points are then reassigned. Again, each point goes to the centroid it is now closest to. This might cause some points to switch clusters if a new centroid is closer than their previous one.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="k-means-algorithm-convergence" class="slide level2">
<h2>k-means Algorithm: Convergence</h2>
<div class="columns">
<div class="column" style="width:45%;">
<h3 id="repeat-converge"><strong>5. Repeat &amp; Converge</strong></h3>
<ul>
<li>Repeat steps 3 and 4 until:
<ul>
<li>Centroids no longer move significantly.</li>
<li>Cluster assignments no longer change.</li>
<li>A maximum number of iterations is reached.</li>
</ul></li>
</ul>
<p><img data-src="06_res/kmeans08.png"></p>
</div><div class="column" style="width:5%;">

</div><div class="column" style="width:45%;">
<h3 id="k-means-flowchart"><strong>K-means Flowchart</strong></h3>
<div class="cell" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<p><img data-src="06_00-03-others_files\figure-revealjs\mermaid-figure-1.png" style="width:3.89in;height:11.22in"></p>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
</div></div>
<aside class="notes">
<p>This process of updating centroids and reassigning points continues iteratively. The algorithm eventually converges when the centroids stop moving much between iterations or when the cluster assignments stabilize. At this point, the clusters and their centroids are considered optimally positioned according to the k-means objective. The flowchart on the right summarizes this iterative process, offering a clear visual guide to the algorithm’s flow.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="interactive-k-means-visualization" class="slide level2">
<h2>Interactive K-means Visualization</h2>
<p>Adjust the number of clusters (<code>k</code>) and see how the data points are grouped.</p>
<div class="columns">
<div class="column" style="width:45%;">
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code hidden" id="cb1" data-startfrom="243" data-source-offset="-0"><pre class="sourceCode numberSource js number-lines code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 242;"><span id="cb1-243"><a></a><span class="im">import</span> { slider } <span class="im">from</span> <span class="st">"@jashkenas/inputs"</span><span class="op">;</span></span>
<span id="cb1-244"><a></a>viewof k_clusters <span class="op">=</span> <span class="fu">slider</span>({</span>
<span id="cb1-245"><a></a>  <span class="dt">min</span><span class="op">:</span> <span class="dv">2</span><span class="op">,</span></span>
<span id="cb1-246"><a></a>  <span class="dt">max</span><span class="op">:</span> <span class="dv">10</span><span class="op">,</span></span>
<span id="cb1-247"><a></a>  <span class="dt">step</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span></span>
<span id="cb1-248"><a></a>  <span class="dt">value</span><span class="op">:</span> <span class="dv">4</span><span class="op">,</span></span>
<span id="cb1-249"><a></a>  <span class="dt">label</span><span class="op">:</span> <span class="st">"Number of Clusters (k)"</span></span>
<span id="cb1-250"><a></a>})<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-1" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-2" data-nodetype="declaration">

</div>
</div>
</div>
</div>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p>This visualization simulates the outcome of k-means clustering. Observe how varying <code>k</code> changes the resulting clusters.</p>
</div>
</div>
</div>
</div><div class="column" style="width:55%;">
<div>
<div id="pyodide-1" class="exercise-cell">

</div>
<script type="pyodide-1-contents">
eyJhdHRyIjp7ImVjaG8iOmZhbHNlLCJlZGl0IjpmYWxzZSwiZXZhbCI6dHJ1ZSwiaW5wdXQiOlsia19jbHVzdGVycyJdfSwiY29kZSI6ImltcG9ydCBwbG90bHkuZ3JhcGhfb2JqZWN0cyBhcyBnb1xuZnJvbSBza2xlYXJuLmRhdGFzZXRzIGltcG9ydCBtYWtlX2Jsb2JzXG5mcm9tIHNrbGVhcm4uY2x1c3RlciBpbXBvcnQgS01lYW5zXG5pbXBvcnQgbnVtcHkgYXMgbnBcblxuIyBHZW5lcmF0ZSBzeW50aGV0aWMgMkQgZGF0YVxuWCwgXyA9IG1ha2VfYmxvYnMobl9zYW1wbGVzPTMwMCwgY2VudGVycz01LCBjbHVzdGVyX3N0ZD0wLjgsIHJhbmRvbV9zdGF0ZT0xMjMpXG5cbiMgRmlsdGVyIG91dCBub24tbnVtZXJpYyB2YWx1ZXMgZm9yIGtfY2x1c3RlcnNcbmsgPSBpbnQoa19jbHVzdGVycykgaWYgaXNpbnN0YW5jZShrX2NsdXN0ZXJzLCAoaW50LCBmbG9hdCkpIGVsc2UgNFxuaWYgayA8IDI6IGsgPSAyICMgRW5zdXJlIGsgaXMgYXQgbGVhc3QgMlxuXG4jIEFwcGx5IEtNZWFuc1xua21lYW5zID0gS01lYW5zKG5fY2x1c3RlcnM9aywgcmFuZG9tX3N0YXRlPTEyMywgbl9pbml0PTEwKVxua21lYW5zLmZpdChYKVxubGFiZWxzID0ga21lYW5zLmxhYmVsc19cbmNlbnRyb2lkcyA9IGttZWFucy5jbHVzdGVyX2NlbnRlcnNfXG5cbiMgQ3JlYXRlIFBsb3RseSBmaWd1cmVcbmZpZyA9IGdvLkZpZ3VyZSgpXG5cbiMgQWRkIGEgdHJhY2UgZm9yIGVhY2ggY2x1c3RlclxuZm9yIGkgaW4gcmFuZ2Uoayk6XG4gICAgY2x1c3Rlcl9wb2ludHMgPSBYW2xhYmVscyA9PSBpXVxuICAgIGZpZy5hZGRfdHJhY2UoZ28uU2NhdHRlcihcbiAgICAgICAgeD1jbHVzdGVyX3BvaW50c1s6LCAwXSxcbiAgICAgICAgeT1jbHVzdGVyX3BvaW50c1s6LCAxXSxcbiAgICAgICAgbW9kZT0nbWFya2VycycsXG4gICAgICAgIG5hbWU9ZidDbHVzdGVyIHtpKzF9JyxcbiAgICAgICAgbWFya2VyPWRpY3Qoc2l6ZT04LCBvcGFjaXR5PTAuNylcbiAgICApKVxuXG4jIEFkZCBjZW50cm9pZHNcbmZpZy5hZGRfdHJhY2UoZ28uU2NhdHRlcihcbiAgICB4PWNlbnRyb2lkc1s6LCAwXSxcbiAgICB5PWNlbnRyb2lkc1s6LCAxXSxcbiAgICBtb2RlPSdtYXJrZXJzJyxcbiAgICBuYW1lPSdDZW50cm9pZHMnLFxuICAgIG1hcmtlcj1kaWN0KHN5bWJvbD0neCcsIHNpemU9MTIsIGNvbG9yPSdibGFjaycsIGxpbmU9ZGljdCh3aWR0aD0yKSlcbikpXG5cbmZpZy51cGRhdGVfbGF5b3V0KFxuICAgIHRpdGxlPWYnSy1NZWFucyBDbHVzdGVyaW5nIHdpdGggaz17a30nLFxuICAgIHhheGlzX3RpdGxlPSdGZWF0dXJlIDEnLFxuICAgIHlheGlzX3RpdGxlPSdGZWF0dXJlIDInLFxuICAgIHNob3dsZWdlbmQ9VHJ1ZSxcbiAgICB3aWR0aD03MDAsXG4gICAgaGVpZ2h0PTUwMCxcbiAgICBtYXJnaW49ZGljdChsPTAsIHI9MCwgYj0wLCB0PTMwKVxuKVxuZmlnIn0=
</script>
</div>
</div></div>
<aside class="notes">
<p>This interactive demo allows you to experiment with the crucial hyperparameter <code>k</code> – the number of clusters. On the left, you’ll find a slider to adjust <code>k</code>. As you change it, the Python code on the right will rerun k-means on a synthetic dataset and update the Plotly visualization. Pay attention to how the data points are grouped and how the centroids shift based on your <code>k</code> selection. This highlights the subjective nature of choosing <code>k</code> and how different <code>k</code> values can lead to different interpretations of the underlying data structure.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="other-clustering-algorithms" class="slide level2">
<h2>Other Clustering Algorithms</h2>
<p>K-means is just one of many! Here are a few others:</p>
<ul>
<li><strong>Affinity Propagation:</strong> Finds ‘exemplars’ which are representative samples of clusters.</li>
<li><strong>Mean-shift:</strong> Locates the centers of dense data regions in a continuous space.</li>
<li><strong>DBSCAN:</strong> Density-Based Spatial Clustering of Applications with Noise; identifies clusters based on density and can find arbitrarily shaped clusters.</li>
<li><strong>Gaussian Mixtures (GMM):</strong> Models data as a mixture of Gaussian distributions, providing probabilistic cluster assignments.</li>
<li><strong>Agglomerative Hierarchical Clustering:</strong> Builds a hierarchy of clusters, starting with individual points as clusters and merging them.</li>
</ul>
<aside class="notes">
<p>While k-means is popular, it’s essential to know that a rich landscape of clustering algorithms exists, each with its strengths and weaknesses. For example, k-means assumes spherical clusters of similar size, which isn’t always true. DBSCAN, for instance, can discover clusters of arbitrary shapes and identify outliers. Gaussian Mixture Models provide a probabilistic approach, giving you a likelihood that a point belongs to a cluster rather than a hard assignment. The choice of algorithm highly depends on the nature of your data and the specific problem you’re trying to solve.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="evaluating-cluster-quality" class="slide level2">
<h2>Evaluating Cluster Quality</h2>
<p>How do we measure the “goodness” of clusters when we don’t have true labels?</p>
<ul>
<li><strong>Internal Metrics:</strong> Evaluate clustering based on the data itself (e.g., compactness, separation).</li>
<li><strong>External Metrics:</strong> If we <em>do</em> have ground truth labels (e.g., for comparison or research), we can use these.</li>
</ul>
<p>Today, we’ll focus on some external metrics that are useful when you happen to have ground truth labels for comparison, even though clustering is unsupervised. These are similar to metrics you’ve seen but adapted for clustering.</p>
<aside class="notes">
<p>A critical question in clustering is: how do we know if our clusters are any good? Unlike supervised learning where we have clear accuracy metrics, clustering lacks a direct ground truth. So, evaluating cluster quality is a nuanced topic.</p>
<p>We categorize evaluation metrics into “internal” and “external.” Internal metrics assess how well the clusters are formed using only the data itself, looking at things like how tightly packed points are within a cluster (compactness) or how far apart different clusters are (separation).</p>
<p>However, sometimes, perhaps in a research setting or when comparing to a known categorization, you might have access to ‘ground truth’ labels. In those specific cases, we can use external metrics to compare our clustering results against these known labels. We’ll briefly touch on three such external metrics now.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="homogeneity" class="slide level2">
<h2>Homogeneity</h2>
<p><span class="math display">\[ \text{Homogeneity} = 1 - \frac{H(C|K)}{H(C)} \]</span></p>
<ul>
<li><strong>Definition:</strong> A clustering result satisfies homogeneity if each cluster contains only data points belonging to a single class.</li>
<li><strong>Range:</strong> 0.0 to 1.0.</li>
<li><strong>Perfect Homogeneity (1.0):</strong> Every cluster is pure; it has items of only one type.</li>
</ul>
<div class="callout callout-caution callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Caution</strong></p>
</div>
<div class="callout-content">
<p><strong>Limitations:</strong> Can be artificially high by having many small clusters (e.g., each point is its own cluster!).</p>
</div>
</div>
</div>
<aside class="notes">
<p>Homogeneity measures whether each cluster is “pure” – meaning it ideally contains only members from a single ground-truth class. Think back to our fastener example: if one of your groups contained <em>only</em> screws and no bolts or washers, it would be highly homogeneous. A score of 1.0 means every cluster consists of items from just one class. However, watch out for the pitfall: you can get a perfect homogeneity score by making every single data point its own cluster. This isn’t useful, so we need other metrics.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="completeness" class="slide level2">
<h2>Completeness</h2>
<p><span class="math display">\[ \text{Completeness} = 1 - \frac{H(K|C)}{H(K)} \]</span></p>
<ul>
<li><strong>Definition:</strong> A clustering result satisfies completeness if all data points belonging to a given class are assigned to the same cluster.</li>
<li><strong>Range:</strong> 0.0 to 1.0.</li>
<li><strong>Perfect Completeness (1.0):</strong> All members of a class are in one cluster.</li>
</ul>
<div class="callout callout-caution callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Caution</strong></p>
</div>
<div class="callout-content">
<p><strong>Limitations:</strong> Can be artificially high by having very few large clusters (e.g., all points in one big cluster!).</p>
</div>
</div>
</div>
<aside class="notes">
<p>Completeness is the flip side of homogeneity. It measures whether all data points that <em>should</em> be together (i.e., belong to the same ground-truth class) are indeed grouped into the same cluster. In our fastener example, if all the screws were in a single cluster, that cluster would be complete with respect to screws. A score of 1.0 means that for any given ground-truth class, all its members are found within a single cluster. The hack for completeness is to put all your data into one giant cluster, which would score 1.0 but again, is not useful.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="v-measure" class="slide level2">
<h2>V-measure</h2>
<p><span class="math display">\[ V = 2 \frac{\text{homogeneity} \cdot \text{completeness}}{\text{homogeneity} + \text{completeness}} \]</span></p>
<ul>
<li>The V-measure is the <strong>harmonic mean</strong> of homogeneity and completeness.</li>
<li>It provides a balanced score between the two metrics.</li>
<li>A high V-measure indicates both:
<ul>
<li>Clusters are homogeneous (pure).</li>
<li>Clusters are complete (all members of a class are together).</li>
</ul></li>
</ul>
<div class="callout callout-important callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Important</strong></p>
</div>
<div class="callout-content">
<p><strong>Aim for a high V-measure as it penalizes clustering solutions that are not balanced.</strong></p>
</div>
</div>
</div>
<aside class="notes">
<p>Since homogeneity and completeness can be trivially maximized by extreme clustering solutions, we need a metric that balances them. The V-measure comes to the rescue! Much like the F1 score we saw in classification, V-measure is the harmonic mean of homogeneity and completeness. This means it only gives a high score if both homogeneity and completeness are high. It’s a robust way to assess cluster quality when ground truth labels are available for comparison, offering a single, balanced value.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="clustering-lab-preview-mushroom-classification" class="slide level2">
<h2>Clustering Lab Preview: Mushroom Classification</h2>
<p><img src="06_res/mushrooms.jpg" alt="Two mushrooms in a forest setting" style="max-width: 60%; height: auto; display: block; margin: 0 auto;"></p>
<blockquote>
<p>Can we cluster mushrooms to determine if they are edible or poisonous? Using attributes like cap shape, odor, and gill size.</p>
</blockquote>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a><span class="co"># Basic k-means usage in scikit-learn</span></span>
<span id="cb2-2"><a></a><span class="im">from</span> sklearn.cluster <span class="im">import</span> KMeans</span>
<span id="cb2-3"><a></a></span>
<span id="cb2-4"><a></a><span class="co"># Initialize KMeans model with 'k' clusters</span></span>
<span id="cb2-5"><a></a><span class="co"># n_init='auto' ensures best of multiple centroid initializations</span></span>
<span id="cb2-6"><a></a>model <span class="op">=</span> KMeans(n_clusters<span class="op">=</span><span class="dv">10</span>, random_state<span class="op">=</span><span class="dv">42</span>, n_init<span class="op">=</span><span class="st">'auto'</span>)</span>
<span id="cb2-7"><a></a></span>
<span id="cb2-8"><a></a><span class="co"># Assuming 'X' is your preprocessed feature data</span></span>
<span id="cb2-9"><a></a><span class="co"># model.fit(X)</span></span>
<span id="cb2-10"><a></a><span class="co"># cluster_assignments = model.labels_</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<aside class="notes">
<p>Now, let’s look at a practical lab example. We’ll be working with a dataset of mushrooms, where each mushroom has various attributes like cap shape, odor, and gill color. The goal is to see if k-means clustering can naturally group mushrooms into categories that align with their edibility – whether they are poisonous or edible. This is a classic example of using unsupervised learning to derive insights without explicit prior labels for edibility within the clustering process itself. The snippet shows how simple it is to initialize a <code>KMeans</code> model in <code>scikit-learn</code>, setting the number of clusters and a random state for reproducibility.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="your-turn-k-means-lab" class="slide level2">
<h2>Your Turn: K-Means Lab</h2>
<p>Let’s dive into the practical application of k-means.</p>
<ul>
<li><strong>Open the K-Means Lab in your environment.</strong></li>
<li><strong>Explore:</strong>
<ul>
<li>Load and preprocess the mushroom dataset.</li>
<li>Apply <code>KMeans</code> with different <code>k</code> values.</li>
<li>Evaluate the clusters using metrics like Homogeneity, Completeness, and V-measure against the <em>actual</em> edibility labels (as a proxy for ground truth).</li>
</ul></li>
<li><strong>Discuss:</strong> What do the results tell you about distinguishing edible from poisonous mushrooms using clustering?</li>
</ul>
<aside class="notes">
<p>Now it’s your turn to apply what you’ve learned. Head to the K-Means lab. You’ll be working with the mushroom dataset. Your tasks will involve loading and preprocessing this dataset, applying the KMeans algorithm, and then, crucially, evaluating the clusters. Even though clustering is unsupervised, the mushroom dataset does come with an “edibility” label, which we can use as a “ground truth” to evaluate the quality of our clusters using metrics like Homogeneity, Completeness, and V-measure. This is a great way to understand the performance of clustering in a real-world scenario.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

</section></section>
<section>
<section id="embeddings" class="title-slide slide level1 center">
<h1>Embeddings</h1>
<p><strong>Bridging Discrete and Dense Representations</strong></p>
<aside class="notes">
<p>Now, we’ll shift our focus to another powerful concept in machine learning: Embeddings. While clustering helps us find groups, embeddings help us represent complex, high-dimensional, or discrete data in a more meaningful and efficient way, particularly for deep learning models. They are fundamental in fields like Natural Language Processing and Recommender Systems.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-challenge-of-one-hot-encodings" class="slide level2 scrollable">
<h2>The Challenge of One-Hot Encodings</h2>
<div class="columns">
<div class="column" style="width:48%;">
<ul>
<li>Often used for categorical data (e.g., words, user IDs, product types).</li>
<li>Each category represented by a vector with a <code>1</code> at its unique index and <code>0</code>s elsewhere.</li>
</ul>
<div class="callout callout-caution callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Caution</strong></p>
</div>
<div class="callout-content">
<p><strong>Problems:</strong></p>
<ol type="1">
<li><strong>Sparsity &amp; High Dimensionality:</strong> Many zeros, very large vectors for large vocabularies.</li>
<li><strong>No Semantic Similarity:</strong> “Hotel” and “Motel” are represented as equally distant as “Hotel” and “Banana”.</li>
</ol>
</div>
</div>
</div>
</div><div class="column" style="width:52%;">
<p><img data-src="06_res/embeddings01.png"></p>
</div></div>
<aside class="notes">
<p>Let’s first understand the problem that embeddings solve. Often, our data involves categorical variables like words, user IDs, or types of devices. A common way to convert these into a numerical format that machine learning models can process is “one-hot encoding.” As you can see in the diagram, each unique word gets its own position in a vector, where a ‘1’ indicates the presence of that word and ’0’s elsewhere.</p>
<p>While simple, one-hot encoding suffers from two major drawbacks. First, for large vocabularies or many categories, the vectors become incredibly long and sparse, mostly filled with zeros, leading to inefficient computations. Second, and more critically for machine learning, one-hot encodings fail to capture any semantic relationships. “Hotel” and “Motel” are conceptually very similar, but their one-hot vectors would be orthogonal, implying no relation at all. We need a richer representation.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="embeddings-efficient-dense-and-semantic" class="slide level2">
<h2>Embeddings: Efficient, Dense, and Semantic</h2>
<div class="columns">
<div class="column" style="width:48%;">
<ul>
<li><strong>Efficient, Dense Representation:</strong>
<ul>
<li>Represent discrete items (words, categories) as low-dimensional, dense vectors of real numbers.</li>
<li>Reduces dimensionality and memory footprint.</li>
</ul></li>
<li><strong>Semantic Similarity:</strong>
<ul>
<li>Crucially, similar items are represented by <strong>similar vectors</strong> (close in vector space).</li>
<li>Captures relationships beyond simple identity.</li>
</ul></li>
</ul>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p><strong>Word embeddings capture meaning!</strong> <em>Example:</em> Vector(“King”) - Vector(“Man”) + Vector(“Woman”) <span class="math inline">\(\approx\)</span> Vector(“Queen”)</p>
</div>
</div>
</div>
</div><div class="column" style="width:52%;">
<p><img data-src="06_res/embeddings02.png"></p>
</div></div>
<aside class="notes">
<p>This is where embeddings come in. Instead of sparse, high-dimensional one-hot vectors, embeddings represent each item as a short, dense vector of real numbers. This provides a much more efficient way to store and process categorical data.</p>
<p>But the real magic of embeddings lies in their ability to capture semantic meaning and relationships. Items that are conceptually similar, like “hotel” and “motel”, will have embedding vectors that are geometrically close to each other in this lower-dimensional space. This allows models to generalize better and understand nuanced relationships. The famous example is how vector arithmetic on word embeddings can reveal analogies, like “King minus Man plus Woman equals Queen.”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="using-embeddings-in-tensorflowkeras" class="slide level2">
<h2>Using Embeddings in TensorFlow/Keras</h2>
<p>In deep learning models, embeddings are usually learned weights.</p>
<ul>
<li>The <code>Embedding</code> layer acts as a <strong>lookup table</strong>.</li>
<li>It maps integer indices to dense vectors.</li>
</ul>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a><span class="im">import</span> tensorflow <span class="im">as</span> tf</span>
<span id="cb3-2"><a></a><span class="im">from</span> tensorflow <span class="im">import</span> keras</span>
<span id="cb3-3"><a></a></span>
<span id="cb3-4"><a></a><span class="co"># Define an Embedding layer</span></span>
<span id="cb3-5"><a></a><span class="co"># Args: (total_vocabulary_size, embedding_dimension)</span></span>
<span id="cb3-6"><a></a>embedding_layer <span class="op">=</span> keras.layers.Embedding(</span>
<span id="cb3-7"><a></a>    input_dim<span class="op">=</span><span class="dv">15</span>,  <span class="co"># e.g., 15 unique words</span></span>
<span id="cb3-8"><a></a>    output_dim<span class="op">=</span><span class="dv">4</span>   <span class="co"># e.g., representing each word with a 4-dim vector</span></span>
<span id="cb3-9"><a></a>)</span>
<span id="cb3-10"><a></a></span>
<span id="cb3-11"><a></a><span class="co"># Example Usage:</span></span>
<span id="cb3-12"><a></a><span class="co"># input_data = tf.constant([0, 1, 10]) # Indices for 3 words</span></span>
<span id="cb3-13"><a></a><span class="co"># embedded_output = embedding_layer(input_data)</span></span>
<span id="cb3-14"><a></a><span class="co"># print(embedded_output.shape) # Expected: (3, 4)</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p>The embedding values are learned parameters during model training, just like other weights.</p>
</div>
</div>
</div>
<aside class="notes">
<p>In practice, especially within deep learning frameworks like TensorFlow and Keras, embeddings are not hand-engineered but rather learned. Keras provides a convenient <code>Embedding</code> layer for this purpose. You specify two main parameters: <code>input_dim</code>, which is the total number of unique items (your vocabulary size), and <code>output_dim</code>, which is the desired dimensionality of your embedding vectors.</p>
<p>This <code>Embedding</code> layer essentially acts as a dynamically updated lookup table. When you feed an integer index (representing a specific word or item) to this layer, it returns the corresponding dense embedding vector. Crucially, the values within these embedding vectors are initialized randomly and then iteratively adjusted and optimized during the model’s training process, allowing them to capture the semantic and contextual relationships present in your data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="embedding-layer-a-look-up-table" class="slide level2">
<h2>Embedding Layer: A Look-Up Table</h2>

<img data-src="06_res/embeddings03.png" class="r-stretch"><ul>
<li>Each row corresponds to a unique item (e.g., word) in your vocabulary.</li>
<li>Each column is a dimension of the embedding vector.</li>
<li>The values (weights) in this table are learned by the model.</li>
</ul>
<aside class="notes">
<p>This diagram visually illustrates how the Keras <code>Embedding</code> layer functions as a lookup table. Think of it as a matrix where each row corresponds to a unique word or item in your vocabulary, identified by its integer index. The number of rows is your <code>input_dim</code> (vocabulary size). Each column represents one dimension of the embedding vector, and the number of columns is your <code>output_dim</code>.</p>
<p>When your model encounters a word (represented by its integer index), the embedding layer simply ‘looks up’ the corresponding row in this table and returns that dense vector. The magic is that the values <em>within</em> this table are not static; they are the parameters that the neural network learns during training, which allows them to capture meaningful relationships between words.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="visualizing-embeddings-closeness-implies-similarity" class="slide level2">
<h2>Visualizing Embeddings: Closeness Implies Similarity</h2>
<p><img src="06_res/embeddings04.png" alt="Visualization of word embeddings showing 'hotel' and 'resort' close together" style="max-width: 70%; height: auto; display: block; margin: 0 auto;"></p>
<ul>
<li>Words with similar meanings or contexts cluster together in the embedding space.</li>
<li>This geometric closeness is a powerful feature for downstream tasks.</li>
</ul>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p><strong>ECE Application:</strong> In natural language processing for voice assistants or anomaly detection in network logs, similar commands or event types should have close embeddings.</p>
</div>
</div>
</div>
<aside class="notes">
<p>One of the most compelling aspects of embeddings is their visual interpretability. When we project these high-dimensional embedding vectors into 2D or 3D space (using techniques like t-SNE or PCA), we can actually “see” the relationships. As shown in the diagram, words like “hotel” and “resort” are typically found very close to each other, indicating their semantic similarity. Conversely, words with vastly different meanings would be far apart. This visual clustering not only confirms that the embeddings are capturing meaning, but it also provides a powerful intuition for how they enable machine learning models to reason about complex relationships in data. This has direct ECE applications in areas like understanding user commands for a voice interface or detecting anomalies in system logs where similar events should be grouped.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="interactive-embedding-comparison" class="slide level2">
<h2>Interactive Embedding Comparison</h2>
<p>Compare One-Hot vs.&nbsp;Conceptual Embedding for chosen words.</p>
<div class="columns">
<div class="column" style="width:45%;">
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code hidden" id="cb4" data-startfrom="602" data-source-offset="-0"><pre class="sourceCode numberSource js number-lines code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 601;"><span id="cb4-602"><a></a>vocab <span class="op">=</span> [<span class="st">"hotel"</span><span class="op">,</span> <span class="st">"motel"</span><span class="op">,</span> <span class="st">"cat"</span><span class="op">,</span> <span class="st">"dog"</span><span class="op">,</span> <span class="st">"apple"</span><span class="op">,</span> <span class="st">"banana"</span>]</span>
<span id="cb4-603"><a></a>viewof selected_word <span class="op">=</span> Inputs<span class="op">.</span><span class="fu">select</span>(vocab<span class="op">,</span> {<span class="dt">label</span><span class="op">:</span> <span class="st">"Select a Word"</span>})<span class="op">;</span></span>
<span id="cb4-604"><a></a></span>
<span id="cb4-605"><a></a>viewof embed_dim <span class="op">=</span> Inputs<span class="op">.</span><span class="fu">range</span>([<span class="dv">2</span><span class="op">,</span> <span class="dv">8</span>]<span class="op">,</span> {<span class="dt">step</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span> <span class="dt">value</span><span class="op">:</span> <span class="dv">4</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">"Embedding Dimension (max 8)"</span>})<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-1" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-2" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-2-3" data-nodetype="declaration">

</div>
</div>
</div>
</div>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p>Observe how the one-hot encoding changes vs.&nbsp;the dense, semantic embedding for different words and dimensions.</p>
</div>
</div>
</div>
</div><div class="column" style="width:55%;">
<div>
<div id="pyodide-2" class="exercise-cell">

</div>
<script type="pyodide-2-contents">
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
</script>
</div>
</div></div>
<aside class="notes">
<p>This interactive section allows you to directly compare one-hot encoding with a conceptual embedding. On the left, you can select a word from a dropdown list and adjust the desired dimensionality for the embedding. The Python code on the right then generates and visualizes: first, the sparse one-hot vector for the selected word against the entire vocabulary, and second, a dense conceptual embedding vector truncated to your chosen dimension.</p>
<p>Notice how the one-hot encoding is always sparse and has the same length as the vocabulary, while the embedding is dense and its length depends on the embedding dimension. Also, try selecting <code>hotel</code> and then <code>motel</code> and observe how their conceptual embeddings show similar patterns compared to <code>cat</code> or <code>dog</code>, which are quite different. This visually demonstrates the efficiency and semantic power of embeddings.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="embeddings-in-practice-for-ece" class="slide level2">
<h2>Embeddings in Practice for ECE</h2>
<p>Embeddings are not just for words!</p>
<ul>
<li><strong>Image Recognition:</strong> Learning embeddings for regions/objects in images.</li>
<li><strong>Sensor Data:</strong> Representing different sensor types or states.</li>
<li><strong>Anomaly Detection:</strong> Embedding normal vs.&nbsp;anomalous system behavior for network security.</li>
<li><strong>Robotics:</strong> Learning compact representations of robot states or environments.</li>
<li><strong>Recommender Systems:</strong> Embedding users and items to capture preferences.</li>
<li><strong>Device Characterization:</strong> Compactly representing device features for classification or clustering.</li>
</ul>
<aside class="notes">
<p>The power of embeddings extends far beyond natural language. In Electrical and Computer Engineering, embeddings find applications in diverse fields:</p>
<ul>
<li>In <strong>computer vision</strong>, embeddings can represent features extracted from images, allowing for tasks like image retrieval or object recognition where similar objects have close embeddings.</li>
<li>For <strong>sensor data</strong>, you can embed different types of sensor readings or states into a common space, enabling better fusion or comparison of heterogeneous data.</li>
<li>In <strong>network security</strong>, embeddings can be used for anomaly detection by training models to embed normal network traffic or system logs into a dense representation. Deviations would show up as distant points in the embedding space.</li>
<li><strong>Robotics</strong> can use embeddings to learn efficient representations of complex robot states or environmental maps.</li>
<li><strong>Recommender systems</strong>, crucial for many online ECE products, use embeddings to represent users and items, allowing the system to find similar items or predict user preferences efficiently.</li>
<li>Finally, in <strong>device characterization</strong>, embeddings can represent complex device characteristics from test data, enabling better classification of devices or clustering for quality control.</li>
</ul>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="your-turn-embeddings-lab" class="slide level2">
<h2>Your Turn: Embeddings Lab</h2>
<p>Let’s apply your understanding of embeddings!</p>
<ul>
<li><strong>Open the Embeddings Lab in your environment.</strong></li>
<li><strong>Explore:</strong>
<ul>
<li>Work with an embedding layer in TensorFlow/Keras.</li>
<li>Train your own embeddings for a dataset of categorical features.</li>
<li>Visualize the learned embeddings, perhaps reduced to 2D or 3D.</li>
</ul></li>
<li><strong>Discuss:</strong>
<ul>
<li>How do the learned embeddings differ from one-hot encodings?</li>
<li>What insights can you gain from visualizing these embeddings?</li>
</ul></li>
</ul>
<aside class="notes">
<p>Alright, it’s time to put what you’ve learned about embeddings into practice. Proceed to the Embeddings Lab. In this lab, you’ll get hands-on experience by defining and training your own embedding layers within a TensorFlow/Keras model. You’ll work with a dataset that has categorical features, observe how the model learns these dense representations, and then visualize these learned embeddings, potentially projecting them down to 2 or 3 dimensions to better understand the relationships they capture. This lab will deepen your appreciation for how embeddings transform abstract categories into meaningful, actionable data points for your machine learning models.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>


<script type="pyodide-data">
eyJvcHRpb25zIjp7ImVudiI6eyJQTE9UTFlfUkVOREVSRVIiOiJwbG90bHlfbWltZXR5cGUifSwiaW5kZXhVUkwiOiJodHRwczovL2Nkbi5qc2RlbGl2ci5uZXQvcHlvZGlkZS92MC4yNy4wL2Z1bGwvIn0sInBhY2thZ2VzIjp7InBrZ3MiOlsicHlvZGlkZV9odHRwIiwibWljcm9waXAiLCJpcHl0aG9uIiwibnVtcHkiLCJwbG90bHkiLCJuYmZvcm1hdCJdfX0=
</script>
<script type="ojs-module-contents">
{"contents":[{"cellName":"pyodide-2","inline":false,"methodName":"interpret","source":"_pyodide_value_2 = {\n  const { highlightPython, b64Decode} = window._exercise_ojs_runtime;\n\n  const scriptContent = document.querySelector(`script[type=\\\"pyodide-2-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  // Default evaluation configuration\n  const options = Object.assign({\n    id: \"pyodide-2-contents\",\n    echo: true,\n    output: true\n  }, block.attr);\n\n  // Evaluate the provided Python code\n  const result = pyodideOjs.process({code: block.code, options}, {selected_word, embed_dim});\n\n  // Early yield while we wait for the first evaluation and render\n  if (options.output && !(\"2\" in pyodideOjs.renderedOjs)) {\n    const container = document.createElement(\"div\");\n    const spinner = document.createElement(\"div\");\n\n    if (options.echo) {\n      // Show output as highlighted source\n      const preElem = document.createElement(\"pre\");\n      container.className = \"sourceCode\";\n      preElem.className = \"sourceCode python\";\n      preElem.appendChild(highlightPython(block.code));\n      spinner.className = \"spinner-grow spinner-grow-sm m-2 position-absolute top-0 end-0\";\n      preElem.appendChild(spinner);\n      container.appendChild(preElem);\n    } else {\n      spinner.className = \"spinner-border spinner-border-sm\";\n      container.appendChild(spinner);\n    }\n\n    yield container;\n  }\n\n  pyodideOjs.renderedOjs[\"2\"] = true;\n  yield await result;\n}\n"},{"cellName":"pyodide-1","inline":false,"methodName":"interpret","source":"_pyodide_value_1 = {\n  const { highlightPython, b64Decode} = window._exercise_ojs_runtime;\n\n  const scriptContent = document.querySelector(`script[type=\\\"pyodide-1-contents\\\"]`).textContent;\n  const block = JSON.parse(b64Decode(scriptContent));\n\n  // Default evaluation configuration\n  const options = Object.assign({\n    id: \"pyodide-1-contents\",\n    echo: true,\n    output: true\n  }, block.attr);\n\n  // Evaluate the provided Python code\n  const result = pyodideOjs.process({code: block.code, options}, {k_clusters});\n\n  // Early yield while we wait for the first evaluation and render\n  if (options.output && !(\"1\" in pyodideOjs.renderedOjs)) {\n    const container = document.createElement(\"div\");\n    const spinner = document.createElement(\"div\");\n\n    if (options.echo) {\n      // Show output as highlighted source\n      const preElem = document.createElement(\"pre\");\n      container.className = \"sourceCode\";\n      preElem.className = \"sourceCode python\";\n      preElem.appendChild(highlightPython(block.code));\n      spinner.className = \"spinner-grow spinner-grow-sm m-2 position-absolute top-0 end-0\";\n      preElem.appendChild(spinner);\n      container.appendChild(preElem);\n    } else {\n      spinner.className = \"spinner-border spinner-border-sm\";\n      container.appendChild(spinner);\n    }\n\n    yield container;\n  }\n\n  pyodideOjs.renderedOjs[\"1\"] = true;\n  yield await result;\n}\n"},{"cellName":"pyodide-prelude","inline":false,"methodName":"interpretQuiet","source":"pyodideOjs = {\n  const {\n    PyodideEvaluator,\n    PyodideEnvironmentManager,\n    setupPython,\n    startPyodideWorker,\n    b64Decode,\n    collapsePath,\n  } = window._exercise_ojs_runtime;\n\n  const statusContainer = document.getElementById(\"exercise-loading-status\");\n  const indicatorContainer = document.getElementById(\"exercise-loading-indicator\");\n  indicatorContainer.classList.remove(\"d-none\");\n\n  let statusText = document.createElement(\"div\")\n  statusText.classList = \"exercise-loading-details\";\n  statusText = statusContainer.appendChild(statusText);\n  statusText.textContent = `Initialise`;\n\n  // Hoist indicator out from final slide when running under reveal\n  const revealStatus = document.querySelector(\".reveal .exercise-loading-indicator\");\n  if (revealStatus) {\n    revealStatus.remove();\n    document.querySelector(\".reveal > .slides\").appendChild(revealStatus);\n  }\n\n  // Make any reveal slides with live cells scrollable\n  document.querySelectorAll(\".reveal .exercise-cell\").forEach((el) => {\n    el.closest('section.slide').classList.add(\"scrollable\");\n  })\n\n  // Pyodide supplemental data and options\n  const dataContent = document.querySelector(`script[type=\\\"pyodide-data\\\"]`).textContent;\n  const data = JSON.parse(b64Decode(dataContent));\n\n  // Grab list of resources to be downloaded\n  const filesContent = document.querySelector(`script[type=\\\"vfs-file\\\"]`).textContent;\n  const files = JSON.parse(b64Decode(filesContent));\n\n  let pyodidePromise = (async () => {\n    statusText.textContent = `Downloading Pyodide`;\n    const pyodide = await startPyodideWorker(data.options);\n\n    statusText.textContent = `Downloading package: micropip`;\n    await pyodide.loadPackage(\"micropip\");\n    const micropip = await pyodide.pyimport(\"micropip\");\n    await data.packages.pkgs.map((pkg) => () => {\n      statusText.textContent = `Downloading package: ${pkg}`;\n      return micropip.install(pkg);\n    }).reduce((cur, next) => cur.then(next), Promise.resolve());\n    await micropip.destroy();\n\n    // Download and install resources\n    await files.map((file) => async () => {\n      const name = file.substring(file.lastIndexOf('/') + 1);\n      statusText.textContent = `Downloading resource: ${name}`;\n      const response = await fetch(file);\n      if (!response.ok) {\n        throw new Error(`Can't download \\`${file}\\`. Error ${response.status}: \"${response.statusText}\".`);\n      }\n      const data = await response.arrayBuffer();\n\n      // Store URLs in the cwd without any subdirectory structure\n      if (file.includes(\"://\")) {\n        file = name;\n      }\n\n      // Collapse higher directory structure\n      file = collapsePath(file);\n\n      // Create directory tree, ignoring \"directory exists\" VFS errors\n      const parts = file.split('/').slice(0, -1);\n      let path = '';\n      while (parts.length > 0) {\n        path += parts.shift() + '/';\n        try {\n          await pyodide.FS.mkdir(path);\n        } catch (e) {\n          if (e.name !== \"ErrnoError\") throw e;\n          if (e.errno !== 20) {\n            const errorTextPtr = await pyodide._module._strerror(e.errno);\n            const errorText = await pyodide._module.UTF8ToString(errorTextPtr);\n            throw new Error(`Filesystem Error ${e.errno} \"${errorText}\".`);\n          }\n        }\n      }\n\n      // Write this file to the VFS\n      try {\n        return await pyodide.FS.writeFile(file, new Uint8Array(data));\n      } catch (e) {\n        if (e.name !== \"ErrnoError\") throw e;\n        const errorTextPtr = await pyodide._module._strerror(e.errno);\n        const errorText = await pyodide._module.UTF8ToString(errorTextPtr);\n        throw new Error(`Filesystem Error ${e.errno} \"${errorText}\".`);\n      }\n    }).reduce((cur, next) => cur.then(next), Promise.resolve());\n\n    statusText.textContent = `Pyodide environment setup`;\n    await setupPython(pyodide);\n\n    statusText.remove();\n    if (statusContainer.children.length == 0) {\n      statusContainer.parentNode.remove();\n    }\n    return pyodide;\n  })().catch((err) => {\n    statusText.style.color = \"var(--exercise-editor-hl-er, #AD0000)\";\n    statusText.textContent = err.message;\n    //indicatorContainer.querySelector(\".spinner-grow\").classList.add(\"d-none\");\n    throw err;\n  });\n\n  // Keep track of initial OJS block render\n  const renderedOjs = {};\n\n  const process = async (context, inputs) => {\n    const pyodide = await pyodidePromise;\n    const evaluator = new PyodideEvaluator(pyodide, context);\n    await evaluator.process(inputs);\n    return evaluator.container;\n  }\n\n  return {\n    pyodidePromise,\n    renderedOjs,\n    process,\n  };\n}\n"}]}
</script>
<div id="exercise-loading-indicator" class="exercise-loading-indicator d-none d-flex align-items-center gap-2">
<div id="exercise-loading-status" class="d-flex gap-2">

</div>
<div class="spinner-grow spinner-grow-sm">

</div>
</div>
<script type="vfs-file">
W10=
</script>
</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="../qrjs_pics/unsoed_logo.png" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://imron-slide.vercel.app">irosyadi-2025</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script type="ojs-module-contents">
    eyJjb250ZW50cyI6W3sibWV0aG9kTmFtZSI6ImludGVycHJldCIsImNlbGxOYW1lIjoib2pzLWNlbGwtMSIsImlubGluZSI6ZmFsc2UsInNvdXJjZSI6ImltcG9ydCB7IHNsaWRlciB9IGZyb20gXCJAamFzaGtlbmFzL2lucHV0c1wiO1xudmlld29mIGtfY2x1c3RlcnMgPSBzbGlkZXIoe1xuICBtaW46IDIsXG4gIG1heDogMTAsXG4gIHN0ZXA6IDEsXG4gIHZhbHVlOiA0LFxuICBsYWJlbDogXCJOdW1iZXIgb2YgQ2x1c3RlcnMgKGspXCJcbn0pO1xuIn0seyJtZXRob2ROYW1lIjoiaW50ZXJwcmV0IiwiY2VsbE5hbWUiOiJvanMtY2VsbC0yIiwiaW5saW5lIjpmYWxzZSwic291cmNlIjoidm9jYWIgPSBbXCJob3RlbFwiLCBcIm1vdGVsXCIsIFwiY2F0XCIsIFwiZG9nXCIsIFwiYXBwbGVcIiwgXCJiYW5hbmFcIl1cbnZpZXdvZiBzZWxlY3RlZF93b3JkID0gSW5wdXRzLnNlbGVjdCh2b2NhYiwge2xhYmVsOiBcIlNlbGVjdCBhIFdvcmRcIn0pO1xuXG52aWV3b2YgZW1iZWRfZGltID0gSW5wdXRzLnJhbmdlKFsyLCA4XSwge3N0ZXA6IDEsIHZhbHVlOiA0LCBsYWJlbDogXCJFbWJlZGRpbmcgRGltZW5zaW9uIChtYXggOClcIn0pO1xuIn0seyJtZXRob2ROYW1lIjoiaW50ZXJwcmV0UXVpZXQiLCJzb3VyY2UiOiJzaGlueUlucHV0KCdrX2NsdXN0ZXJzJykifSx7Im1ldGhvZE5hbWUiOiJpbnRlcnByZXRRdWlldCIsInNvdXJjZSI6InNoaW55SW5wdXQoJ3NlbGVjdGVkX3dvcmQnKSJ9LHsibWV0aG9kTmFtZSI6ImludGVycHJldFF1aWV0Iiwic291cmNlIjoic2hpbnlJbnB1dCgnZW1iZWRfZGltJykifV19
    </script>
    <script type="module">
    if (window.location.protocol === "file:") { alert("The OJS runtime does not work with file:// URLs. Please use a web server to view this document."); }
    window._ojs.paths.runtimeToDoc = "../../amli";
    window._ojs.paths.runtimeToRoot = "../..";
    window._ojs.paths.docToRoot = "..";
    window._ojs.selfContained = false;
    window._ojs.runtime.interpretFromScriptTags();
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>