<!DOCTYPE html>
<html lang="en"><head>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-7b89279ff1a6dce999919e0e67d4d9ec.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/quarto-contrib/live-runtime/live-runtime.js" type="module"></script>
<link href="../site_libs/quarto-contrib/live-runtime/live-runtime.css" rel="stylesheet"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.8.25">

  <meta name="author" content="Imron Rosyadi">
  <title>Machine Learning</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    html { -webkit-text-size-adjust: 100%; }
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-b0356e9119c1bdfd0db189d130feb51c.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/font-awesome/css/all.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-chalkboard/style.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script type="module" src="../site_libs/quarto-ojs/quarto-ojs-runtime.js"></script>
  <link href="../site_libs/quarto-ojs/quarto-ojs.css" rel="stylesheet">
  <meta name="mermaid-theme" content="neutral">
  <script src="../site_libs/quarto-diagram/mermaid.min.js"></script>
  <script src="../site_libs/quarto-diagram/mermaid-init.js"></script>
  <link href="../site_libs/quarto-diagram/mermaid.css" rel="stylesheet">
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Machine Learning</h1>
  <p class="subtitle">Introduction to Classification</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Imron Rosyadi 
</div>
</div>
</div>

</section>
<section class="slide level2">

<!-- Include Marp style resets if the previous content used it, but Quarto's Reveal.js handles separation well. -->
<style>
img[alt~="center"] {
  display: block;
  margin: 0 auto;
}
</style>
</section>
<section>
<section id="classification-fundamentals-for-ece" class="title-slide slide level1 center">
<h1>Classification Fundamentals for ECE</h1>
<aside class="notes">
<p>Welcome to this lecture on Classification for Electrical and Computer Engineering undergraduates. This topic is fundamental to many real-world engineering applications, especially in areas like signal processing, image recognition, control systems, and embedded machine learning. Today, we’ll dive into what classification is, how it differs from regression, common models, and crucial evaluation metrics.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="classification-vs.-regression-a-quick-review" class="slide level2">
<h2>Classification vs.&nbsp;Regression: A Quick Review</h2>
<div class="columns">
<div class="column" style="width:50%;">
<h3 id="regression-predicting-continuous-values">Regression: Predicting Continuous Values</h3>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="04_res/regression.gif"></p>
<figcaption>center</figcaption>
</figure>
</div>
<ul>
<li>Predicts a numeric, continuous output.</li>
<li>Examples: House prices, temperature, signal strength.</li>
<li>Evaluation: Measures like Mean Squared Error (MSE).</li>
</ul>
<aside class="notes">
<p>Recall that regression attempts to predict a continuous value. In this illustration, you can see a linear regression fitting a line to a dataset. We judge the quality of our regression by measuring the distance of the actual data from our prediction line. Metrics like Mean Squared Error and Root Mean Squared Error are common. In ECE, regression might be used for predicting sensor readings or component lifetimes.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div><div class="column" style="width:50%;">
<h3 id="classification-predicting-categories">Classification: Predicting Categories</h3>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="04_res/classification.gif"></p>
<figcaption>center</figcaption>
</figure>
</div>
<ul>
<li>Predicts a categorical, discrete output.</li>
<li>Examples: Spam/Not Spam, Object presence (cat/dog), Fault detection.</li>
<li>Evaluation: Focuses on correct vs.&nbsp;incorrect assignments.</li>
</ul>
<aside class="notes">
<p>Classification models don’t predict a continuous value, but instead attempt to predict the “class” or category of a data point. Classification algorithms can distinguish between two states (binary classification), like spam or not. They can also determine the probability that a data point belongs to one of many classes (multi-class classification), such as identifying different types of modulation in a communication signal. The illustration shows separating red and blue data points using a clear boundary. In ECE, this could be identifying a defect on a PCB, classifying speech commands, or detecting anomalies in sensor data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div></div>
</section>
<section id="what-does-it-mean-to-classify" class="slide level2">
<h2>What Does It Mean to Classify?</h2>
<p>Classification model results are often returned as a list of <strong>confidences</strong> for each class. The model predicts the probability a data point belongs to each class.</p>
</section>
<section id="understanding-classification-confidence" class="slide level2">
<h2>Understanding Classification Confidence</h2>
<div class="columns">
<div class="column" style="width:60%;">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="04_res/tiger.png"></p>
<figcaption>center</figcaption>
</figure>
</div>
<aside class="notes">
<p>Classification models often return a list of confidences, indicating the predicted probability that a given data point belongs to each possible class. For example, when analyzing an image, the model might assign a 98% confidence to “tiger,” 1% to “lion,” and 1% to “cheetah.” These confidences are not always true probabilities without further transformation, like applying a softmax function. Your code then needs to interpret these predictions to make a final decision, perhaps by selecting the class with the highest confidence or applying a specific threshold.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</div><div class="column" style="width:40%;">
<h3 id="example-output">Example Output:</h3>
<ul>
<li><strong>Tiger:</strong> 0.98</li>
<li><strong>Lion:</strong> 0.01</li>
<li><strong>Cheetah:</strong> 0.01</li>
</ul>
<div class="callout callout-tip callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Tip</strong></p>
</div>
<div class="callout-content">
<p>In ECE, such confidence levels are critical in systems like autonomous vehicles (identifying pedestrians with high certainty), medical image diagnosis, or anomaly detection in power grids.</p>
</div>
</div>
</div>
</div></div>
</section>
<section id="ambiguous-cases" class="slide level2">
<h2>Ambiguous Cases</h2>

<img data-src="04_res/grapefruit.jpg" class="r-stretch quarto-figure-center"><p class="caption">center</p><ul>
<li><strong>Orange:</strong> 0.45</li>
<li><strong>Grapefruit:</strong> 0.53</li>
<li><strong>Lemon:</strong> 0.02</li>
</ul>
<aside class="notes">
<p>Here’s an example of a model returning confusing predictions for an image. The model is highly confident that the image contains either an orange or a grapefruit, with very similar confidence scores. What would you do in this situation? This highlights that sometimes ML models provide ambiguous results, and the system or human operator needs to handle such cases. For instance, in an automated fruit sorting system, this might lead to a re-scan or manual inspection.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="common-classification-models" class="slide level2">
<h2>Common Classification Models</h2>
<div class="columns">
<div class="column" style="width:50%;">
<ul>
<li><strong>Logistic Regression:</strong>
<ul>
<li>A variation of linear regression, uses a sigmoid function for binary outcomes. Simple and interpretable.</li>
</ul></li>
<li><strong>Nearest Neighbors:</strong>
<ul>
<li>Classifies based on the majority class among its closest data points. Intuitive, but sensitive to local data structure.</li>
</ul></li>
<li><strong>Decision Trees:</strong>
<ul>
<li>Tree-like structure where each node tests a feature, leading to a class decision. Good for interpretability.</li>
</ul></li>
</ul>
</div><div class="column" style="width:50%;">
<ul>
<li><strong>Random Forests:</strong>
<ul>
<li>An ensemble of many decision trees, combining their predictions for robustness and better accuracy. Often very powerful.</li>
</ul></li>
<li><strong>Naive Bayes:</strong>
<ul>
<li>Based on Bayes’ theorem, assumes feature independence. Useful for text classification and spam detection.</li>
</ul></li>
<li>**Deep Learning (Neural Networks):
<ul>
<li>Multi-layered networks capable of learning complex patterns. Highly effective for image, speech, and sensor data classification.</li>
</ul></li>
</ul>
</div></div>
<aside class="notes">
<p>There are numerous models that can be used for classification, each with different underlying mathematical principles and strengths. Some of the more common ones we’ll encounter are listed here. In ECE, the choice of model often depends on the type of data, computational constraints (especially for embedded systems), and real-time requirements. For example, simpler models might be preferred for low-power edge devices, while deep learning excels in complex image or signal processing tasks.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-machine-learning-classification-workflow" class="slide level2">
<h2>The Machine Learning Classification Workflow</h2>
<div class="cell" data-reveal="true" data-layout-align="default">
<div class="cell-output-display">
<div>
<p></p><figure class=""><p></p>
<div>
<pre class="mermaid mermaid-js">graph TD
    A[Raw Sensor/System Data] --&gt; B{Data Preprocessing}
    B --&gt; C[Feature Engineering/Extraction]
    C --&gt; D{Split Data &lt;br&gt; (Training &amp; Testing Sets)}
    D -- Training Data --&gt; E[Choose &amp; Train ML Model]
    E -- &amp; Evaluation --&gt; F[Model Evaluation &amp; Tuning]
    D -- Testing Data --&gt; F
    F -- Performance OK? --&gt; G[Deploy Model to ECE System]
    F -- Needs Improvement --&gt; E
    G --&gt; H[New Live Data Input]
    H --&gt; I[Real-time Prediction / Classification]
    I --&gt; J[Action/Decision &lt;br&gt; (e.g., Control Signal, Alert)]

    style A fill:#f9f,stroke:#333,stroke-width:2px;
    style G fill:#bbf,stroke:#333,stroke-width:2px;
    style J fill:#fcf,stroke:#333,stroke-width:2px;
    style E fill:#ccf,stroke:#333,stroke-width:2px;
    style F fill:#dfd,stroke:#333,stroke-width:2px;
</pre>
</div>
<p></p></figure><p></p>
</div>
</div>
</div>
<aside class="notes">
<p>This flowchart illustrates a typical machine learning classification workflow. Notice the continuous loop for model training and evaluation, highlighting that model development is an iterative process. For ECE applications, “Raw Sensor/System Data” could be anything from acceleration data in a drone to voltage readings in a power grid. “Feature Engineering” could involve extracting frequency components, statistical moments, or energy levels from time-series signals. “Deploy Model to ECE System” represents integrating the trained model into hardware, software, or an embedded system, where it performs “Real-time Prediction” and drives “Actions,” such as adjusting a motor’s speed or triggering a safety shutdown.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="classification-model-performance" class="slide level2">
<h2>Classification Model Performance</h2>
<p>Unlike regression, we can’t measure continuous “distance” to evaluate classification. Instead, we count <strong>correct</strong> vs.&nbsp;<strong>incorrect</strong> predictions. These counts form the basis for various performance metrics.</p>
<aside class="notes">
<p>As mentioned, determining the performance of a regression model involves measuring the distance between continuous values. In classification, we’re dealing with discrete categories, so we can’t use the same “distance” concept. Instead, we focus on how many predictions the model got right versus wrong. These counts allow us to define metrics that robustly evaluate model quality. Understanding these metrics is crucial in ECE, especially when a false positive or false negative can have significant consequences.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-confusion-matrix" class="slide level2">
<h2>The Confusion Matrix</h2>

<img data-src="04_res/confusion-matrix.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><ul>
<li><strong>True Positive (TP):</strong> Model predicted positive, was actually positive.</li>
<li><strong>False Positive (FP):</strong> Model predicted positive, was actually negative (Type I error).</li>
<li><strong>False Negative (FN):</strong> Model predicted negative, was actually positive (Type II error).</li>
<li><strong>True Negative (TN):</strong> Model predicted negative, was actually negative.</li>
</ul>
<aside class="notes">
<p>Most of the performance measures we’ll discuss are derived from the confusion matrix. For simplicity, we often analyze binary classification or evaluate a single class as “positive” against all others. For instance, in a system detecting defects (<code>positive</code>), a True Positive means the system correctly identified a defect. A False Positive means it flagged a non-defect as a defect (a false alarm). A False Negative means it missed a defect (a critical failure). A True Negative means it correctly identified a non-defect. The implications of FP vs.&nbsp;FN can vary greatly across ECE applications; e.g., in medical diagnosis, FN is often more critical than FP, while in spam detection, FP might be more annoying than FN.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="accuracy" class="slide level2">
<h2>Accuracy</h2>
<ul>
<li>The fraction of all predictions that a classification model got right.</li>
<li>Simply the sum of True Positives and True Negatives, divided by the total.</li>
</ul>
<p><span class="math display">\[ \text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}} \]</span></p>

<img data-src="04_res/accuracy.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><aside class="notes">
<p>Accuracy seems like a straightforward measure, but it can be misleading, especially with imbalanced datasets. Imagine a system trying to detect a rare fault in an industrial machine that occurs only 1% of the time. If our model simply predicts “no fault” all the time, it would achieve 99% accuracy, but it would completely fail to detect any actual faults. In ECE, relying solely on accuracy for rare event detection, like critical system failures or cybersecurity intrusions, can be very dangerous. This is why we need more nuanced metrics.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="motivation-for-precision" class="slide level2">
<h2>Motivation for Precision</h2>
<p>When the model predicted positive, how often was it correct?</p>
<p><em>What is the probability that a detected anomaly in our sensor data is an </em>actual* anomaly, given that our model flagged it?*</p>
<aside class="notes">
<p>In many ECE scenarios, precision is crucial. For example, in a robotic arm that picks up defective items, high precision means fewer good items are accidentally discarded (fewer false positives). While accuracy might be high, if the FP rate is unacceptably high, it leads to waste or unnecessary actions. Precision directly answers the question: “Of all the times the model said ‘yes,’ how many times was it actually ‘yes’?”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="precision" class="slide level2">
<h2>Precision</h2>
<ul>
<li>The fraction of <strong>correct</strong> positive predictions out of <strong>all</strong> positive predictions made by the model.</li>
</ul>
<p><span class="math display">\[ \text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}} \]</span></p>

<img data-src="04_res/precision.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><aside class="notes">
<p>Precision focuses on the accuracy of positive predictions. A high precision indicates a low rate of false positives. In ECE, high precision is desirable in applications where false alarms are costly or disruptive. Consider a system for chip manufacturing QA: discarding a good chip because it was misclassified as defective is costly. Here, precision helps minimize such errors. Precision of 1 means every time the model said “positive,” it was truly positive, but it doesn’t tell us if it missed any actual positives.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="motivation-for-recall" class="slide level2">
<h2>Motivation for Recall</h2>
<p>Out of all the actual positive cases, how many did the model correctly identify?</p>
<p><em>What is the probability that our model will detect a ‘critical’ electromagnetic interference event, given that it </em>actually occurred<em>?</em></p>
<aside class="notes">
<p>Recall addresses a different but equally important question: “Of all the actual ‘yes’ cases, how many did the model find?” In safety-critical ECE applications, missing an actual positive (a false negative) can be devastating. This is where recall shines.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="recall" class="slide level2">
<h2>Recall</h2>
<ul>
<li>The fraction of <strong>correct</strong> positive predictions out of <strong>all actual</strong> positive cases.</li>
</ul>
<p><span class="math display">\[ \text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}} \]</span></p>

<img data-src="04_res/recall.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><aside class="notes">
<p>Recall, also known as sensitivity or true positive rate, is about how complete the model’s positive detections are. A high recall means a low rate of false negatives. In ECE, high recall is crucial for applications where missing a positive event is more detrimental than a false alarm. Examples include detecting equipment failures, security breaches, or health monitoring systems where failing to detect a critical condition is unacceptable. A recall of 1 means the model caught every single positive instance, but it doesn’t say anything about how many false positives it had along the way.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="precision-vs.-recall-a-trade-off" class="slide level2">
<h2>Precision vs.&nbsp;Recall: A Trade-Off</h2>

<img data-src="04_res/tug_of_war.jpg" class="r-stretch quarto-figure-center"><p class="caption">center</p><ul>
<li>Increasing one often decreases the other.</li>
<li>The optimal balance depends on the application’s cost of FP vs.&nbsp;FN.</li>
</ul>
<aside class="notes">
<p>Balancing precision and recall is often a “tug-of-war.” If you want to increase recall (catch more positives), you might lower your decision threshold, potentially increasing false positives and thus lowering precision. Conversely, if you want to increase precision (be more certain of your positives), you’d raise the threshold, which might cause you to miss some actual positives, lowering recall. Finding the optimal point where these two metrics are acceptable for your specific ECE application is critical. For instance, in a fire detection system, high recall is paramount, even if it means some false alarms (lower precision).</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="f1-score" class="slide level2">
<h2>F1 Score</h2>
<ul>
<li>The harmonic mean of precision and recall.</li>
<li>High F1 indicates both precision and recall are high.</li>
</ul>
<p><span class="math display">\[ F_1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}} \]</span></p>

<img data-src="04_res/f1.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><aside class="notes">
<p>The F1 score provides a single metric that balances both precision and recall. It’s particularly useful when you have an uneven class distribution, as it penalizes models that favor one metric over the other. The harmonic mean gives more weight to lower values, meaning a model needs both good precision and good recall to achieve a high F1 score. It’s a common metric when you need a general measure of a model’s effectiveness in ECE applications where both missing events and false alarms are important to manage.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="f1-score-simplified" class="slide level2">
<h2>F1 Score: Simplified</h2>
<p>The F1 formula can be reduced to:</p>
<p><span class="math display">\[ F_1 = \frac{2 \cdot \text{TP}}{2 \cdot \text{TP} + \text{FP} + \text{FN}} \]</span></p>

<img data-src="04_res/f1_optimized.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><aside class="notes">
<p>This simplified form of the F1 score can be directly calculated from the True Positives, False Positives, and False Negatives, making it convenient for quick computations.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="interactive-metric-calculator" class="slide level2">
<h2>Interactive Metric Calculator</h2>
<p>Adjust the True Positives, False Positives, False Negatives, and True Negatives to see how Accuracy, Precision, Recall, and F1 Score change.</p>
<div class="cell">
<div class="code-copy-outer-scaffold"><div class="sourceCode cell-code hidden" id="cb1" data-startfrom="318" data-source-offset="-31"><pre class="sourceCode numberSource js number-lines code-with-copy"><code class="sourceCode javascript" style="counter-reset: source-line 317;"><span id="cb1-318"><a></a>viewof tp_val <span class="op">=</span> Inputs<span class="op">.</span><span class="fu">range</span>([<span class="dv">0</span><span class="op">,</span> <span class="dv">100</span>]<span class="op">,</span> {<span class="dt">value</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span> <span class="dt">step</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">"True Positives (TP)"</span>})<span class="op">;</span></span>
<span id="cb1-319"><a></a>viewof fp_val <span class="op">=</span> Inputs<span class="op">.</span><span class="fu">range</span>([<span class="dv">0</span><span class="op">,</span> <span class="dv">100</span>]<span class="op">,</span> {<span class="dt">value</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span> <span class="dt">step</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">"False Positives (FP)"</span>})<span class="op">;</span></span>
<span id="cb1-320"><a></a>viewof fn_val <span class="op">=</span> Inputs<span class="op">.</span><span class="fu">range</span>([<span class="dv">0</span><span class="op">,</span> <span class="dv">100</span>]<span class="op">,</span> {<span class="dt">value</span><span class="op">:</span> <span class="dv">8</span><span class="op">,</span> <span class="dt">step</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">"False Negatives (FN)"</span>})<span class="op">;</span></span>
<span id="cb1-321"><a></a>viewof tn_val <span class="op">=</span> Inputs<span class="op">.</span><span class="fu">range</span>([<span class="dv">0</span><span class="op">,</span> <span class="dv">100</span>]<span class="op">,</span> {<span class="dt">value</span><span class="op">:</span> <span class="dv">90</span><span class="op">,</span> <span class="dt">step</span><span class="op">:</span> <span class="dv">1</span><span class="op">,</span> <span class="dt">label</span><span class="op">:</span> <span class="st">"True Negatives (TN)"</span>})<span class="op">;</span></span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-1" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-2" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-3" data-nodetype="declaration">

</div>
</div>
</div>
<div class="cell-output cell-output-display">
<div>
<div id="ojs-cell-1-4" data-nodetype="declaration">

</div>
</div>
</div>
</div>
<div>
<div id="pyodide-1" class="exercise-cell">

</div>
<script type="pyodide-1-contents">
eyJhdHRyIjp7ImVkaXQiOnRydWUsImV2YWwiOnRydWUsImlucHV0IjpbInRwX3ZhbCIsImZwX3ZhbCIsImZuX3ZhbCIsInRuX3ZhbCJdfSwiY29kZSI6IlxuaW1wb3J0IHBsb3RseS5ncmFwaF9vYmplY3RzIGFzIGdvXG5pbXBvcnQgbnVtcHkgYXMgbnBcblxudHAgPSB0cF92YWxcbmZwID0gZnBfdmFsXG5mbiA9IGZuX3ZhbFxudG4gPSB0bl92YWxcblxuIyBDYWxjdWxhdGUgbWV0cmljc1xudG90YWwgPSB0cCArIGZwICsgZm4gKyB0blxuXG5hY2N1cmFjeSA9ICh0cCArIHRuKSAvIHRvdGFsIGlmIHRvdGFsID4gMCBlbHNlIDBcbnByZWNpc2lvbiA9IHRwIC8gKHRwICsgZnApIGlmICh0cCArIGZwKSA+IDAgZWxzZSAwXG5yZWNhbGwgPSB0cCAvICh0cCArIGZuKSBpZiAodHAgKyBmbikgPiAwIGVsc2UgMFxuZjEgPSAoMiAqIHByZWNpc2lvbiAqIHJlY2FsbCkgLyAocHJlY2lzaW9uICsgcmVjYWxsKSBpZiAocHJlY2lzaW9uICsgcmVjYWxsKSA+IDAgZWxzZSAwXG5cbm1ldHJpY3MgPSB7XG4gICAgJ0FjY3VyYWN5JzogYWNjdXJhY3ksXG4gICAgJ1ByZWNpc2lvbic6IHByZWNpc2lvbixcbiAgICAnUmVjYWxsJzogcmVjYWxsLFxuICAgICdGMSBTY29yZSc6IGYxXG59XG5cbm1ldHJpY19uYW1lcyA9IGxpc3QobWV0cmljcy5rZXlzKCkpXG5tZXRyaWNfdmFsdWVzID0gbGlzdChtZXRyaWNzLnZhbHVlcygpKVxuXG5maWcgPSBnby5GaWd1cmUoZGF0YT1bZ28uQmFyKHg9bWV0cmljX25hbWVzLCB5PW1ldHJpY192YWx1ZXMsIFxuICAgICAgICAgICAgICAgICAgICAgICAgICAgICB0ZXh0PVtmJ3t2Oi4yZn0nIGZvciB2IGluIG1ldHJpY192YWx1ZXNdLCBcbiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgdGV4dHBvc2l0aW9uPSdhdXRvJyxcbiAgICAgICAgICAgICAgICAgICAgICAgICAgICAgbWFya2VyX2NvbG9yPVsnYmx1ZScsICdncmVlbicsICdvcmFuZ2UnLCAncmVkJ10pXSlcbmZpZy51cGRhdGVfbGF5b3V0KFxuICAgIHRpdGxlX3RleHQ9J0NsYXNzaWZpY2F0aW9uIE1ldHJpY3MnLFxuICAgIHlheGlzPWRpY3QocmFuZ2U9WzAsIDEuMDVdKSxcbiAgICBtYXJnaW49ZGljdChsPTAsIHI9MCwgYj0wLCB0PTMwKSwgIyBBZGp1c3QgbWFyZ2lucyBmb3IgYmV0dGVyIGZpdFxuICAgIGhlaWdodD00MDAsXG4gICAgc2hvd2xlZ2VuZD1GYWxzZVxuKVxuZmlnIn0=
</script>
</div>
<aside class="notes">
<p>This interactive tool allows you to directly manipulate the components of a confusion matrix and observe their impact on the key classification metrics. By adjusting the sliders, you can simulate different model behaviors and gain an intuitive understanding of how True Positives, False Positives, False Negatives, and True Negatives affect Accuracy, Precision, Recall, and the F1 Score. This hands-on experience is crucial for ECE students to grasp the trade-offs involved in designing and evaluating ML systems.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="which-metric-do-i-use" class="slide level2">
<h2>Which Metric Do I Use?</h2>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p>The answer is always: it depends on your specific ECE application!</p>
</div>
</div>
</div>
<ul>
<li><strong>Accuracy:</strong> Rarely a sufficient standalone metric, especially with imbalanced classes.</li>
<li><strong>Precision:</strong> Crucial when False Positives are costly (e.g., discarding good products in QA, false alarms in security).</li>
<li><strong>Recall:</strong> Critical when False Negatives are costly (e.g., missing a fault in critical infrastructure, failing to detect a disease).</li>
<li><strong>F1 Score:</strong> A good general measure when you need to balance both precision and recall, particularly with imbalanced datasets.</li>
</ul>
<aside class="notes">
<p>Just remember, there’s no single “best” metric. In ECE, the choice depends heavily on the cost associated with different types of errors. In some contexts, a false positive might just be an annoyance, while in others (like a medical diagnosis or a safety system), it could lead to significant financial loss or danger. Conversely, a false negative in a critical fault detection system could lead to catastrophic equipment failure. Always consider the real-world consequences of your model’s mistakes when choosing which metrics to prioritize. Later, we’ll discuss more advanced measures and graphical tools that help provide a more complete picture.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="confusion-matrix-example" class="slide level2">
<h2>Confusion Matrix Example</h2>
<p><strong>Scenario:</strong> A model predicts if a tumor is malignant. <em>(Positive Class: Malignant, Negative Class: Benign)</em></p>

<img data-src="04_res/confusion_matrix_tumor1.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><aside class="notes">
<p>Let’s practice calculating these metrics using a concrete example. Focus on a model designed to predict if a tumor is malignant. A “positive” outcome from the model means it predicts the tumor is malignant. We will walk through the components of the confusion matrix again with this scenario in mind. Remember: - True Positive: Model said malignant, and it <em>was</em> malignant. - True Negative: Model said benign, and it <em>was</em> benign. - False Positive: Model said malignant, but it <em>was</em> benign (Type I error - false alarm, patient undergoes unnecessary procedure). - False Negative: Model said benign, but it <em>was</em> malignant (Type II error - dangerous miss, patient doesn’t get treatment).</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="confusion-matrix-example-data" class="slide level2">
<h2>Confusion Matrix Example: Data</h2>
<p><strong>Model to predict if a tumor is malignant</strong></p>

<img data-src="04_res/confusion_matrix_tumor2.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><p>Given these values: - TP = 1 - FP = 1 - FN = 8 - TN = 90</p>
<p><strong>Total predictions = 100</strong></p>
<aside class="notes">
<p>Now, given these specific counts from our tumor prediction model, take a few minutes to calculate the Accuracy, Precision, Recall, and F1 score on your own. Think about what each value means in the context of tumor detection before we reveal the solutions on the next slides.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="solution-accuracy" class="slide level2">
<h2>Solution: Accuracy</h2>
<p><strong><span class="math display">\[\text{Accuracy} = \frac{1 + 90}{1 + 1 + 8 + 90} = \frac{91}{100} = 0.91\]</span></strong></p>

<img data-src="04_res/confusion_matrix_tumor_accuracy.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><aside class="notes">
<p>As you can see, the accuracy is 91%. This looks quite good on its own. However, let’s see how the other metrics inform our understanding of this model. Remember our earlier discussion about accuracy with imbalanced datasets and the potential for false confidence.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="solution-precision" class="slide level2">
<h2>Solution: Precision</h2>
<p><strong><span class="math display">\[\text{Precision} = \frac{1}{1 + 1} = \frac{1}{2} = 0.50\]</span></strong></p>

<img data-src="04_res/confusion_matrix_tumor_precision.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><aside class="notes">
<p>The precision is 0.50, or 50%. This means that when the model predicts a tumor is malignant, it’s only correct half the time. While the overall accuracy was high, the model frequently gives false alarms for malignancy. This would lead to many patients undergoing potentially stressful and invasive follow-up tests unnecessarily.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="solution-recall" class="slide level2">
<h2>Solution: Recall</h2>
<p><strong><span class="math display">\[\text{Recall} = \frac{1}{1 + 8} = \frac{1}{9} \approx 0.11\]</span></strong></p>

<img data-src="04_res/confusion_matrix_tumor_recall.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><aside class="notes">
<p>The recall is approximately 0.11, or 11%. This is a very low recall score. It means the model only correctly identifies about 11% of the actual malignant tumors. In this medical context, missing 89% of malignant tumors (false negatives) is a severe problem. This highlights a critical failure of the model despite its seemingly high accuracy. Without surgical intervention, the consequences of a malignant tumor would be dire.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="solution-f1-score" class="slide level2">
<h2>Solution: F1 Score</h2>
<p><strong><span class="math display">\[ F_1 = \frac{2 \cdot 0.50 \cdot 0.11}{0.50 + 0.11} = \frac{0.11}{0.61} \approx 0.18 \]</span></strong></p>
<p><em>(Or, using the simplified formula: <span class="math display">\[ F_1 = \frac{2 \cdot 1}{2 \cdot 1 + 1 + 8} = \frac{2}{11} \approx 0.18 \]</span>)</em></p>

<img data-src="04_res/confusion_matrix_tumor_f1.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><aside class="notes">
<p>The F1 score is very low, approximately 0.18. This low F1 score correctly reflects the poor performance of the model by penalizing the low recall, despite the relatively high precision (0.50) and high accuracy (0.91). This example vividly demonstrates why looking at all metrics, especially F1, is crucial and why relying solely on accuracy can be misleading in applications where class imbalance or the cost of different error types is significant.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="weather-prediction" class="slide level2">
<h2>Weather Prediction</h2>
<p><strong>Scenario:</strong> Predict “Rain” or “No Rain”.</p>

<img data-src="04_res/weather.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><p><strong>Create a Confusion Matrix</strong> from this data.</p>
<aside class="notes">
<p>Here’s another chance to practice. Given this weather prediction scenario for a week, where ‘R’ denotes Rain and ‘NR’ denotes No Rain, first, construct the confusion matrix based on the model’s predictions versus the actual weather.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="your-turn-calculate-metrics" class="slide level2">
<h2>Your Turn: Calculate Metrics</h2>
<p>Now that you have constructed the confusion matrix for the weather prediction:</p>
<ul>
<li><strong>Accuracy</strong> = ?</li>
<li><strong>Precision</strong> = ?</li>
<li><strong>Recall</strong> = ?</li>
<li><strong>F1 Score</strong> = ?</li>
</ul>
<aside class="notes">
<p>Once you’ve built the confusion matrix, calculate the Accuracy, Precision, Recall, and F1 Score. Take a few moments to work through these.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="solution-weather-prediction" class="slide level2">
<h2>Solution: Weather Prediction</h2>

<img data-src="04_res/weather_solution.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><p><strong>Confusion Matrix:</strong> - <strong>TP (Actual Rain, Predicted Rain):</strong> 2 - <strong>FP (Actual No Rain, Predicted Rain):</strong> 1 - <strong>FN (Actual Rain, Predicted No Rain):</strong> 1 - <strong>TN (Actual No Rain, Predicted No Rain):</strong> 3</p>
<p><strong>Metrics:</strong> - <strong>Accuracy:</strong> (2+3) / (2+1+1+3) = 5/7 = 0.714 - <strong>Precision:</strong> 2 / (2+1) = 2/3 = 0.667 - <strong>Recall:</strong> 2 / (2+1) = 2/3 = 0.667 - <strong>F1 Score:</strong> (2 * 0.667 * 0.667) / (0.667 + 0.667) = 0.667</p>
<aside class="notes">
<p>Here are the solutions. This example shows a more balanced performance compared to the tumor prediction model, where all metrics are relatively consistent around two-thirds. This indicates a more even-handed performance from the classifier.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="graphical-measurements-for-classification" class="slide level2">
<h2>Graphical Measurements for Classification</h2>
<p>Beyond single scalar metrics, graphical tools offer deeper insights into model performance across different decision thresholds.</p>
</section>
<section id="precision-vs.-recall-curve" class="slide level2">
<h2>Precision vs.&nbsp;Recall Curve</h2>

<img data-src="04_res/precision_recall_curve.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><ul>
<li>Plots Precision against Recall for different threshold values.</li>
<li>Helps select an optimal operating point based on FP/FN costs.</li>
</ul>
<aside class="notes">
<p>The Precision-Recall curve visualizes the trade-off. Each point on the curve represents the precision and recall achievable at a specific classification threshold. For example, if your ECE system needs extremely high precision (e.g., avoiding false alarms for a critical alert), you might choose an operating point far to the right on the curve, even if it means lower recall. Conversely, if high recall is paramount (e.g., never missing a faulty component), you would choose a point further to the left, accepting more false positives. This curve is especially useful when one class is significantly rarer than the other, and helps you tune your ML model for the specific operational constraints of your ECE application.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="receiver-operating-characteristic-roc-curve" class="slide level2">
<h2>Receiver Operating Characteristic (ROC) Curve</h2>

<img data-src="04_res/roc_curve.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><ul>
<li>Plots True Positive Rate (Recall) against False Positive Rate.</li>
<li>Helps compare models across all possible thresholds.</li>
</ul>
<aside class="notes">
<p>Another powerful graphical tool is the ROC curve. It plots the True Positive Rate, which is identical to Recall, against the False Positive Rate for various sensitivity thresholds. The False Positive Rate quantifies how many negative instances the model incorrectly classified as positive. A perfect classifier would reach the top-left corner (100% TPR, 0% FPR). The dotted line represents a random classifier.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="roc-curve-true-positive-rate-tpr-recall" class="slide level2">
<h2>ROC Curve: True Positive Rate (TPR) / Recall</h2>
<p><span class="math display">\[ \text{TPR (Recall)} = \frac{\text{TP}}{\text{TP} + \text{FN}} \]</span></p>

<img data-src="04_res/recall.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><aside class="notes">
<p>The Y-axis of the ROC curve is the True Positive Rate, which is simply our familiar Recall. It tells us, out of all actual positive cases, what fraction the model correctly identified.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="roc-curve-false-positive-rate-fpr" class="slide level2">
<h2>ROC Curve: False Positive Rate (FPR)</h2>
<p><span class="math display">\[ \text{FPR} = \frac{\text{FP}}{\text{FP} + \text{TN}} \]</span></p>

<img data-src="04_res/specificity.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><ul>
<li>FPR is 1 minus the True Negative Rate (Specificity).</li>
<li>Measures how many actual negative examples were falsely predicted as positive.</li>
</ul>
<aside class="notes">
<p>The X-axis of the ROC curve is the False Positive Rate. This is 1 minus Specificity, where Specificity is the True Negative Rate. FPR indicates the proportion of actual negative cases that were incorrectly classified as positive. So, if we have a system for detecting anomalies, a high FPR means we get a lot of false alarms from normal operations.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="interpreting-the-roc-curve" class="slide level2">
<h2>Interpreting the ROC Curve</h2>

<img data-src="04_res/roc_curve.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><ul>
<li><strong>TPR (Y-axis):</strong> Proportion of actual positives correctly identified.</li>
<li><strong>FPR (X-axis):</strong> Proportion of actual negatives incorrectly identified as positive.</li>
<li><strong>Dotted Line:</strong> Represents a random classifier (AUC = 0.5).</li>
<li><strong>Area Under Curve (AUC):</strong> Single scalar metric to summarize the curve.
<ul>
<li>AUC near 1.0 indicates excellent discriminative power.</li>
<li>AUC near 0.5 suggests poor or random classification.</li>
</ul></li>
</ul>
<aside class="notes">
<p>An ideal ROC curve hugs the top-left corner, signifying high TPR and low FPR across various thresholds. The Area Under the Curve (AUC) provides a single value summary of the model’s performance across all possible classification thresholds. An AUC of 1.0 is a perfect classifier, while 0.5 is no better than random guessing. AUC is a robust metric for comparing different models, especially when the class distribution is balanced or when the cost of FP and FN is similar. In ECE, AUC is commonly used for evaluating diagnostic systems, anomaly detection, and classification problems where overall discriminative ability is key, regardless of a specific operating point initially.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="binary-classification" class="slide level2">
<h2>Binary Classification</h2>
<aside class="notes">
<p>Now that we’ve covered the basics of classification and its evaluation, let’s dive into the simplest form: <strong>binary classification</strong>. This is fundamental and forms the building block for more complex multi-class problems.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="binary-classification-two-outcomes" class="slide level2">
<h2>Binary Classification: Two Outcomes</h2>

<img data-src="04_res/yes_or_no.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><ul>
<li>Predicts one of two discrete values or states.</li>
<li>Commonly encoded as 0 or 1.</li>
<li>Examples:
<ul>
<li>Spam / Not Spam</li>
<li>Fault / No Fault</li>
<li>Signal Present / Signal Absent</li>
<li>Pass / Fail for product testing</li>
</ul></li>
</ul>
<aside class="notes">
<p>Binary classification problems involve predicting one of only two possible outcomes. These outcomes are often represented as a positive class (e.g., 1) and a negative class (e.g., 0). In ECE, binary classification is ubiquitous. Think of a sensor determining if a component’s temperature is “over threshold” or “normal,” a communications system detecting if a packet contains “error” or “no error,” or an embedded system classifying a touch input as “press” or “release.”</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="binary-classification-common-models" class="slide level2">
<h2>Binary Classification: Common Models</h2>
<ul>
<li><strong>Logistic Regression:</strong> Transforms linear regression output into a probability (0-1).</li>
<li><strong>Decision Trees &amp; Random Forests:</strong> Can naturally split data into two categories.</li>
<li><strong>Support Vector Machines (SVM):</strong> Finds an optimal hyperplane to separate classes with the largest margin.</li>
<li><strong>Bayesian Networks:</strong> Probabilistic graphical models used for classification.</li>
<li><strong>Neural Networks:</strong> Highly versatile, learn complex non-linear boundaries.</li>
</ul>
<aside class="notes">
<p>Many different machine learning models can be adapted for binary classification. Each has its own strengths and weaknesses regarding computational complexity, interpretability, and ability to handle different data distributions. We will explore several of these throughout the course. For an ECE context, the choice often depends on the available computational resources on a chip or embedded system, the latency requirements, and the complexity of the decision boundary needed.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="binary-classification-logistic-regression-example" class="slide level2">
<h2>Binary Classification: Logistic Regression Example</h2>

<img data-src="04_res/classification.gif" class="r-stretch quarto-figure-center"><p class="caption">center</p><ul>
<li>Finds a <strong>logistic function</strong> to separate two classes.</li>
<li>Outputs a probability value (0-1) which is then thresholded for classification.</li>
<li>Relatively easy to interpret.</li>
</ul>
<aside class="notes">
<p>In the upcoming lab, we will build a logistic regression model. This algorithm is particularly useful for binary classification. It applies a sigmoid function to the output of a linear model, squeezing the result into a range between 0 and 1, which can be interpreted as a probability. You can then set a threshold (e.g., 0.5) to classify points. While straightforward, it performs best when the data is linearly separable or can be made so with feature engineering. This is a good starting point for many ECE tasks due to its computational efficiency.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="lab-preview-fruit-classification" class="slide level2">
<h2>Lab Preview: Fruit Classification</h2>

<img data-src="04_res/oranges_and_grapefruit.jpg" class="r-stretch quarto-figure-center"><p class="caption">center</p><ul>
<li><strong>Objective:</strong> Differentiate between oranges and grapefruit.</li>
<li><strong>Dataset:</strong> Contains features like weight, size, and color.</li>
<li><strong>Model:</strong> We will build a logistic regression model.</li>
</ul>
<aside class="notes">
<p>In our hands-on lab, you’ll tackle a binary classification problem: distinguishing between oranges and grapefruits. We’ll utilize a dataset rich with physical characteristics like weight, size, and color. This is a practical example of how classification can be used in areas like automated sorting systems in agriculture or quality control in food processing, which are relevant to ECE.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="lab-preview-hyperparameter-tuning-with-grid-search" class="slide level2">
<h2>Lab Preview: Hyperparameter Tuning with Grid Search</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a>search <span class="op">=</span> GridSearchCV(model, {</span>
<span id="cb2-2"><a></a>  <span class="st">'learning_rate'</span>: [<span class="fl">1e-3</span>, <span class="fl">1e-4</span>],</span>
<span id="cb2-3"><a></a>  <span class="st">'max_iter'</span>: [<span class="dv">10000</span>, <span class="dv">15000</span>],</span>
<span id="cb2-4"><a></a>  <span class="st">'C'</span>: <span class="dv">1</span>,</span>
<span id="cb2-5"><a></a>})</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Grid Search:</strong> Systematically explores a combination of hyperparameters.</li>
<li>Helps find the best parameter settings for your model.</li>
<li>Can be computationally intensive, especially with many parameters.</li>
</ul>
<aside class="notes">
<p>In the lab, you’ll also encounter <code>GridSearchCV</code>, a powerful technique for hyperparameter tuning. Instead of manually trying different <code>learning_rate</code> or <code>max_iter</code> values, Grid Search automates this process. It tries every possible combination of the provided hyperparameter values, trains a model for each combination, and evaluates its performance to find the optimal set. While incredibly useful for robust model development, remember that the number of combinations grows factorially, which can make it time-consuming, especially for complex ECE models running on limited embedded hardware.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="lab-preview-confusion-matrix-generation" class="slide level2">
<h2>Lab Preview: Confusion Matrix Generation</h2>

<img data-src="04_res/Classification1.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><ul>
<li>You will generate your first confusion matrix.</li>
<li>Visualizing TP, FP, FN, TN for your fruit classifier.</li>
</ul>
<aside class="notes">
<p>Finally, the lab will guide you through creating your first confusion matrix, just like we discussed earlier. This will allow you to see the real-world performance of your logistic regression model on the fruit classification task and apply the metrics we’ve learned today.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="your-turn-binary-classification-lab" class="slide level2">
<h2>Your Turn: Binary Classification Lab</h2>
<p>Let’s apply these concepts and build a binary classifier!</p>
<aside class="notes">
<p>Now it’s time to put what you’ve learned into practice! Head over to the lab environment to begin working on the binary classification exercise.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="multiclass-classification" class="slide level2">
<h2>Multiclass Classification</h2>
<aside class="notes">
<p>Moving beyond two categories, we now explore scenarios where models must distinguish between more than two distinct classes—a common occurrence in many advanced ECE applications.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="multiclass-classification-many-outcomes" class="slide level2">
<h2>Multiclass Classification: Many Outcomes</h2>

<img data-src="04_res/yesno_yesno.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><ul>
<li>Classification problems with <strong>more than two</strong> classes.</li>
<li>Examples:
<ul>
<li>Digit recognition (0-9)</li>
<li>Speech command recognition (e.g., “activate,” “mute,” “volume up”)</li>
<li>Modulation scheme identification (e.g., BPSK, QPSK, 16-QAM)</li>
<li>Component type classification</li>
</ul></li>
</ul>
<aside class="notes">
<p>“Multiclass classification” refers to problems where a data point needs to be assigned to one of several possible categories. This is distinct from binary classification, which handles only two categories. In ECE, multi-class problems are prevalent: classifying different types of electrical faults, recognizing multiple speech commands for a microcontroller, identifying different types of cybersecurity attacks, or classifying different materials using sensor data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="multiclass-strategies-one-vs-all-ova-one-vs-one-ovo" class="slide level2">
<h2>Multiclass Strategies: One-vs-All (OvA) &amp; One-vs-One (OvO)</h2>
<ul>
<li><strong>One-vs-All (OvA):</strong>
<ul>
<li>Trains <code>k</code> binary classifiers for <code>k</code> classes.</li>
<li>Each classifier distinguishes <em>one class</em> from <em>all others</em>.</li>
<li>Final prediction is the class with the highest confidence.</li>
</ul></li>
<li><strong>One-vs-One (OvO):</strong>
<ul>
<li>Trains <code>k * (k-1) / 2</code> binary classifiers.</li>
<li>Each classifier distinguishes <em>one class</em> from <em>another specific class</em>.</li>
<li>Final prediction is derived by a voting scheme among classifiers.</li>
</ul></li>
</ul>
<aside class="notes">
<p>Many binary classification algorithms can be extended to handle multi-class problems using strategies like One-vs-All (OvA) or One-vs-One (OvO). OvA is simpler: for each class, you train a binary classifier to decide if an instance belongs to <em>that specific class</em> or <em>any other class</em>. OvO is more complex, training a binary classifier for every unique pair of classes, and then aggregating their votes. While often hidden from the user in modern ML libraries, understanding these strategies helps in debugging and selecting appropriate models, especially in resource-constrained ECE systems where computational efficiency matters. Some models, like Decision Trees, naturally handle multiple classes without needing these decomposition strategies.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="lab-preview-the-iris-dataset" class="slide level2">
<h2>Lab Preview: The Iris Dataset</h2>

<img data-src="04_res/iris.jpg" class="r-stretch quarto-figure-center"><p class="caption">center</p><ul>
<li><strong>Classic ML Dataset:</strong> Widely used for multiclass classification.</li>
<li><strong>Features:</strong> Sepal length, sepal width, petal length, petal width.</li>
<li><strong>Target:</strong> Three species of Iris flowers (Setosa, Versicolor, Virginica).</li>
</ul>
<aside class="notes">
<p>For our multiclass classification lab, we’ll use the famous Iris dataset. This dataset is a cornerstone in machine learning and provides a perfect example for practicing multi-class problems. The features are physical measurements of different parts of the flower, and the goal is to classify the species. This type of problem is analogous to classifying different types of electronic components based on their physical or electrical characteristics, which could be relevant in automated manufacturing and quality control in ECE.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="lab-preview-cross-fold-validation" class="slide level2 scrollable">
<h2>Lab Preview: Cross-Fold Validation</h2>

<img data-src="04_res/cross_fold.png" class="r-stretch quarto-figure-center"><p class="caption">center</p><ol type="1">
<li><strong>Shuffle</strong> data.</li>
<li><strong>Split</strong> into <code>k</code> groups (folds).</li>
<li><strong>Iterate <code>k</code> times:</strong>
<ul>
<li>Use <strong>one fold</strong> as test set.</li>
<li>Use <strong>remaining <code>k-1</code> folds</strong> as training set.</li>
<li><strong>Train</strong> model on training data.</li>
<li><strong>Evaluate</strong> on test data and record performance.</li>
</ul></li>
<li><strong>Average</strong> performance metrics across <code>k</code> iterations.</li>
</ol>
<aside class="notes">
<p>In this lab, we’ll also introduce <strong>cross-fold validation</strong>. This technique is crucial for robust model evaluation, especially with smaller datasets, as it ensures that your model’s performance isn’t just an artifact of a particular train-test split. By repeatedly partitioning your data and evaluating the model, you get a much more reliable estimate of its generalization performance. For ECE applications, this means you can be more confident that a model trained in the lab will perform similarly when deployed in real-world conditions, preventing unexpected behavior in critical systems.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="lab-preview-wine-producer-identification" class="slide level2">
<h2>Lab Preview: Wine Producer Identification</h2>

<img data-src="04_res/wine.jpg" class="r-stretch quarto-figure-center"><p class="caption">center</p><ul>
<li><strong>Challenge:</strong> Identify wine producers based on chemical properties.</li>
<li><strong>Dataset:</strong> Chemical analysis of different wines.</li>
<li><strong>Your Task:</strong> Apply your ML skills with minimal guidance.</li>
</ul>
<aside class="notes">
<p>For your final exercise in the lab, you’ll tackle another multiclass problem: identifying the producer of a wine based on its chemical composition. This exercise will provide less guidance, challenging you to independently apply the machine learning skills you’ve acquired. This scenario mirrors many real-world ECE problems where sensor data (e.g., from spectroscopy or chemical analysis) is used for classification tasks like material identification, quality control, or authentication.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="your-turn-multiclass-classification-lab" class="slide level2">
<h2>Your Turn: Multiclass Classification Lab</h2>
<p>Time to apply your knowledge to solve multiclass problems!</p>
<aside class="notes">
<p>You’ve now covered the theoretical foundations of multiclass classification and learned about powerful evaluation techniques like cross-fold validation. The lab awaits, where you’ll get hands-on experience with these concepts, culminating in a challenge to really test your machine learning prowess. Good luck!</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

</section></section>
<section>
<section id="classification-with-tensorflow" class="title-slide slide level1 center">
<h1>Classification with TensorFlow</h1>
<aside class="notes">
<p>We have performed binary and multiclass classification with scikit-learn. We’ll now use the TensorFlow toolkit to create a deep neural network that can perform classification. TensorFlow is a powerful open-source library developed by Google, widely used in ECE for advanced applications like image recognition, natural language processing, and embedded AI due to its flexibility and performance.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="dataset-uci-heart-disease" class="slide level2">
<h2>Dataset: UCI Heart Disease</h2>
<p><strong>Predicting the presence of heart disease</strong></p>
<div class="callout callout-note callout-titled callout-style-default">
<div class="callout-body">
<div class="callout-title">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<p><strong>Note</strong></p>
</div>
<div class="callout-content">
<p>This will be a <strong>binary classification</strong> problem: 0 = does not have heart disease 1 = has heart disease</p>
</div>
</div>
</div>
<aside class="notes">
<p>The dataset we’ll use is the UCI Heart Disease dataset. This dataset contains health information about patients, as well as a “presence of heart disease” indicator. This indicator is a 1 for “has heart disease” and 0 for “does not have heart disease.” As you can probably guess, the model that we will build will be a binary classification model. This medical application highlights the ethical and high-stakes nature of such predictions, relevant to bio-medical engineering aspects of ECE.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="dataset-features" class="slide level2">
<h2>Dataset: Features</h2>
<table class="caption-top">
<colgroup>
<col style="width: 2%">
<col style="width: 97%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>age</code></td>
<td>Age in years.</td>
</tr>
<tr class="even">
<td><code>sex</code></td>
<td>Sex (0 = female, 1 = male).</td>
</tr>
<tr class="odd">
<td><code>cp</code></td>
<td>Chest pain type (1 = typical angina, 2 = atypical angina, 3 = non-anginal pain, 4 = asymptomatic).</td>
</tr>
</tbody>
</table>
<aside class="notes">
<p>The dataset contains 13 features. ‘age’ is an integer value representing the patient’s age in years. ‘sex’ is a categorical column with zero representing female and one representing male. ‘cp’ stands for chest pain. It is a categorical column with the four values shown. These features are typical inputs for many data-driven ECE systems that process various sensor or clinical data.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="dataset-features-continued" class="slide level2">
<h2>Dataset: Features (continued)</h2>
<table class="caption-top">
<colgroup>
<col style="width: 2%">
<col style="width: 97%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>trestbps</code></td>
<td>Resting blood pressure in Hg.</td>
</tr>
<tr class="even">
<td><code>chol</code></td>
<td>Serum cholesterol in mg/dl.</td>
</tr>
<tr class="odd">
<td><code>fbs</code></td>
<td>Is fasting blood sugar &gt; 120 mg/dl (0 = false, 1 = true).</td>
</tr>
<tr class="even">
<td><code>restecg</code></td>
<td>Results of a resting electrocardiograph (0 = normal, 1 = ST-T wave abnormality, 2 = left ventricular hypertrophy).</td>
</tr>
</tbody>
</table>
<aside class="notes">
<p><code>trestbps</code> is the resting blood pressure of the patient upon admission to the hospital. <code>chol</code> is a variable representing cholesterol. <code>fbs</code> is a measure of fasting blood sugar, but it is represented as a categorical column that measures if blood sugar is over a threshold. <code>restecg</code> is a categorical column with the three values shown. These are physiological signals, often acquired through sensor arrays, that ECE engineers would be responsible for designing and processing.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="dataset-features-continued-1" class="slide level2">
<h2>Dataset: Features (continued)</h2>
<table class="caption-top">
<colgroup>
<col style="width: 1%">
<col style="width: 98%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>thalach</code></td>
<td>Max heart rate.</td>
</tr>
<tr class="even">
<td><code>exang</code></td>
<td>Exercise induced angina (0 = no, 1 = yes).</td>
</tr>
<tr class="odd">
<td><code>oldpeak</code></td>
<td>Measurement of an abnormal ST depression.</td>
</tr>
<tr class="even">
<td><code>slope</code></td>
<td>Slope of peak of exercise ST segment (1 = upslope, 2 = flat, 3 = downslope).</td>
</tr>
</tbody>
</table>
<aside class="notes">
<p>The next two columns have to do with an exercise stress test the patients completed. <code>thalach</code> is the maximum heart rate the patient achieved during the exercise session. <code>exang</code> is a categorical variable that lets us know if the exercise caused angina. <code>oldpeak</code> is a variable that measures ST depression. ST depression is a curve on an electrocardiogram graph where the ST segment line is very low when compared to a baseline. <code>slope</code> is a categorical variable that lets you know which direction the line was going at the peak exercise ST segment. These stress test parameters are derived from complex biomedical signal processing, a core area of ECE.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="dataset-features-continued-2" class="slide level2">
<h2>Dataset: Features (continued)</h2>
<table class="caption-top">
<colgroup>
<col style="width: 0%">
<col style="width: 99%">
</colgroup>
<thead>
<tr class="header">
<th>Feature</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>ca</code></td>
<td>Count of major blood vessels colored by fluoroscopy (0, 1, 2, 3, or 4).</td>
</tr>
<tr class="even">
<td><code>thal</code></td>
<td>Presence heart condition (0 = unknown, 1 = normal, 2 = fixed defect, 3 = reversible defect).</td>
</tr>
</tbody>
</table>
<aside class="notes">
<p><code>ca</code> is a count of major blood vessels colored by fluoroscopy. The values are 0, 1, 2, or 3, and are limited by biology, though occasionally 4 appears due to data quirks. <code>thal</code> relates to a heart defect, describing if it exists and its nature. You might notice the values on the slides for some of these columns differ from the documentation. For instance, the documentation for ‘ca’ states that the values range from 0-3, but there are 4s in the data. And the documentation for ‘thal’ says that the values are 3, 6, and 7, but the actual values in the data are 0, 1, 2, and 3. The takeaway from this is that you should always read the documentation, but you should also always look at the data and verify that the documentation is accurate. When there are questions, you should do research. If you are in contact with the source of the data, ask for clarification. Though documentation is great and can really help in data science, the dataset itself is the actual ground truth. This is a critical lesson for ECE engineers handling data from new sensors or instruments.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-model-output-layer-activation" class="slide level2">
<h2>The Model: Output Layer Activation</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a>    tf.keras.layers.Dense(<span class="dv">1</span>, activation<span class="op">=</span>tf.nn.sigmoid)</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li>For binary classification, the final layer typically has <strong>1 neuron</strong>.</li>
<li>Uses a <strong>sigmoid</strong> activation function.</li>
<li>Output range [0.0, 1.0] interpreted as prediction confidence.</li>
<li>Threshold determines final class.</li>
</ul>
<aside class="notes">
<p>The model in this lab won’t look too different from the TensorFlow Keras models we built for regression analysis. The primary difference is the final layer in the model. We want to create a binary prediction that will let us know if a patient has heart disease or not. If we stick with a ReLU activation function for the output, then there is no bound for the maximum output value, so it would be impossible to understand what the prediction confidence is. Instead, we’ll use an activation function that limits the output value. In this particular lab, we use a sigmoid function, so the output is limited to the range of 0.0 to 1.0. This output is then a measure of confidence that a patient has heart disease (since “has heart disease” is the 1.0 value). We can then decide how much confidence it takes to classify the patient as having heart disease. The choice of threshold is very important for model performance, and remember that we can measure performance at different thresholds with an ROC curve. This is directly applicable to digital circuit design for ML acceleration, where the choice of activation impacts hardware implementation efficiency.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-model-loss-function-optimizer" class="slide level2">
<h2>The Model: Loss Function &amp; Optimizer</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a>    model.<span class="bu">compile</span>(</span>
<span id="cb4-2"><a></a>        loss<span class="op">=</span><span class="st">'binary_crossentropy'</span>,</span>
<span id="cb4-3"><a></a>        optimizer<span class="op">=</span><span class="st">'Adam'</span>,</span>
<span id="cb4-4"><a></a>        metrics<span class="op">=</span>[<span class="st">'accuracy'</span>]</span>
<span id="cb4-5"><a></a>    )</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Loss Function:</strong> <code>binary_crossentropy</code> is standard for binary classification.</li>
<li><strong>Optimizer:</strong> <code>Adam</code> is an adaptive learning rate optimization algorithm.
<ul>
<li>Adjusts learning rate for each parameter, often faster convergence.</li>
</ul></li>
</ul>
<aside class="notes">
<p>How we measure loss is also very important. For binary classification problems, we need to use binary cross-entropy, which is specifically designed to quantify the difference between two probability distributions. Although we’ve talked a lot about using gradient descent for optimization, there are other methods as well. Adam is one of these methods. Adam uses an adaptive learning rate. That is, it uses a different learning rate for each of the different parameters in the model. This differs from stochastic gradient descent which uses a single learning rate for all parameters. While Adam often offers faster convergence, selecting the right optimizer is a non-trivial part of ECE machine learning, influencing training time and model accuracy on specialized hardware. A lot of research is being done to understand the conditions under which different optimizers perform better.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-model-early-stopping" class="slide level2">
<h2>The Model: Early Stopping</h2>
<div class="code-copy-outer-scaffold"><div class="sourceCode" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a></a>    tf.keras.callbacks.EarlyStopping(</span>
<span id="cb5-2"><a></a>        monitor<span class="op">=</span><span class="st">'loss'</span>,</span>
<span id="cb5-3"><a></a>        min_delta<span class="op">=</span><span class="fl">1e-3</span>,</span>
<span id="cb5-4"><a></a>        patience<span class="op">=</span><span class="dv">5</span>,</span>
<span id="cb5-5"><a></a>    )</span></code></pre></div><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></div>
<ul>
<li><strong>Purpose:</strong> Prevents overfitting and reduces training time.</li>
<li><strong>Mechanism:</strong> Stops training when a monitored metric (e.g., <code>loss</code>) stops improving significantly.
<ul>
<li><code>monitor='loss'</code>: Watches the validation loss.</li>
<li><code>min_delta=1e-3</code>: Minimum change in the monitored quantity to qualify as an improvement.</li>
<li><code>patience=5</code>: Number of epochs with no improvement after which training will be stopped.</li>
</ul></li>
</ul>
<aside class="notes">
<p>We’ll also visit early stopping in this lab. Early stopping is a model-fitting strategy where you monitor some metric - say, loss - and stop training when that metric doesn’t change enough across a number of epochs. In this example we monitor the validation loss and stop early if the loss hasn’t changed by at least 0.001 during any of the last five epochs. This technique is critical in practical ECE ML deployments to save computational resources and ensure the model generalizes well to unseen data, preventing wasted energy and time on embedded or cloud-based training platforms.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="your-turn-tensorflow-lab" class="slide level2">
<h2>Your Turn: TensorFlow Lab</h2>
<p>Now, it’s your turn to perform binary classification using TensorFlow Keras and deep neural networks!</p>
<aside class="notes">
<p>This lab will connect the theoretical concepts of classification with the powerful, industry-standard tools for deep learning. You’ll gain practical experience in building, training, and evaluating a neural network for a real-world ECE-relevant problem.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section class="slide level2">

</section></section>
<section>
<section id="classification-project-predicting-titanic-survivors" class="title-slide slide level1 center">
<h1>Classification Project: Predicting Titanic Survivors</h1>
<aside class="notes">
<p>In this project you will apply what you have learned about classification and TensorFlow to complete a project from Kaggle. This is a chance to consolidate your understanding and explore a full end-to-end ML pipeline.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="the-titanic-shipwreck-challenge" class="slide level2">
<h2>The Titanic Shipwreck Challenge</h2>

<img data-src="04_res/ship.jpg" class="r-stretch quarto-figure-center"><p class="caption">center</p><ul>
<li><strong>Goal:</strong> Achieve a high accuracy score in predicting passenger survival.</li>
<li><strong>Application:</strong> A canonical challenge for applying binary classification.</li>
</ul>
<aside class="notes">
<p>The challenge is to achieve a high accuracy score while trying to predict which passengers survived the Titanic shipwreck. This is a classic dataset for introductory machine learning due to its mix of numerical and categorical features, missing data, and clear binary classification target. It’s an excellent way to practice data preprocessing and feature engineering, skills directly transferable to ECE applications involving sensor data or system logs.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="review-types-of-classification" class="slide level2">
<h2>Review: Types of Classification</h2>
<p>What types of classification have we learned about?</p>
<aside class="notes">
<p>Let’s take a moment to review before diving into the project. What are the key categories of classification problems we’ve covered? (Expected answers: Binary classification, Multiclass classification). Can you give examples of when each is appropriate, perhaps from an ECE context? For instance, binary for fault detection (fault/no fault) and multiclass for identifying different types of signal modulation (e.g., PSK, FSK, QAM).</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="review-ml-tools-for-classification" class="slide level2">
<h2>Review: ML Tools for Classification</h2>
<p>What tools have we learned about for classification?</p>
<aside class="notes">
<p>We have learned many different models and tools for performing classification. What are some of those models and tools? (Expected answers: Scikit-learn (e.g., Logistic Regression), TensorFlow/Keras for Deep Neural Networks, concepts like OvO/OvA for multiclass conversion). Briefly explain a bit about each of the tools and when you might choose one over the other in an ECE scenario, considering factors like complexity, speed, and interpretability.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="review-evaluation-metrics" class="slide level2">
<h2>Review: Evaluation Metrics</h2>
<p>What metrics have we learned for evaluating classification models?</p>
<aside class="notes">
<p>Now, let’s talk about how we measure success. What are some of the evaluation metrics we’ve discussed for classification models? (Expected answers: Confusion Matrix, Accuracy, Precision, Recall, F1 Score, ROC Curve, AUC). Have students discuss what each metric measures and how we interpret them, emphasizing the importance of choosing the right metric based on the application’s cost function for FP and FN errors in ECE.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="review-other-useful-techniques" class="slide level2">
<h2>Review: Other Useful Techniques</h2>
<p>What other useful techniques have we learned, and what are they used for?</p>
<aside class="notes">
<p>We’ve covered a few other techniques that can be useful for model training and testing. Can you name a few and describe their purpose? (Expected answers: Hyperparameter tuning (e.g., Grid Search), Cross-validation, Early Stopping, Data preprocessing (normalization, encoding categorical features)). Discuss how these techniques contribute to building robust and generalized ML models for real-world ECE systems.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="classification-project-the-data" class="slide level2">
<h2>Classification Project: The Data</h2>
<table class="caption-top">
<thead>
<tr class="header">
<th>Column</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><code>Survived</code></td>
<td>number</td>
<td>1 or 0 ( <em>target</em> )</td>
</tr>
<tr class="even">
<td><code>Name</code></td>
<td>string</td>
<td>Passenger name</td>
</tr>
<tr class="odd">
<td><code>Pclass</code></td>
<td>number</td>
<td>Ticket class</td>
</tr>
<tr class="even">
<td><code>Sex</code></td>
<td>string</td>
<td>male or female</td>
</tr>
<tr class="odd">
<td><code>Age</code></td>
<td>number</td>
<td>Passenger age</td>
</tr>
<tr class="even">
<td><code>SibSp</code></td>
<td>number</td>
<td># of siblings/spouses on board</td>
</tr>
<tr class="odd">
<td><code>Embarked</code></td>
<td>string</td>
<td>Port of Embarkation</td>
</tr>
</tbody>
</table>
<aside class="notes">
<p>The dataset we’re using comes from Kaggle. Here are just a few of the columns of data you’ll be working with. As you can see, we have both numbers and strings. The target column is <code>Survived</code>, and it is a number that is either 0 or 1. This mix of data types is very common in ECE applications, where you might deal with numerical sensor readings, categorical status codes, and potentially textual log data. You’ll need to think about how to preprocess these different types of features.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="classification-project-kaggle-competition" class="slide level2">
<h2>Classification Project: Kaggle Competition</h2>
<p><strong>Titanic: Machine Learning from Disaster</strong></p>
<ul>
<li>Engage with a global community of ML practitioners.</li>
<li>Upload your results to compare your model’s performance.</li>
</ul>
<aside class="notes">
<p>Kaggle hosts several competitions that are open to users. It’s an exciting way to engage with the broader machine learning community and learn new things. At the end of this lab, you will upload your results to the Kaggle competition and see how your model compares to the over 17,000 other models people have created! This provides a real-world context for competition and benchmarking, akin to engineering design challenges.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="classification-project-your-turn" class="slide level2 scrollable">
<h2>Classification Project: Your Turn</h2>
<ol type="1">
<li><strong>Exploratory Data Analysis (EDA):</strong>
<ul>
<li>Understand the data, identify obvious problems, and perform initial cleaning.</li>
<li>Consider pros/cons of using ML for this problem.</li>
</ul></li>
<li><strong>Model Building &amp; Evaluation:</strong>
<ul>
<li>Choose your model (scikit-learn or TensorFlow).</li>
<li>Train and evaluate your model, discussing chosen metrics.</li>
</ul></li>
<li><strong>Make Predictions &amp; Upload to Kaggle:</strong>
<ul>
<li>Generate predictions for the test dataset.</li>
<li>Submit your predictions to the Kaggle competition.</li>
</ul></li>
<li><strong>Iterate on Your Model:</strong>
<ul>
<li>Tweak hyperparameters, try different models, explore new features.</li>
<li>Discuss your methodical approach to improvement.</li>
<li>Research and compare with other solutions for deeper insights.</li>
</ul></li>
</ol>
<aside class="notes">
<p>It is now your turn to perform a classification from end-to-end. The lab you are about to be given is divided into four primary parts. In the first section, you’ll acquire and explore the data. Here we expect you to write code and prose about the data. Does the data have obvious problems? Do any model-independent changes need to be made to the data? EDA is the place to reason about and perform these tasks. This is also a good time to think about the pros and cons of using machine learning to solve this problem. In the next section, you will build and evaluate your model. You may choose to use scikit-learn or Tensorflow. You may even try multiple approaches and compare your results. Here you should also evaluate your model and discuss your particular evaluation metrics, including why you chose them and what they say. Finally, you will make predictions on the features found in the <code>test.csv</code> file and upload them to Kaggle using the Kaggle API. Your lab should discuss your predictions as well as your Kaggle results. Last but not least, iterate on your model. Tweak hyperparameters, and see if you can improve your model. Discuss your method for changing specific hyperparameters. Be thoughtful and methodical; don’t just do it at random! Since this is a popular Kaggle dataset and competition, research other users’ solutions. Try looking at solutions that both do and don’t use ML, and discuss their relative merits. Take your time. Experiment. Don’t be afraid to throw away some work along the way. This iterative process is crucial for ECE engineers developing and refining complex systems.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>


<script type="pyodide-data">
eyJvcHRpb25zIjp7ImVudiI6eyJQTE9UTFlfUkVOREVSRVIiOiJwbG90bHlfbWltZXR5cGUifSwiaW5kZXhVUkwiOiJodHRwczovL2Nkbi5qc2RlbGl2ci5uZXQvcHlvZGlkZS92MC4yNy4wL2Z1bGwvIn0sInBhY2thZ2VzIjp7InBrZ3MiOlsicHlvZGlkZV9odHRwIiwibWljcm9waXAiLCJpcHl0aG9uIiwibnVtcHkiLCJwbG90bHkiLCJuYmZvcm1hdCJdfX0=
</script>
<script type="ojs-module-contents">
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
</script>
<div id="exercise-loading-indicator" class="exercise-loading-indicator d-none d-flex align-items-center gap-2">
<div id="exercise-loading-status" class="d-flex gap-2">

</div>
<div class="spinner-grow spinner-grow-sm">

</div>
</div>
<script type="vfs-file">
W10=
</script>
</section></section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="../qrjs_pics/unsoed_logo.png" class="slide-logo"></p>
<div class="footer footer-default">
<p><a href="https://imron-slide.vercel.app">irosyadi-2025</a></p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-chalkboard/plugin.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': false,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleChalkboard(event)\"><kbd>b</kbd> Toggle Chalkboard</a></li>\n<li class=\"slide-tool-item\" data-item=\"6\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleNotesCanvas(event)\"><kbd>c</kbd> Toggle Notes Canvas</a></li>\n<li class=\"slide-tool-item\" data-item=\"7\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.downloadDrawings(event)\"><kbd>d</kbd> Download Drawings</a></li>\n<li class=\"slide-tool-item\" data-item=\"8\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'chalkboard': {"buttons":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: true,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'fade',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@2.7.9/MathJax.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, RevealChalkboard, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script type="ojs-module-contents">
    eyJjb250ZW50cyI6W3sibWV0aG9kTmFtZSI6ImludGVycHJldCIsImNlbGxOYW1lIjoib2pzLWNlbGwtMSIsImlubGluZSI6ZmFsc2UsInNvdXJjZSI6Ii8vIElucHV0cyBmb3IgQ29uZnVzaW9uIE1hdHJpeFxudmlld29mIHRwX3ZhbCA9IElucHV0cy5yYW5nZShbMCwgMTAwXSwge3ZhbHVlOiAxLCBzdGVwOiAxLCBsYWJlbDogXCJUcnVlIFBvc2l0aXZlcyAoVFApXCJ9KTtcbnZpZXdvZiBmcF92YWwgPSBJbnB1dHMucmFuZ2UoWzAsIDEwMF0sIHt2YWx1ZTogMSwgc3RlcDogMSwgbGFiZWw6IFwiRmFsc2UgUG9zaXRpdmVzIChGUClcIn0pO1xudmlld29mIGZuX3ZhbCA9IElucHV0cy5yYW5nZShbMCwgMTAwXSwge3ZhbHVlOiA4LCBzdGVwOiAxLCBsYWJlbDogXCJGYWxzZSBOZWdhdGl2ZXMgKEZOKVwifSk7XG52aWV3b2YgdG5fdmFsID0gSW5wdXRzLnJhbmdlKFswLCAxMDBdLCB7dmFsdWU6IDkwLCBzdGVwOiAxLCBsYWJlbDogXCJUcnVlIE5lZ2F0aXZlcyAoVE4pXCJ9KTtcbiJ9LHsibWV0aG9kTmFtZSI6ImludGVycHJldFF1aWV0Iiwic291cmNlIjoic2hpbnlJbnB1dCgndHBfdmFsJykifSx7Im1ldGhvZE5hbWUiOiJpbnRlcnByZXRRdWlldCIsInNvdXJjZSI6InNoaW55SW5wdXQoJ2ZwX3ZhbCcpIn0seyJtZXRob2ROYW1lIjoiaW50ZXJwcmV0UXVpZXQiLCJzb3VyY2UiOiJzaGlueUlucHV0KCdmbl92YWwnKSJ9LHsibWV0aG9kTmFtZSI6ImludGVycHJldFF1aWV0Iiwic291cmNlIjoic2hpbnlJbnB1dCgndG5fdmFsJykifV19
    </script>
    <script type="module">
    if (window.location.protocol === "file:") { alert("The OJS runtime does not work with file:// URLs. Please use a web server to view this document."); }
    window._ojs.paths.runtimeToDoc = "../../amli";
    window._ojs.paths.runtimeToRoot = "../..";
    window._ojs.paths.docToRoot = "..";
    window._ojs.selfContained = false;
    window._ojs.runtime.interpretFromScriptTags();
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
      window.document.addEventListener("DOMContentLoaded", function (event) {
        const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
        tabsets.forEach(function(tabset) {
          const tabby = new Tabby('#' + tabset.id);
        });
        const isCodeAnnotation = (el) => {
          for (const clz of el.classList) {
            if (clz.startsWith('code-annotation-')) {                     
              return true;
            }
          }
          return false;
        }
        const onCopySuccess = function(e) {
          // button target
          const button = e.trigger;
          // don't keep focus
          button.blur();
          // flash "checked"
          button.classList.add('code-copy-button-checked');
          var currentTitle = button.getAttribute("title");
          button.setAttribute("title", "Copied!");
          let tooltip;
          if (window.bootstrap) {
            button.setAttribute("data-bs-toggle", "tooltip");
            button.setAttribute("data-bs-placement", "left");
            button.setAttribute("data-bs-title", "Copied!");
            tooltip = new bootstrap.Tooltip(button, 
              { trigger: "manual", 
                customClass: "code-copy-button-tooltip",
                offset: [0, -8]});
            tooltip.show();    
          }
          setTimeout(function() {
            if (tooltip) {
              tooltip.hide();
              button.removeAttribute("data-bs-title");
              button.removeAttribute("data-bs-toggle");
              button.removeAttribute("data-bs-placement");
            }
            button.setAttribute("title", currentTitle);
            button.classList.remove('code-copy-button-checked');
          }, 1000);
          // clear code selection
          e.clearSelection();
        }
        const getTextToCopy = function(trigger) {
          const outerScaffold = trigger.parentElement.cloneNode(true);
          const codeEl = outerScaffold.querySelector('code');
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
        }
        const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
          text: getTextToCopy
        });
        clipboard.on('success', onCopySuccess);
        if (window.document.getElementById('quarto-embedded-source-code-modal')) {
          const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
            text: getTextToCopy,
            container: window.document.getElementById('quarto-embedded-source-code-modal')
          });
          clipboardModal.on('success', onCopySuccess);
        }
          var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
          var mailtoRegex = new RegExp(/^mailto:/);
            var filterRegex = new RegExp('/' + window.location.host + '/');
          var isInternal = (href) => {
              return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
          }
          // Inspect non-navigation links and adorn them if external
         var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
          for (var i=0; i<links.length; i++) {
            const link = links[i];
            if (!isInternal(link.href)) {
              // undo the damage that might have been done by quarto-nav.js in the case of
              // links that we want to consider external
              if (link.dataset.originalHref !== undefined) {
                link.href = link.dataset.originalHref;
              }
            }
          }
        function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
          const config = {
            allowHTML: true,
            maxWidth: 500,
            delay: 100,
            arrow: false,
            appendTo: function(el) {
                return el.closest('section.slide') || el.parentElement;
            },
            interactive: true,
            interactiveBorder: 10,
            theme: 'light-border',
            placement: 'bottom-start',
          };
          if (contentFn) {
            config.content = contentFn;
          }
          if (onTriggerFn) {
            config.onTrigger = onTriggerFn;
          }
          if (onUntriggerFn) {
            config.onUntrigger = onUntriggerFn;
          }
            config['offset'] = [0,0];
            config['maxWidth'] = 700;
          window.tippy(el, config); 
        }
        const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
        for (var i=0; i<noterefs.length; i++) {
          const ref = noterefs[i];
          tippyHover(ref, function() {
            // use id or data attribute instead here
            let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
            try { href = new URL(href).hash; } catch {}
            const id = href.replace(/^#\/?/, "");
            const note = window.document.getElementById(id);
            if (note) {
              return note.innerHTML;
            } else {
              return "";
            }
          });
        }
        const findCites = (el) => {
          const parentEl = el.parentElement;
          if (parentEl) {
            const cites = parentEl.dataset.cites;
            if (cites) {
              return {
                el,
                cites: cites.split(' ')
              };
            } else {
              return findCites(el.parentElement)
            }
          } else {
            return undefined;
          }
        };
        var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
        for (var i=0; i<bibliorefs.length; i++) {
          const ref = bibliorefs[i];
          const citeInfo = findCites(ref);
          if (citeInfo) {
            tippyHover(citeInfo.el, function() {
              var popup = window.document.createElement('div');
              citeInfo.cites.forEach(function(cite) {
                var citeDiv = window.document.createElement('div');
                citeDiv.classList.add('hanging-indent');
                citeDiv.classList.add('csl-entry');
                var biblioDiv = window.document.getElementById('ref-' + cite);
                if (biblioDiv) {
                  citeDiv.innerHTML = biblioDiv.innerHTML;
                }
                popup.appendChild(citeDiv);
              });
              return popup.innerHTML;
            });
          }
        }
      });
      </script>
    

</body></html>