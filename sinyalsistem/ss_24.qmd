---
title: "Signals and Systems"
subtitle: "2.4 Causal LTI Systems Described by Differential and Difference Equations"
author: "Imron Rosyadi"
format:
  live-revealjs:
    logo: "qrjs_assets/unsoed_logo.png"
    footer: "[irosyadi-2025](https://imron-slide.vercel.app)"
    slide-number: true
    chalkboard: true
    scrollable: true
    controls: true
    progress: true
    preview-links: false
    transition: fade
    incremental: false
    smaller: false
    theme: [default, qrjs_assets/ir_style.scss]
    mermaid:
        theme: neutral
pyodide:
  packages:
    - numpy
    - plotly
    - nbformat
---

# Signals and Systems
## 2.4 Causal LTI Systems Described by Differential and Difference Equations

---

## System Description using Equations
-   **Continuous-time systems** are often described by Linear Constant-Coefficient **Differential** Equations (LCCDEs).
    -   Examples: RC circuits (Figure 1.1), vehicle motion (Figure 1.2), mechanical systems with restoring and damping forces.
-   **Discrete-time systems** are often described by Linear Constant-Coefficient **Difference** Equations (LCCDEs).
    -   Examples: Bank account accumulation (Example 1.10), digital simulations, signal processing filters (e.g., differencing, averaging filters).

::: {.notes}
Today, we delve into a foundational aspect of Signals and Systems: how we mathematically model systems using differential and difference equations. These equations are not just abstract mathematical constructs; they are the language we use to describe a vast array of real-world engineering phenomena. Think of an RC circuit, where the capacitor's voltage changes based on the input current and its own past charge, or a vehicle's speed evolving under the influence of applied forces and friction. All these are elegantly captured by differential equations. Similarly, in the digital realm, from a simple moving average filter to complex control algorithms, difference equations provide the framework for understanding and designing discrete-time systems. Understanding how to interpret and solve these equations is crucial for analyzing system behavior.
:::

---

## Implicit System Specification
-   Differential and difference equations provide an **implicit specification** of system behavior.
    -   They describe a *relationship* between the input ($x(t)$ or $x[n]$) and the output ($y(t)$ or $y[n]$), rather than an explicit expression.
-   **Example: First-order LCCDE**
    $$
    \frac{d y(t)}{d t}+2 y(t)=x(t) \tag{2.95}
    $$
    -   This equation relates the rate of change of $y(t)$ and $y(t)$ itself to $x(t)$.
    -   It doesn't directly tell us what $y(t)$ is for a given $x(t)$.

::: {.notes}
It's important to understand that these equations are *not* direct formulas for the output. They don't simply say "y equals this function of x". Instead, they describe a constraint or a rule that the input and output must satisfy together. For instance, the equation shown on the slide states that the sum of the output's rate of change and twice the output itself must equal the input. To get an explicit formula for $y(t)$, we need to *solve* this differential equation. This implicit nature is key to understanding why solving these equations requires specific techniques and additional information.
:::

---

## Auxiliary Conditions and Initial Rest
-   To find an **explicit expression** for the output, we must solve the differential or difference equation.
-   Solving requires more information than the equation alone: **auxiliary conditions**.
    -   E.g., initial speed of a car, initial voltage across a capacitor.
-   Different auxiliary conditions lead to different input-output relationships.
-   For **Causal LTI systems**, the auxiliary conditions typically take the form of the **condition of initial rest**.
    -   If the input $x(t)=0$ for $t < t_0$, then the output $y(t)$ must also be 0 for $t < t_0$.
    -   This implies specific initial conditions at $t_0$, e.g., $y(t_0)=0$ (and its derivatives for higher-order systems).

::: {.notes}
Imagine trying to predict where a car will be after 10 seconds of constant acceleration. You can't just know the acceleration; you also need to know its starting position and speed. Similarly, for an RC circuit, knowing the applied voltage isn't enough; you need the initial capacitor voltage. These "starting values" are our auxiliary conditions. For most systems we study in Signals and Systems, particularly those that are Linear, Time-Invariant, and Causal – which we'll call LTI-C systems for short – we employ a standard auxiliary condition called "initial rest." This condition essentially states that if the system has not been acted upon by an input before a certain time, its output, and all its internal "memory" elements, must be zero up to that time. This condition is crucial because it makes the system unique, causal, and LTI. It ensures that the system's response only begins when the input begins, and that the system "remembers" its past only via the input it has received, not through some arbitrary pre-existing state.
:::

---

## Solving First-Order LCCDE: Example 2.14

Consider the system described by:  $\frac{d y(t)}{d t}+2 y(t)=x(t)$
Let the input signal be: $x(t)=K e^{3 t} u(t)$

-   The **complete solution** to a differential equation consists of two parts:
    $$
    y(t)=y_{p}(t)+y_{h}(t) \tag{2.97}
    $$
    -   $y_p(t)$: **Particular solution** (or forced response). This part satisfies the full differential equation with the given input.
    -   $y_h(t)$: **Homogeneous solution** (or natural response). This part is a solution to the homogeneous differential equation (with input set to zero):
        $$
        \frac{d y(t)}{d t}+2 y(t)=0 \tag{2.98}
        $$

::: {.notes}
Let's walk through an example to see how we solve these. We have a first-order differential equation modeling a system, and we're applying an exponential input `x(t)`. The general approach to solving such an equation is to break the problem into two parts. First, we find the particular solution, which directly responds to the input signal. This is the forced part of the response. Second, we find the homogeneous solution, which describes the system's inherent behavior—how it would react without any external input, or how it would 'ring out' if disturbed. This is often called the natural response. The total solution is simply the sum of these two components.
:::

---

## Example 2.14: Finding the Particular Solution
-   **For $t>0$, the input is $x(t)=K e^{3 t}$.**
-   We hypothesize that the particular solution $y_p(t)$ will have the same exponential form as the input for $t>0$:
    $$
    y_{p}(t)=Y e^{3 t} \tag{2.99}
    $$
    where $Y$ is a coefficient to be determined.
-   Substitute $y_p(t)$ and $x(t)$ into the original differential equation ($\frac{d y(t)}{d t}+2 y(t)=x(t)$) for $t>0$:
    $$
    \frac{d}{dt}(Y e^{3 t}) + 2 (Y e^{3 t}) = K e^{3 t}  \quad \implies \quad 3 Y e^{3 t}+2 Y e^{3 t}=K e^{3 t} \tag{2.100}
    $$
-   Cancel $e^{3 t}$ from both sides, then solve for $Y$:
    $$
    5 Y = K \implies Y = \frac{K}{5} \tag{2.101, 2.102}
    $$
-   Thus, the particular solution for $t>0$ is:
    $$
    y_{p}(t)=\frac{K}{5} e^{3 t}, \quad t>0 \tag{2.103}
    $$

::: {.notes}
To find the particular solution when the input is an exponential, a common and effective strategy is to assume that the particular solution itself will be an exponential of the same form. So, for an input `K * e^(3t)`, we propose a particular solution `Y * e^(3t)`. We then substitute this proposed solution and the input back into the original differential equation. The derivative of `Y * e^(3t)` is `3Y * e^(3t)`. After substitution, we can factor out `e^(3t)` and solve for the unknown coefficient `Y`. In this case, we find `Y = K/5`. This gives us the part of the output that is directly "forced" by the input signal.
:::

---

## Example 2.14: Finding the Homogeneous Solution
-   Now, we need to find the homogeneous solution $y_h(t)$, which satisfies the homogeneous differential equation:
    $$
    \frac{d y(t)}{d t}+2 y(t)=0 \tag{2.98}
    $$
-   We hypothesize an exponential form for the homogeneous solution:
    $$
    y_{h}(t)=A e^{s t} \tag{2.104}
    $$
    where $A$ and $s$ are constants.
-   Substitute $y_h(t)$ into the homogeneous equation:
    $$
    \frac{d}{dt}(A e^{s t}) + 2 (A e^{s t}) = 0 \quad \implies \quad A s e^{s t}+2 A e^{s t}=0 \tag{2.105}
    $$
-   Factor out $A e^{s t}$:
    $$
    A e^{s t}(s+2)=0
    $$
-   For this to be true for all $t$, we must have $s+2=0$, which implies $s = -2$.
-   Therefore, the homogeneous solution is:
    $$
    y_{h}(t)=A e^{-2 t}
    $$
    where $A$ is an arbitrary constant determined by auxiliary conditions.

::: {.notes}
Next, let's find the homogeneous solution. This represents the system's "natural" way of responding, independent of the specific input. We again assume an exponential form, `A * e^(st)`. When we substitute this into the homogeneous equation (where the input is zero), we find a condition for 's'. In this case, `s` must be -2. This means `A * e^(-2t)` is a valid solution to the homogeneous equation for any constant `A`. This `A` is the arbitrary constant that will be determined by our auxiliary or initial conditions. The `-2t` in the exponent indicates an exponentially decaying component, often related to the system's stability or its natural frequency.
:::

---

## Example 2.14: Total Solution and Initial Rest
-   **Combine particular and homogeneous solutions to get the general solution for $t>0$:**
    $$
    y(t)=A e^{-2 t}+\frac{K}{5} e^{3 t}, \quad t>0 \tag{2.106}
    $$
-   **Apply the condition of initial rest:**
    -   Since the input $x(t)=K e^{3 t} u(t)$ implies $x(t)=0$ for $t<0$, a causal LTI system will have $y(t)=0$ for $t<0$.
    -   This means the initial condition is $y(0)=0$.
-   **Solve for $A$ using $y(0)=0$ in the general solution:**
    $$
    0 = A e^{-2(0)} + \frac{K}{5} e^{3(0)}  \implies  0 = A + \frac{K}{5}  \implies  A = -\frac{K}{5}
    $$
-   **Substitute $A$ back into the general solution to obtain the final, complete response:**
    $$
    y(t)=\frac{K}{5} e^{3 t} - \frac{K}{5} e^{-2 t}, \quad t>0
    $$
-   Combining with $y(t)=0$ for $t<0$:
    $$
    y(t)=\frac{K}{5}\left[e^{3 t}-e^{-2 t}\right] u(t) \tag{2.108}
    $$

::: {.notes}
Now that we have both the particular and homogeneous solutions, we combine them to form the general solution. Notice that it still has an unknown constant `A`. This is where our auxiliary condition of "initial rest" comes into play. Since our input `x(t)` effectively starts at `t=0` (due to the `u(t)`), the condition of initial rest implies that the output `y(t)` must also be zero before `t=0`. Thus, we can set `y(0) = 0`. Plugging this into our general solution allows us to solve for `A`, making the solution unique. In this example, `A` turns out to be `-K/5`. With `A` determined, we have the complete and unique output `y(t)` for the given input and initial rest condition. This final form includes the unit step `u(t)` to correctly represent the causality, meaning the response starts at `t=0`.
:::

---

## Example 2.14: Output Signal Plot

<small>Adjust the input amplitude K and observe the output response.  </small>

```{ojs}
viewof K_slider = Inputs.range([0, 10], {
  label: html`<span style="font-size: 0.8em;">Amplitude K</span>`,
  step: 1,
  value: 5,
});
```
```{pyodide}
#| echo: false
#| input: 
#| - K_slider
import numpy as np
import plotly.graph_objects as go

K = K_slider
t = np.linspace(-1, 3, 400)
x = K * np.exp(3 * t) * (t >= 0)
y = (K / 5) * (np.exp(3 * t) - np.exp(-2 * t)) * (t >= 0)

fig = go.Figure()
fig.add_trace(go.Scatter(x=t, y=x, mode='lines', name=f'Input x(t) = {K}e^(3t)u(t)'))
fig.add_trace(go.Scatter(x=t, y=y, mode='lines', name='Output y(t)'))
fig.update_layout(
    title=f'System Response for K={K}',
    xaxis_title='Time (t)',
    yaxis_title='Amplitude',
    yaxis_range=[0, 80000],
    height=400,
    margin=dict(t=50, b=50, l=50, r=50)
)
fig.show()
```

::: {.notes}
Let's visualize this. Here, you can change the amplitude 'K' of the input signal using the slider. Observe how the input signal `x(t)` starts at `t=0` and grows exponentially. The output `y(t)` also starts at `t=0`, due to initial rest. It initially grows because of the `e^(3t)` term from the input, but also incorporates the decaying `e^(-2t)` term from the system's natural response. Notice how if you double K, the output also doubles, confirming the linearity of the system under initial rest conditions. This interactive plot helps us gain an intuitive understanding of how the system processes the input and how the different components of the solution manifest over time.
:::

---

## General Nth-Order LCCDE
-   A general $N$th-order linear constant-coefficient differential equation is given by:
    $$
    \sum_{k=0}^{N} a_{k} \frac{d^{k} y(t)}{d t^{k}}=\sum_{k=0}^{M} b_{k} \frac{d^{k} x(t)}{d t^{k}} \tag{2.109}
    $$
    -   $N$ is the order of the system (highest derivative of $y(t)$).
    -   If $N=0$, then $y(t)=\frac{1}{a_{0}} \sum_{k=0}^{M} b_{k} \frac{d^{k} x(t)}{d t^{k}}$, which is an explicit function of $x(t)$ and its derivatives (no auxiliary conditions needed).
-   **Solution approach:** Still a sum of particular and homogeneous solutions.
    -   Homogeneous equation: $\sum_{k=0}^{N} a_{k} \frac{d^{k} y(t)}{d t^{k}}=0$.
-   **Initial Rest Condition:** For $x(t)=0$ for $t \leq t_0$, the output $y(t)=0$ for $t \leq t_0$. This requires the initial conditions:
    $$
    y\left(t_{0}\right)=\frac{d y\left(t_{0}\right)}{d t}=\ldots=\frac{d^{N-1} y\left(t_{0}\right)}{d t^{N-1}}=0 \tag{2.112}
    $$

::: {.notes}
The concepts we just covered for a first-order differential equation extend directly to more complex, higher-order systems. Equation 2.109 is the general form for an Nth-order LCCDE. The 'N' here refers to the highest derivative of the output `y(t)`. If `N` is zero, the equation simplifies, and `y(t)` becomes an explicit function of the input and its derivatives; in this highly simplified case, no auxiliary conditions are strictly needed. However, for `N` greater than or equal to 1, the output is implicitly defined, and we still follow the same strategy: finding particular and homogeneous solutions. For LTI-C systems, the initial rest condition applies, but for an Nth-order system, it means that a total of N initial conditions (the output and its first N-1 derivatives) must all be zero at the starting point `t0` where the input becomes non-zero. This provides the `N` constants needed to uniquely determine the full solution. We will later introduce more advanced tools like Laplace Transforms to greatly simplify the solution of these higher-order equations.
:::

---

## Linear Constant-Coefficient Difference Equations (LCCDEs)
-   The **discrete-time counterpart** to continuous-time LCCDEs is the $N$th-order linear constant-coefficient difference equation:
    $$
    \sum_{k=0}^{N} a_{k} y[n-k]=\sum_{k=0}^{M} b_{k} x[n-k] \tag{2.113}
    $$
-   **Solution approach:** Analogous to differential equations – sum of a particular solution and a homogeneous solution.
    -   Homogeneous equation: $\sum_{k=0}^{N} a_{k} y[n-k]=0$.
-   **Condition of Initial Rest:** If $x[n]=0$ for $n<n_0$, then $y[n]=0$ for $n<n_0$.
    -   Under the condition of initial rest, the system described by the difference equation is LTI and causal.

::: {.notes}
Just as differential equations describe continuous-time systems, difference equations are fundamental for discrete-time systems. Equation 2.113 is the general form. The solution methodology mirrors the continuous-time case: find a particular solution responding to the input, and a homogeneous solution representing the system's natural behavior. And crucially, just as with differential equations, difference equations require auxiliary conditions for a unique solution. Again, for LTI and causal systems, we adopt the "initial rest" condition. This states that if the input is zero before a certain time `n0`, then the output must also be zero before `n0`. This ensures causality and preserves the LTI properties.
:::

---

## Recursive vs. Nonrecursive Systems

**Recursive Equation (IIR)**  

-   If $N \ge 1$ (output depends on past outputs), the equation can be rearranged to directly compute $y[n]$:
    $$
    y[n]=\frac{1}{a_{0}}\left\{\sum_{k=0}^{M} b_{k} x[n-k]-\sum_{k=1}^{N} a_{k} y[n-k]\right\} \tag{2.115}
    $$
-   Output $y[n]$ depends on both **current/past inputs** and **past outputs**.
-   Requires auxiliary conditions (e.g., $y[n_0-1], \ldots, y[n_0-N]$) to start the recursion.
-   Often leads to **Infinite Impulse Response (IIR)** systems.

**Nonrecursive Equation (FIR)**  

-   In the special case when $N = 0$:
    $$
    y[n]=\sum_{k=0}^{M}\left(\frac{b_{k}}{a_{0}}\right) x[n-k] \tag{2.116}
    $$
-   Output $y[n]$ depends **only on present and past inputs.**
-   No auxiliary conditions are directly needed, as output is explicit.
-   Always a **Finite Impulse Response (FIR)** system.
    -   Its impulse response $h[n]$ has finite duration:
        $$
        h[n]= \begin{cases}\frac{b_{n}}{a_{0}}, & 0 \leq n \leq M \\ 0, & \text { otherwise }\end{cases} \tag{2.117}
        $$

::: {.notes}
A significant distinction in discrete-time systems is between recursive and nonrecursive equations. If the current output `y[n]` depends on *past outputs* (i.e., N is greater than or equal to 1), the equation is recursive. This forms a feedback loop where past results influence current calculations. Because of this feedback, initial conditions are essential to kickstart the process, and such systems typically have an impulse response that goes on indefinitely, hence "Infinite Impulse Response" or IIR.

In contrast, if `N` is zero, the current output `y[n]` depends *only on current and past inputs*. This is a nonrecursive equation. There's no feedback from the output back into the system. As a result, no auxiliary conditions are needed, and the impulse response is always finite in duration, making these "Finite Impulse Response" or FIR systems. FIR systems are simpler to analyze and design in certain contexts.
:::

---

## Solving First-Order LCCDE: Example 2.15

Consider the difference equation: $y[n]-\frac{1}{2} y[n-1]=x[n]$  
Rearranging for recursive computation: $y[n]=x[n]+\frac{1}{2} y[n-1]$  
Let the input be an impulse: $x[n]=K \delta[n]$  

-   **Apply initial rest condition:**  
    -   Since $x[n]=0$ for $n<-1$, initial rest implies $y[n]=0$ for $n<-1$.
    -   Therefore, $y[-1]=0$.
-   **Iterative Solution for $n \ge 0$:**  
    -   $y[0] = x[0] + \frac{1}{2} y[-1] = K \delta[0] + \frac{1}{2}(0) = K$
    -   $y[1] = x[1] + \frac{1}{2} y[0] = K \delta[1] + \frac{1}{2} K = 0 + \frac{1}{2} K = \frac{1}{2} K$
    -   $y[2] = x[2] + \frac{1}{2} y[1] = K \delta[2] + \frac{1}{2} \left(\frac{1}{2} K\right) = 0 + \left(\frac{1}{2}\right)^2 K = \left(\frac{1}{2}\right)^2 K$
    -   $\vdots$
    -   In general, for $n \ge 0$: $y[n] = \left(\frac{1}{2}\right)^n K$.
-   **Impulse Response ($K=1$):**
    $$
    h[n]=\left(\frac{1}{2}\right)^{n} u[n] \tag{2.125}
    $$
    This is an **Infinite Impulse Response (IIR) system**.

::: {.notes}
Let's see a discrete-time example. We have a first-order difference equation, rearranged into its recursive form to show that $y[n]$ depends on $y[n-1]$. We apply an impulse input, $K \delta[n]$. The initial rest condition means that before `n=0`, `y[n]` is zero, so `y[-1]` is zero. From there, we can iteratively calculate `y[n]` for `n=0, 1, 2, ...`.

At `n=0`, `y[0]` is `x[0]` plus half of `y[-1]`, which gives `K`.
At `n=1`, `y[1]` is `x[1]` plus half of `y[0]`, which gives `(1/2)K`.
This pattern continues, leading to $y[n] = (1/2)^n K$ for `n` greater than or equal to zero. If `K=1`, this directly gives us the impulse response `h[n] = (1/2)^n u[n]`. Since this response extends indefinitely, it confirms that this is an IIR system, characteristic of recursive difference equations.
:::

---

## Example 2.15: Impulse Response of an IIR System

<small>Observe the decaying impulse response for different coefficients.  </small>

```{ojs}
viewof alpha_slider = Inputs.range([-0.9, 0.9], {
  label: html`<span style="font-size: 0.8em;">Coefficient 'a'</span>`,
  step: 0.1,
  value: 0.5,
});
```
```{pyodide}
#| echo: false
#| input: 
#| - alpha_slider
import numpy as np
import plotly.graph_objects as go

alpha = alpha_slider
n = np.arange(0, 20) # Time indices
h = (alpha)**n * (n >= 0) # Impulse response h[n] = a^n u[n]

fig = go.Figure()
fig.add_trace(go.Scatter(x=n, y=h, mode='lines+markers', name=f'h[n] for a={alpha:.1f}'))
fig.update_layout(
    title=f'Impulse Response h[n] = ({alpha:.1f})^n u[n]',
    xaxis_title='n (samples)',
    yaxis_title='Amplitude',
    yaxis_range=[-1, 1],
    height=400,
    margin=dict(t=50, b=50, l=50, r=50)
)
fig.show()
```

::: {.notes}
Here's an interactive visualization of the impulse response we just derived. The difference equation is `y[n] = x[n] + a*y[n-1]`. The impulse response is `h[n] = a^n u[n]`. You can adjust the coefficient 'a' using the slider. Notice how the shape of the impulse response changes:
-   When `a` is between 0 and 1 (like 0.5 in our example), the response decays exponentially, indicating a stable system.
-   When `a` is negative (e.g., -0.5), it oscillates while decaying.
-   If the absolute value of `a` is greater than or equal to 1, the response will not decay, indicating an unstable or marginally stable system.

This helps visualize why these are called Infinite Impulse Response (IIR) systems—the response theoretically continues indefinitely, though it can decay quickly depending on the value of 'a'.
:::

---

## Block Diagram Representations
-   Representing systems using block diagrams offers several advantages:
    -   Provides a **pictorial representation** for better intuitive understanding of system structure.
    -   Useful for **simulation** (analog or digital computers).
    -   Guides **hardware implementation** for physical systems.
-   **Basic Operations for Discrete-Time Systems:**
    -   **Adder:** Sums multiple input signals.
    -   **Multiplier:** Scales a signal by a constant coefficient.
    -   **Unit Delay:** Outputs the input from the *previous* time step. This is the **memory element**.

::: {.notes}
Moving beyond mathematical equations, block diagrams offer a powerful and intuitive way to visualize and implement systems. They break down a complex system into an interconnection of simple, fundamental operations. This not only enhances our understanding of how signals flow and are processed within the system but also provides a direct blueprint for how these systems could be simulated on computers or even built in hardware. For discrete-time systems, we use three basic building blocks: adders to combine signals, multipliers to scale them by coefficients, and crucially, a unit delay element, which serves as the system's memory, holding onto a value from the previous time step.
:::

---

## Discrete-Time First-Order System Block Diagram
System equation: $y[n]+a y[n-1]=b x[n]$  
Rearranged for direct computation: $y[n] = -a y[n-1] + b x[n]$  

```{mermaid}
graph LR
    x_n("x[n]") --> mult_b{b}
    mult_b --> sum1("$$+$$")
    delay("$$z^{-1}$$") -- y[n-1] --> mult_a{-a}
    mult_a --> sum1
    sum1 -- y[n] --> delay
    sum1 -- y[n] --> y_n("y[n]")

    subgraph Operations
        sum1
        mult_b
        mult_a
        delay
    end
```

-   The **delay element** ($z^{-1}$) represents the system's memory. Its initial state corresponds to the auxiliary condition $y[-1]$.
-   This diagram clearly shows **feedback**, characteristic of recursive (IIR) systems.

::: {.notes}
Let's construct a block diagram for our first-order discrete-time difference equation: `y[n] = -a*y[n-1] + b*x[n]`. The term `b*x[n]` is created by multiplying the input `x[n]` by `b`. The term `-a*y[n-1]` is generated from the output `y[n]`. The output `y[n]` goes into a delay element, which stores `y[n-1]`. This `y[n-1]` is then multiplied by `-a`. Finally, these two terms (`b*x[n]` and `-a*y[n-1]`) are summed to produce the current output `y[n]`. Notice the feedback loop: the output `y[n]` is fed back through the delay and multiplier to influence future outputs. The delay element is explicitly where the system's "memory" resides, and its initial stored value `y[-1]` is the necessary auxiliary condition. This feedback structure is a hallmark of recursive systems.
:::

---

## Basic Elements of Block Diagram

For equation $y[n] = -a*y[n-1] + b*x[n]$ : (a) an adder; (b) multiplication by a coefficient; (c) a unit delay; (d) overall representation. 

![](https://cdn.mathpix.com/cropped/2024_02_14_ad5c48a840b9702e9410g-156.jpg?height=192&width=636&top_left_y=246&top_left_x=397){fig-align="center" width="50%"}

(a)

![](https://cdn.mathpix.com/cropped/2024_02_14_ad5c48a840b9702e9410g-156.jpg?height=77&width=531&top_left_y=564&top_left_x=411){fig-align="center" width="50%"}

(b)

![](https://cdn.mathpix.com/cropped/2024_02_14_ad5c48a840b9702e9410g-156.jpg?height=134&width=545&top_left_y=782&top_left_x=414){fig-align="center" width="50%"}

(c)

![](https://cdn.mathpix.com/cropped/2024_02_14_ad5c48a840b9702e9410g-156.jpg?height=309&width=577&top_left_y=1027&top_left_x=472){fig-align="center" width="50%"}

(d)

---

## Basic Operations for Continuous-Time Systems
-   Similar basic elements found in continuous-time block diagrams:
    -   **Adder:** Sums multiple input signals.
    -   **Multiplier:** Scales a signal by a constant coefficient.
-   Crucially, for continuous-time, instead of a differentiator (which is difficult to implement and sensitive to noise), we use an **integrator**.
    -   **Integrator:** $\int_{-\infty}^{t} (\cdot) d\tau$. This is the **memory storage element** for continuous-time systems.

::: {.notes}
For continuous-time systems, the fundamental building blocks for block diagrams are similar: adders and multipliers. However, a key difference emerges when we deal with derivatives. While analytically we define systems with derivatives, practically, differentiators are very hard to build and are notoriously sensitive to noise amplification. Think about trying to build a circuit that perfectly differentiates a signal – any tiny bit of noise would be greatly exaggerated. So, for practical implementation and stable representations, we prefer to work with *integrators* instead. An integrator performs the inverse operation of differentiation, accumulating the input over time, and it naturally acts as the memory element in continuous-time systems, much like a capacitor storing charge.
:::

---

## Continuous-Time First-Order System Block Diagram
System equation: $\frac{d y(t)}{d t}+a y(t)=b x(t)$  
Rearranged for integration: $\frac{d y(t)}{d t}=b x(t)-a y(t)$  
Integrate from $-\infty$ to $t$: $y(t)=\int_{-\varkappa}^{t}[b x(\tau)-a y(\tau)] d \tau$  

```{mermaid}
graph LR
    x_t("x(t)") --> mult_b{b}
    mult_b --> sum1("$$+$$")
    y_t("y(t)") --> mult_a{-a}
    mult_a --> sum1
    sum1 --> intg("∫dτ")
    intg --> y_t
```

-   The **integrator** is the memory element, storing the accumulated signal.
-   The value $y(t_0)$ represents the initial condition stored by the integrator.
-   This representation is the basis for **analog computer simulations**.

::: {.notes}
Let's visualize the first-order continuous-time LCCDE. Instead of expressing `y(t)` directly, we rearrange the equation to isolate the derivative of `y(t)`. So, `dy(t)/dt = b*x(t) - a*y(t)`. If we integrate both sides from `negative infinity` to `t`, the left side becomes `y(t)`, and the right side becomes the integral of `b*x(tau) - a*y(tau)`.

In the block diagram:
`x(t)` is multiplied by `b`.
`y(t)` is multiplied by `-a`.
These two signals are added together.
The sum is then fed into an integrator.
The output of the integrator is `y(t)`.
Again, we see a feedback loop where `y(t)` is fed back to influence its own derivative. The integrator is the system's memory, storing its past values. This type of block diagram directly forms the basis of historical analog computers and remains a fundamental way to understand continuous-time system implementation.
:::

---

## Basic Elements of Block Diagram

(a) an adder; (b) multiplication by a coefficient; (c) a differentiator; (d) overall representation using differentiator; (d) overall representation using integrator

![](https://cdn.mathpix.com/cropped/2024_02_14_ad5c48a840b9702e9410g-156.jpg?height=192&width=636&top_left_y=246&top_left_x=397){fig-align="center" width="50%"}

(a)

![](https://cdn.mathpix.com/cropped/2024_02_14_ad5c48a840b9702e9410g-156.jpg?height=77&width=531&top_left_y=564&top_left_x=411){fig-align="center" width="50%"}

(b)

![](https://cdn.mathpix.com/cropped/2024_02_14_ad5c48a840b9702e9410g-156.jpg?height=134&width=545&top_left_y=782&top_left_x=414){fig-align="center" width="50%"}

(c)

![](https://cdn.mathpix.com/cropped/2024_02_14_ad5c48a840b9702e9410g-156.jpg?height=309&width=577&top_left_y=1027&top_left_x=472){fig-align="center" width="50%"}

(d)

![](https://cdn.mathpix.com/cropped/2024_02_14_ad5c48a840b9702e9410g-158.jpg?height=438&width=644&top_left_y=251&top_left_x=512){fig-align="center" width="50%"}

(e)

---

## Continous System in Differential Equations

**Mass–Spring System (Oscillator)**

A mass attached to a spring (ignoring friction first).

* Hooke’s law: restoring force $F = -kx$
* Newton’s second law: $F = m \dfrac{d^2x}{dt^2}$

So:

$$
m \frac{d^2x}{dt^2} + kx = 0
$$

This **second-order ODE** governs the oscillation. Its solution is sinusoidal:

$$
x(t) = A \cos(\omega t) + B \sin(\omega t), \quad \omega = \sqrt{\tfrac{k}{m}}
$$

---

## Continous System in Differential Equations

**RC Circuit (Charging a Capacitor)**

A resistor $R$ and capacitor $C$ in series with a voltage source $V$.
Kirchhoff’s law:

$$
V = V_R + V_C = Ri(t) + \frac{q(t)}{C}
$$

Since $i(t) = \dfrac{dq}{dt}$:

$$
R \frac{dq}{dt} + \frac{q}{C} = V
$$

This **first-order ODE** models how charge (and voltage across capacitor) evolves. The solution is exponential:

$$
q(t) = CV \left(1 - e^{-t/RC}\right)
$$

**Pendulum (Nonlinear System)**

For a pendulum of length $L$, angle $\theta(t)$:

$$
\frac{d^2 \theta}{dt^2} + \frac{g}{L}\sin(\theta) = 0
$$

This is a **nonlinear ODE** (due to $\sin\theta$). 

---

## Discrete System in Difference Equations

**Digital RC Circuit (Discrete Approximation)**

If you sample the continuous RC circuit at time steps of length $\Delta t$, the capacitor voltage $v[n]$ satisfies a first-order **difference equation**:

$$
v[n+1] = \left(1 - \frac{\Delta t}{RC}\right) v[n] + \frac{\Delta t}{RC} V
$$

This models how the voltage changes step by step in a digital simulation.

## **Spring-Mass System with Numerical Integration**

Discretizing Newton’s second law for a spring–mass:

$$
m \frac{d^2x}{dt^2} = -kx
$$

Using finite differences ($x_{n+1} - 2x_n + x_{n-1}$/$\Delta t^2$):

$$
x_{n+1} = 2x_n - x_{n-1} - \frac{k}{m} \Delta t^2 \, x_n
$$

This is a **second-order difference equation** that simulates oscillations step by step.

**Control Systems (Z-Domain Models)**

Digital controllers (like in robotics or motor drives) are governed by difference equations.
Example: A discrete-time first-order system:

$$
y[n+1] = a y[n] + b u[n]
$$

where $y[n]$ is system output and $u[n]$ is input at time step $n$.

---

## Conclusion
-   **LCCDEs** are fundamental for describing causal LTI systems in both continuous and discrete domains.
-   Solving involves finding a **particular solution** (forced response) and a **homogeneous solution** (natural response).
-   **Auxiliary conditions**, particularly the **condition of initial rest**, are crucial for unique, causal, and LTI solutions.
-   Discrete-time systems are categorized as **Recursive (IIR)** or **Nonrecursive (FIR)** based on output dependence.
-   **Block diagrams** (using adders, multipliers, delays/integrators) provide valuable visual understanding and aid implementation.
-   **Ahead:** We will develop more powerful frequency-domain tools (e.g., Laplace and Z-transforms) to simplify solving these equations and further analyze complex system properties.

::: {.notes}
To summarize, differential and difference equations are the bedrock for modeling LTI causal systems. We've learned that solving them involves combining a particular solution, driven by the input, with a homogeneous solution, representing the system's natural behavior. Initial rest is the key auxiliary condition for ensuring the crucial properties of causality and LTI. We also explored the distinction between FIR and IIR systems in discrete time and saw how block diagrams offer a powerful visual and practical representation. In the coming chapters, we'll build on this foundation by introducing frequency-domain transforms that will provide even more efficient and insightful ways to analyze these complex and fascinating systems. Thank you.
:::
